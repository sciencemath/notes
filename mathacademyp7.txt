Parametric Inference:

Point Estimation
Maximum likelihood
Hypothesis testing
Confidence Intervals

Note:
anything with Φ(z) denotes a z-table lookup

--------------------------------------------

In statistics we often want ot use sample data to deduce or infer the values of various population parameters, the two most common population parameters
the population mean μ
the population variance σ^2
The population mean is the mean of the entire population, the population variance is the variance of the entire population we should consider these values as fixed unknowns
for example we want to find the mean number of pages per book at barnes and noble we wish to find the population mean μ, but it is impractactical to count teh pages in every book instead we migh approximate μ using the sampling procedure
1. Randomly choose 5 books off the shelf
2. count the number of pages in each book
3. compute the mean of the 5 observations
sample size n = 5
suppose we get the following observations
201, 506, 58, 104, 99
its convenient to denote the individual observations as xi
x1 = 201, x2 = 506, ..., x5 = 99
we can compute the mean x̄ of our sample
x̄ = 1/n*Σ^n_i=1(xi)
= 1/5(201 + 506 + 58 + 104 + 99)
= 1/5 * 968
= 193.6
this is called an estimate of the population mean μ, we sometimes write μ (hat) = 193.6 to denote that the value 193.6 is an estimate of μ
its important to realize that our estimate x̄ depends entirely on this particular sample we'd get a different estimate for μ if we took a different sample

The sample mean
it is helpful to think of the observations of a particular sample
x1,x2, ..., xn
as a particular instance of data generated by a sequence of random variables
X1,X2, ..., Xn
Xi is a random variable that denotes the ith observation in a random sample its value changes when we conduct a new sample
xi is the value of the ith observation in a particular sample
Our sequence of random variables X1,X2,...,Xn typically has these properties
they are independent and identically distributed (I.I.D) meaning they are indpendent and have the same probability distribution they have the same distribution as the population
their mean is equal to the population mean
E(Xi) = μ, 1 <= i <= n
their variance is equal to the population variance
Var(Xi) = σ^2, 1 <= i <= n
the sequence of random variables X1,X2,...Xn with these properties as a random sample size n
in general if X1,X2,...,Xn is a random sample of size n then the sample mean is given by
X̄ = 1/n*Σ^n_i=1(Xi)
the sample mean X̄ is an estimator of the population mean μ
X1,X2,...Xn are random variables so is X̄. The probability distribution of X̄ is called the sampling distribution

Estimating a population mean from the sample mean
data is sampled from a population, compute an estimate for the population mean
6, 13, 7, 5, 14, 11, 7
X1,X2,...Xn is a sequence of random variables representing a random sample of size n drawn from a population mean μ the sample mean X̄
X̄ = 1/n*Σ^n_i=1(Xi)
X̄ is the mean value of X1,X2,...,Xn x̄ is the mean of a specific sample x1,x2...,xn
the sample mean X̄ is an estimator of the population mean μ
the value of μ(hat) = x̄ is an estimate of the population mean μ
= 1/7(6 + 13 + 7 + 5 + 14 + 11 + 7)
= 63/7
= 9

example:
compute an estimate for the population mean
3, 8, 10, 5, 7
1/5(3 + 8 + 10 + 5 + 7)
= 33/5 = 6.6

example:
compute an estimate for the population mean
-2, 5, -3, 10
1/4(-2 + 5 - 3 + 10)
10/4 = 5/2 = 2.5

The sample mean as an unbiased estimator
One important feature of X̄ is that its an unbiased estimator of μ the expected value of X̄ = μ
E[X̄] = μ
we can show X̄ is an unbiased estimator using properties of expectation
E[X̄] = E[1/n*Σ^n_i=1(Xi)]
= 1/n * E[Σ^n_i=1(Xi)]
= 1/n * E[X1 + X2 + ... + Xn]
= 1/n * (E[X1] + E[X2] + ... + E[Xn])
= 1/n * (μ + μ + ... + μ)
= 1/n * nμ
= μ
any estimate of x̄ of the population mean μ found by computing the mean of a sample is called an unbiased estimate of μ

The expected value of the sample mean
A sample X1,X2 of two metallic rings is drawn from a population, the population has rings of two different diameters 16.5mm and 18mm distributed in the ratio 5:1 calculate E[X̄]
to compute the population mean we can consider a population consisting of 5+1 = 6 rings only with the following diameters
16.5mm, 16.5mm, 16.5mm, 16.5mm, 16.5mm, 18mm
the population mean is
1/6(5*16.5 + 18)
= 1/6(82.5 + 18)
= 100.5/6
= 16.75mm
E[X̄] = μ = 16.75mm

example:
if X1,X2,...,X50 is a sample size n = 50 drawn from a population with mean μ = 30 and variance σ^2 = 9 what is E[X̄]?
E[X̄] = μ
E[X̄] = 30

example:
A sample X1,X2 of two nails is drawn from a population, the population has nails of two different lengths 6cm,12cm distributed in the ratio 3:1 calculate E[X̄]
1/4(3*6 + 12)
= 1/4(18 + 12)
= 1/4(30)
= 7.5

===================================================

The sample mean is an example of a statistic. A statistic is a random variable computed using values from a sample. Statistics are often used to estimate population parameters, although they also have other uses
The following statistic could be used as an estimator for the population variance σ^2
1/n*Σ^n_i=1(Xi - X̄)^2
an estimator for the population maximum
max(X1,X2,...,Xn)
an estimator for the population range
max(X1,X2,...,Xn) - min(X1,X2,...,Xn)
an estimator for the population median
median(X1,X2,...,Xn)
statistics cannot include any unknown population parameters
if the population mean μ in unknown then this is not a statistic
1/n*Σ^n_i=1(Xi - μ)^2
however if the population parameters μ and σ are both known then this is a statistic
Σ^n_i=1((Xi - μ)/σ)^2
statistics are described using observations from a random sample, they are random variables and have a probability distribution. The probability distribution of a statistic is called the sampling distribution of the statistic.

Calculating statistics
The weights in stones of five randomly selected 24 year olds
12.5, 11.7, 13.2, 12.8, 12.1
calculate the value of the statistic Σ^n_i=1(Xi^2) for this particular sample
Σ^n_i=1(xi^2) = (12.5)^2 + (11.7)^2 + (13.2)^2 + (12.8)^2 + (12.1)^2
= 156.25 + 136.89 + 174.24 + 163.84 + 146.41
= 777.63

example:
25.2, 24.8, 28.9, 27.5, 28.9
calculate the value of the statistic max(X1,X2,...,Xn) - min(X1,X2,...,Xn)
28.9 - 24.8 = 4.1

example:
1.34, 1.24, 1.42, 1.28, 1.39, 1.44
Σ^n_i=1(Xi)
1.34 + 1.24 + 1.42 + 1.28 + 1.39 + 1.44
= 8.11

===================================================

Lets now find the variance of the sampling distribution of X̄ using the properties of variance for sums of independent variables
Var[X̄] = Var[1/n*Σ^n_i=1(Xi)]
= (1/n)^2 * Var[Σ^n_i=1(Xi)]
= 1/(n^2) * Var[X1 + X2 + ... + Xn]
= 1/(n^2) * (Var[X1] + Var[X2] + ... + Var[Xn])
= 1/(n^2) * (σ^2 + σ^2 + ... + σ^2)
= 1/(n^2) * nσ^2
= σ^2/n
Var[X̄] = σ^2/n
we dont yet know the sampling distribution of X̄. What we do know is that whatever the sampling distribution of X̄ is it has mean μ and variance σ^2/n

finding the variance of a sample mean
A sample X1,X2 of two pills is drawn from a population the population has pills of two different active ingredient concentrations 30mg/ml and 15mg/ml distributed in the ratio 1:2 calculate Var[X̄]
E[X̄] = μ, Var[X̄] = σ^2/n
to compute the population mean and variance, we can consider a population consisting of 1 + 2 = 3 pill concentrations
30mg/ml + 15mg/ml + 15mg/ml
μ = 1/3(30 + 2*15)
= 60/3
= 20mg/ml
variance
σ^2 = 1/3*Σ_i(xi^2 - μ^2)
= 1/3(30^2 + 2*15^2) - 20^2
= 1/3(900 + 450) - 400
= 1/3(1350) - 400
= 450 - 400
= 50(mg/ml)^2
sample size n = 2
Var[X̄] = σ^2/n = 50/2 = 25(mg/ml)^2

example:
if X1,X2,...,X100 is a sample size n = 100 mean μ = 30 and variance σ^2 = 9 calculate the value of Var[X̄]
9/100 = 0.09

example:
a sample X1,X2 of two nails is drawn from a population, the population has nails of two different lengths 6cm and 12cm distributed in the ratio 3:1 calculate Var[X̄]
E[X̄] = 1/4(6^2*3 + 12^2) - 7.5^2
= 1/4(108 + 144) - 7.5^2
= 63 - 56.25
= 6.75/2
= 3.375cm^2

The standard error
the standard deviation of the sample mean is called the standard error of the sample mean and is denoted SE[X̄]
SE[X̄] = sqrt(Var[X̄])
if we have a random sample of size n drawn from a population with mean μ and variance σ^2 then the standard error is
SE[X̄] = sqrt(σ^2/n) = σ/sqrt(n)
the population standard deviation σ is often unknown whenever we draw a random sample from a population, we can usually estimate its value by replacing σ with a suitable estimate say s
SE[X̄] = s/sqrt(n)

finding the standard error
if X1,X2,...,X200 is a sample size n = 200 drawn from a population with mean μ = 23 and variance σ^2 = 4 calculate the standard error of X̄
Var[X̄] = 4/200
= 0.02
SE[X̄] = sqrt(0.02) ~= 0.14

example:
X1,X2,...,X100 sample of size n = 100 with mean μ = 30 and variance σ^2 = 9 calculate standard error of X̄
9/100 = sqrt(0.09)
SE[X̄] = 0.3

example:
X1,X2,X3 of three nails is drawn from a population, the population has nails of two different lengths, 5cm and 10cm distributed in the ratio 4:1 calculate the standard error of X̄
E[X̄] = 1/5(4*5 + 10)
= 1/5(30)
= 6
σ^2 = 1/5(4*5^2 + 10^2) - 6^2
= 40 - 36
= 4cm^2
Var[X̄] = σ^2/n = 4/3cm^2
SE[X̄] = sqrt(4/3) ~= 1.15cm

The sample mean and large samples
As the sample size n becomes larger and larger the variance and standard error of X̄ become smaller and smaller it is easy to see that n -> ∞
Var[X̄] = σ^2/n -> 0
SE[X̄] = σ/sqrt(n) -> 0
when the sample size n is large, there is less variance in the sampling distribution of X̄ the larger the sample the more likely it is that X̄ will give good estimates for μ the individual sample elements do not have this property since Var[Xi] = σ^2
the sample mean X̄ becomes a better estimator for the corresponding population mean μ as the sample size n increases

calculating an appropiate sample size
X1,X2,...,Xn of n bananas is drawn from a population the population has bananas of two different weights 1.5lbs and 2lb distributed 2:3 determine the smallest sample size required to give a SE fo less than 0.02lb
E[X̄] = μ
Var[X̄] = σ^2/n
SE[X̄] = sqrt(Var[X̄]) = σ/sqrt(n)
population consisting of 2+3 = 5
1.5lb, 1.5lb, 2lb, 2lb, 2lb
population mean
= 1/5(2*1.5 + 3*2)
= 1/5(3+6)
= 9/5
= 1.8lb
variance
= 1/5(2*1.5^2 + 3*2^2) - 1.8^2
= 1/5(16.5) - 3.24
= 3.3 - 3.24
= 0.06lb^2
SD = σ = sqrt(0.06)
SE[X̄] = sqrt(0.06/n)
we require that the standard error is less than 0.02lb
sqrt(0.06/n) < 0.02
sqrt(0.06)/sqrt(n) < 0.02
sqrt(n) > sqrt(0.06)/0.02
sqrt(n) > sqrt(0.06/0.02^2)
sqrt(n) > sqrt(0.06/0.0004)
sqrt(n) > sqrt(150)
n > 150
smallest sample size is n = 151

example:
X1,X2,...,Xn is a sample size n drawn from a population with mean μ = 12 and variance σ^2 = 16 determine the smallest sample size required so that the SE of the mean is less than 0.1
SD = σ = sqrt(16) = 4
4/sqrt(n) < 0.1
sqrt(n) > 4/0.1
sqrt(n) > 40
n > 40^2
n > 1600
smallest sample size is n = 1601

example:
X1,X2,...,Xn population of bartenders with two different working hours 38 h/week and 40h/week distributed 3:1 determine the smallest sample size required so that the standard error of the mean is less than 0.5 h/week
population mean μ
= 1/4(38*3 + 40)
= 1/4(154)
= 38.5
variance
= 1/4(38^2*3 + 40^2) - 38.5^2
= 1/4(5932) - 38.5^2
= 1483 - 1482.25
= 0.75
sqrt(0.75/n) < 0.5
sqrt(0.75)/sqrt(n) < 0.5
sqrt(n) > sqrt(0.75)/0.5
sqrt(n) > sqrt(0.75/0.5^2)
sqrt(n) > sqrt(0.75/0.25)
sqrt(n) > sqrt(3)
n > 3
smallest sample size n = 4

===================================================

From the definition of the population variance you might expect
1/n*Σ^n_i=1(Xi - X̄)^2
is an unbiased estimator for σ^2, it can be shown that it is a biased estimator of σ^2
E[1/n*Σ^n_i=1(Xi - X̄)^2] != σ^2
To compute an unbiased estimate of σ^2 we use the sample variance
S^2 = 1/n-1*Σ^n_i=1(Xi - X̄)^2
Instead of dividing by n (as with our original biased estimator) we instead divide by n - 1 this is referred to as Bessel's correction it corrects the bias of the original estimator
we should think of S^2 as a random variable whose value varies according to the particular sample under consideration
since S^2 is a random variable it has a sampling distribution (probility distribution)
An alternative formula for a sample variance thats often more convenient in practice:
S^2 = n/n-1[X̄^2 - (X̄)^2]

Computing an estimate of the population variance
A random sample of size n = 81 is conducted from a population
Σ^81_i=1(xi - x̄)^2 = 180
each xi is a sample observation, compute an unbiased estimate for the population standard deviation
X1,X2,...Xn is a sequence of random variables representing a random sample of size n drawn from a population with a population mean μ and population variance σ^2 the sample variance S^2
S^2 = 1/n-1 Σ^n_i=1(Xi - X̄)^2 = n/n-1[X̄^2 - (X̄)^2]
X̄ is the sample mean
the sample variance S^2 is an unbiased esitmator of the population variance σ^2
σ^2 = s^2 denotes an unbiased estimate of σ^2 thats computed from the sample x1,x2,...,xn
Σ^81_i=1(xi - x̄)^2 = 180 and n = 81
= 1/n-1 Σ^n_i=1(xi - x̄)^2
= (1/81 - 1) * 180
= (1/80) * 180
= 2.25
an unbiased estimate of the population variance is σ^2 = 2.25 we take the square root to compute an unbiased estimate of the standard deviation
σ = sqrt(2.25) = 1.5

example:
sample size n = 50
Σ^50_i=1(xi - x̄)^2 = 1176
compute an unbiased estimate of the variance
= (1/49) * 1176
unbiased estimate = 24

compute an unbiased estimate of the standard deviation
unbiased 
sample size n = 100
Σ^100_i=1(xi - x̄)^2 = 1584
= 1/99 * 1584
σ^2 = 16
σ = sqrt(16) = 4

Computing an estimate of the population variance using the alternative formula
x1,x2,...,x9 is a random sample size n = 9 from a population x̄^2 - (x̄)^2 = 4
compute an unbiased estimate of the population variance
= n/n - 1[x̄^2 - (x̄)^2]
= 9/9-1 * 4
= 36/8
= 4.5

example:
x1,x2,...,x11 sample size 11 x̄^2 - (x̄)^2 = 7
compute an unbiased estimate of the population variance
= 11/10 * 7
= 77/10
= 7.7

example:
x1,x2,...,x6 sample size n = 6
x̄^2 - (x̄)^2 = 3
compute an unbiased esitmate of the population variance
= 6/5 * 3
= 18/5
= 3.6

Estimating the population variance from sample data
compute an unbiased estimate of the population variance
5, 3, 6, 4, 7
x̄ = 1/5(5 + 3 + 6 + 4 + 7)
= 25/5
= 5
x̄^2 = 1/5(5^2 + 3^2 + 6^2 + 4^2 + 7^2)
= 135/5
= 27
x̄^2 - (x̄)^2 = 27 - 5^2
= 2
σ^2 = s^2
= 5/5-1 * 2
= 2.5
unbiased estimate of population variance 2.5

example:
compute an unbiased estimate of the population variance
4, 8, 10, 6, 7
x̄ = 1/5(4 + 8 + 10 + 6 + 7)
= 1/5(35)
= 7
x̄^2 = 1/5(4^2 + 8^2 + 10^2 + 6^2 + 7^2)
= 265/5
= 53
x̄^2 - (x̄)^2 = 53 - 49
= 4
σ^2 = s^2
= 5/5-1 * 4
= 20/4
= 5

example:
compute an unbiased estimate of the population variance
-10, 20, -30, 40
x̄ = 1/4(-10 + 20 - 30 + 40)
= 1/4(20)
= 5
x̄^2 = 1/4(-10^2 + 20^2 - 30^2 + 40^2)
= 1/4(3000)
= 750
x̄^2 - (x̄)^2 = 750 - 5^2
= 725
σ^2 = s^2
4/3 * 725
= 2900/3
~= 966

Proof of the alternative formula
S^2 = n/n-1[X̄^2 - (X̄)^2]
definition
S^2 = 1/n-1 * Σ^n_i=1(X̄i - X̄)^2
expaning paranetheses and distributing
S^2 = 1/n-1 Σ^n_i=1(X̄i^2 - 2XiX̄ + (X̄)^2)
= 1/n-1[Σ^n_i=1(X̄i^2) - Σ^n_i=1(2XiX̄) + Σ^n_i=1(X̄)^2)]
= 1/n-1[Σ^n_i=1(X̄i^2) - 2Σ^n_i=1(XiX̄) + (X̄)^2*Σ^n_i=1(1))]
considering each sum separately
Σ^n_i=1(X̄i^2) = n * X̄^2 from the definition of the mean of X^2
Σ^n_i=1(Xi) = n * X̄ from the definition of the mean of X
Σ^n_i=1(1) = 1 + 1 + ... + 1 = n (n times)
S^2 = 1/n-1[Σ^n_i=1(X̄i^2) - 2Σ^n_i=1(XiX̄) + (X̄)^2*Σ^n_i=1(1))]
= 1/n-1[n * X̄^2 - 2X̄*n*X̄ + (X̄)^2*n]
= n/n-1[X̄^2 - 2(X̄)^2 + (X̄)^2]
= n/n-1[X̄^2 - (X̄)^2]

Proof that the sample variance is an unbiased estimator
S^2 is an unbiased estimator of σ^2
E[S^2] = σ^2
we'll prove
E[X̄^2 - (X̄)^2] = n-1/n * σ^2
X̄^2 - (X̄)^2 is the variance sample
X̄^2 - (X̄)^2 = 1/n Σ^n_i=1(X̄i - X̄)^2
the variance of the sample is not the same as the sample variance S^2
we start by computing the expected difference between σ^2 and the variance of the sample, simplify
σ^2 - (X̄^2 - (X̄)^2)
= 1/n Σ^n_i=1(Xi - μ)^2 - 1/n Σ^n_i=1(Xi - X̄)^2
= 1/n Σ^n_i=1[(Xi - μ)^2 - (Xi - X̄)^2]
= 1/n Σ^n_i=1[(Xi^2 - 2μXi + μ^2) - (Xi^2 - 2X̄Xi + (X̄)^2)]
= 1/n Σ^n_i=1[μ^2 - (X̄)^2 + 2X̄Xi - 2μXi]
compute the expectation, E[Xi] = X̄ and Var[X̄] = σ^2/n
E[σ^2 - (X̄^2 - (X̄)^2)]
= E[1/n Σ^n_i=1(μ^2 - (X̄)^2 + 2X̄Xi - 2μXi)]
= 1/n Σ^n_i=1(μ^2 - (X̄)^2 + 2X̄E[Xi] - 2μE[Xi])
= 1/n Σ^n_i=1(μ^2 - (X̄)^2 + 2(X̄)^2 - 2μX̄)
= 1/n Σ^n_i=1((X̄)^2 - 2X̄μ + μ^2)
= 1/n Σ^n_i=1(X̄ - μ)^2
= Var[X̄]
= σ^2/n

E[X̄^2 - (X̄)^2] = E[σ^2 - (X̄^2 - (X̄)^2)]
= E[σ^2] - E[σ^2 - X̄^2 - (X̄)^2]
= σ^2 - σ^2/n
= n-1/n * σ^2

E[S^2] = E[n-1/n[X̄^2 - (X̄)^2]]
= n/n-1 * E[X̄^2 - (X̄)^2]]
= n/n-1 * n-1/n*σ^2
= σ^2

===================================================

Sample means from normal populations
X1,X2,...Xn be a random sample of size n drawn from a normal population N(μ,σ^2)
X1,X2,...Xn ~ N(μ,σ^2)
sampling distribution of the sample mean
X̄ = 1/n Σ^n_i=1(Xi)
The sum of n independent and identically distributed normal random variables is normally distributed
Y = Σ^n_i=1(Xi)
a normally distributed random variable scaled by a constant factor is normally distributed
X̄ = 1/n * Y
expected value of the sample mean equals population mean
E[X̄] = μ
variance of sample mean
Var[X̄] = σ^2/n
altogether
X̄ ~ N(μ, σ^2/n)
sample mean X̄ is normally distributed with mean μ and variance σ^2/n

Stating the distribution of the sample mean
X1,X2,...,X28 ~ N(8,14^2) is a random sample size of n = 28 from a normal population what is the distribution of the sample mean X̄?
X̄ ~ N(μ, σ^2), 1 <= i <= n
sample mean X̄ has the distribution
X̄ ~ N(μ, σ^2/n)
n = 28, μ = 8, σ = 14
distribution of the sample mean X̄
X̄ ~ N(8, 14^2/28)
~ N(8,7)

example:
X1,X2,...,X50 ~ N(5,10^2) random sample size n = 50 what is the distribution of the sample mean X̄?
~ N(5,10^2/50) ~ N(5,2)

example:
X1,X2,...,X100 ~ N(16,20^2) sample size n = 100 what is the distribution of the sample mean X̄?
~ N(16,20^2/100) ~ N(16,4)

Calculating a probability involving sample mean
X1,X2,...,X100 ~ N(-4,20^2) is a random sample of size 100 from a normal population calculate P(-4.3 < X̄ < -3.9)
sample distribution of the sample mean X̄ is
X̄ ~ N(-4, 20^2/100)
~ N(-4,4)
tansform X into a standard normal random variable by z-scoring
P(-4.3 < X̄ < -3.9)
= P((-4.3 - (-4))/sqrt(4) < Z < (-3.9 - (-4))/sqrt(4))
= P(-0.15 < Z < 0.05)
= Φ(0.05) - Φ(-0.15)
Φ(0.05) = 0.5199
Φ(-0.15) = 0.4404
0.5199 - 0.4404
= 0.0795

example:
X1,X2,...,X50 ~ N(5,10^2) 
sample size of 50 calculate P(4.8 < X̄ < 5.2)
X̄ ~ N(5, 10^2/50) ~ N(5,2)
= P((4.8 - 5)/sqrt(2) < Z < (5.2 - 5)/sqrt(2))
= P(-0.14 < X̄ < 0.14)
Φ(0.14) - Φ(-0.14)
Φ(0.14) = 0.5557
symmetry of normal distribution
Φ(-0.14) = 1 - Φ(0.14)
= 1 - 0.5557
= 0.4443
= 0.5557 - 0.4443
= 0.1114

example:
X1,X2,...,X36 ~ N(0,18^2) is a random sample size of 36
calculate P(|X̄| > 0.8)
~ N(0,18^2/36) ~ N(0,9)
= 1 - P(|X̄| < 0.8)
= 1 - P(-0.8 < X̄ < 0.8)
= 1 - P(-(0.8 - 0)/sqrt(9) < Z < (0.8 - 0)/sqrt(9))
= 1 - P(-0.27 < Z < 0.27)
= 1 - (Φ(0.27) - Φ(-0.27))
= 1 + Φ(0.27) - Φ(-0.27)
Φ(0.27) = 0.6064
Φ(-0.27) = 1 - 0.6064
= 0.3936
= 1 + 0.3936 - 0.6064
= 0.7872

Calculating a probability involving a sample mean in context
blood pressure of adult women in a population that is normally distributed with mean 75mm and SD 10mm. 10 women are selected at random what is the probability that the blod pressure mean for this sample wil be less than 70mm?
X̄ ~ N(75, 10^2/10) ~ N(75,10)
P(X̄ < 70)
= P(Z < (70 - 75)/sqrt(10))
~= P(Z < -1.58)
= Φ(-1.58)
= 0.0571

example:
IQ scores are normally distributed with a mean of 100 and SD 15, 10 people are selected randomly. What is the probability that the mean score for this sample will be greater than 105?
X̄ ~ N(100, 15^2/10) ~ N(100,22.5)
P(X̄ > 105)
= P(Z > (105 - 100)/sqrt(22.5))
= 1 - Φ(1.05)
= 1 - 0.8531
= 0.1469

example:
weights of a particular breed of duck are normally distributed with a mean of 7kg and SD 1kg, 4 ducks are randomly selected. What is the probability that the mean for this sample will be more than 6.8kg but less than 7kg?
P(6.8 < X̄ < 7)
X̄ ~ N(7, 1^2/4) ~ N(7,0.25)
= P((6.8 - 7)/sqrt(0.25) < Z < (7 - 7)/sqrt(0.25))
= P(-0.4 < Z < 0)
= Φ(0.0) - Φ(-0.4)
= 0.5000 - 0.3446
= 0.1554

===================================================

The central limit theorem
if X1,X2,...,Xn is a random sample of size n drawn from a normal population N(μ, σ^2) then the sample mean X̄ is normally distributed with the sampling distribution
X̄ = 1/n Σ^n_i=1(Xi) ~ N(μ, σ^2/n)
The sampling distribution X̄ depends on the population distribution, no general result exists that tells us how X̄ is distributed for an arbitrary population distribution.
An important result, known as the central limit theorem, tells us that when the sample size n is large, the sample mean X̄ is approximately normally distributed the sampling distribution of X̄ for large n does not depend on the population distribution
theorem:
Suppose that X1,X2,...,Xn is a random sample of size n from a population with a population mean μ and population SD σ. THe centeral limit theorem (CLT) states that for sufficiently large n, the distribution of the sample mean X̄ can be approximated as
X̄ ~ N(μ, σ^2/n)
in other words as the sample size increases the distribution of the sample mean is approximately normal

We assume that X1,X2,...,Xn are independent and identically distributed and they can have any distribution (discrete or continuous)
the theorem is valid for sufficiently large n, typically n >= 30 is assumed to be sufficiently large, although this does vary in general the larger the better
CLT assumes that μ and σ both exist, this is not true for every probability distribution (e.g. the Cauchy distribution)

Consider a random variable X that follows a binomial distribution where
X ~ B(20, 0.1) the parameters are m = 20, p = 0.1 lets start by calculating the mean and the variance of X
mean μ is
μ = E[X]
= mp
= 20*0.1
= 2
variance σ^2
σ^2 = Var[X]
= mp(1 - p)
= 20 * 0.1 * 0.9
= 1.8
To understand the sampling distribution of X̄ for this population suppose we conduct the following experiment
1. Pick a value for the sample size n
2. Using a computer randomly generate 1000 sample size n drawn from our binomial population
3. Calculate the sample mean for each sample
4. Create a histogram of the sample means to visualize the approximate sampling distribution
5. repeat this process for increasing values of n
lets do this procedure for sample sizes of 2, 4 and 9
lets consider sample size n = 2
E[X̄] = 2, Var[X̄] = σ^2/n = 1.8/2 = 0.9
next generating 1000 sample of size n = 2 and calculating the corresponding sample mean for each sample, when visualizing the results (histogram) the sample mean does not closely resemble the normal distribution
n = 4
E[X̄] = 2, Var[X̄] = σ^2/n = 1.8/4 = 0.45
again 1000 samples of size n = 4, the visualization of this is closer to normal distribution than n = 2 case
n = 9
E[X̄] = 2, Var[X̄] = σ^2/n = 1.8/9 = 0.2
1000 samples of size n = 9, this is much closer to what appears to be a normal distribution compared to the n=2, and n=4 cases
As the sample size n increases the histograms become more and more similar to their corresponding normal distribution, and the standard error of the sample mean becomes smaller and smaller.

Finding an approximate probability using the central limit theorem
X1,X2,...,X120 be a random sample of size n = 120 from a population with a population mean μ = 100 and population SD σ = 60 find an approximation for the probability that the sample mean is between 102 and 105
n = 120, μ = 100, σ = 60
~ N(100, 60^2/120)
~ N(100, 30)
P(102 < X̄ < 105) = P((102 - 100)/sqrt(30) < Z < (105 - 100)/sqrt(30))
= P(2/sqrt(30) < Z < 5/sqrt(30))
~= P(0.37 < Z < 0.91)
= P(Z < 0.91) - P(Z < 0.37)
= Φ(0.91) - Φ(0.37)
= 0.8186 - 0.6443
= 0.1743

example:
X1,X2,...,X100 be a random sample of size n = 100 from a population mean μ = 500 and population SD σ = 80 find an approximation for the probability that the sample mean is between 490 and 510
n = 100, μ = 500, σ = 80
~ N(500, 80^2/100) ~ N(500,64)
P(490 < X̄ < 510) = P((490 - 500)/8 < Z < (510 - 500)/8)
P(-1.25 < Z < 1.25)
= Φ(1.25) - Φ(-1.25)
Φ(-1.25) = 1 - Φ(1.25)
= 0.8944 - 0.1056
= 0.7888

example:
X1,X2,...,X176 be a random sample of size n = 176 from a population with a population mean μ = 8 and population SD σ = 88 find an approximation for P(|X̄| > 4)
n = 176, μ = 8, σ = 88
~ N(8,88^2/176) ~ N(8,44)
= P(|X̄| < 4) = P(X̄ < -4) + P(X̄ > 4)
= P(Z < (-4 - 8)/sqrt(44)) + P(Z > (4 - 8)/sqrt(44))
~= P(Z < -1.81) + P(Z > -0.60)
= P(Z < -1.81) + (1 - P(Z <= -0.60))
= 1 + Φ(-1.81) - Φ(-0.60)
= 1 + 0.0351 - 0.2743

using the CLT with a population whose probability is discrete
x   | -3| -1|  1|  3|
f(x)|0.4|0.1|0.1|0.4|
X1,X2,...,X185 be a random sample of size n = 185 from a population with the probability mass function, find the approximation in terms of Φ(z) for P(|X̄| > 0.1)
Φ(z) is the cumulative distribution function for the standard normal distribution
n = 185
population mean
μ = E[X]
= Σ^n_i=1(xi * f(xi))
= -3 * 0.4 + (-1) * 0.1 + 1 * 0.1 + 3 * 0.4
= -1.2 - 0.1 + 0.1 + 1.2
= 0
population variance
σ^2 = Var[X]
= E[X^2] - E[X]^2
= ((-3)^2 * 0.4 + (-1)^2 * 0.1 + 1^2 * 0.1 + 3^2 * 0.4) - 0^2
= (3.6 + 0.1 + 0.1 + 3.6) - 0
= 7.4
by the CLT we have that the distribution of the sample mean
X̄ ~ N(μ, σ^2/n)
~ N(0, 7.4/185)
P(|X̄| > 0.1) = P(X̄ < -0.1) + P(X̄ > 0.1)
~= P(Z < (-0.1 - 0)/sqrt(0.04) + P(Z > (0.1 - 0)/sqrt(0.04)))
= P(Z < -0.5) + P(Z > 0.5)
= P(Z < -0.5) + 1 - P(Z < 0.5)
= 1 + Φ(-0.5) - Φ(0.5)
(Φ(-0.5) = 1 - Φ(0.5))
P(|X̄| > 0.1) = 1 + (1 - Φ(-0.5)) - Φ(0.5)
= 2 - 2Φ(0.5)
= 2(1 - Φ(0.5))

example:
x   |  1|  2|  3|  4|
f(x)|0.5|0.2|0.1|0.2|
X1,X2,...,X50 be a random sample of size n = 50, probability sample mean is greater than 2.2
n = 50
μ = 1*0.5 + 2*0.2 + 3*0.1 + 4*0.2
= 2
σ^2 = (1^2*0.5 + 2^2*0.2 + 3^2*0.1 + 4^2*0.2) - 2^2
= 5.4 - 4
= 1.4
~ N(2, 1.4/50) ~ N(2,0.028)
P(X̄ > 2.2)
~= P(Z > (2.2 - 2)/sqrt(0.028))
= P(Z > 1.20)
= 1 - Φ(1.20)

example:
x   | -2| -1|  0|  2|
f(x)|0.3|0.2|0.1|0.4|
X1,X2,...,X30 be a random sample of size n = 30, find an approximation for P(|X̄| > 0.2) = P(X̄ < -0.2) + P(X̄ > 0.2)
n = 30
μ = (-2)*0.3 + (-1)*0.2 + 0*0.1 + 2*0.4
= 0
σ^2 = ((-2)^2*0.3 + (-1)^2*0.2 + 0^2*0.1 + 2^2*0.4) - (0)^2
= 3 - 0
= 3
~ N(0, 3/30) ~ N(0,0.1)
~= P(Z < (-0.2 - 0)/sqrt(0.1) + P(Z > (0.2 - 0)/sqrt(0.1)))
~= P(Z < -0.63) + P(Z > 0.63)
= P(Z < -0.63) + 1 - P(Z < 0.63)
= 1 + Φ(-0.63) - Φ(0.63)
Φ(0.63) = 0.2643
Φ(0.63) = 1 - Φ(-0.63)
= 2Φ(0.63)
= 2 * 0.2643
= 0.5286

Using the CLT with a population is continuous
X1,X2,...,X100 be a random sample of size n = 100, with probability density function
f(x) = {
	2/9(x), 0 <= x <= 3
	0,      otherwise
}
given that the population variance σ^2 = 0.5 calculate P(X̄ > 1.9)
μ = E[X]
∫^∞_-∞ xf(x) dx
= ∫^3_0 x * 2/9(x) dx
= ∫^3_0 2/9(x^2) dx
= [2x^3/27]|_0-3
= 2
σ^2 = 0.5
~ N(2, 0.5/100) ~ N(2, 0.005)
= P(Z > (1.9 - 2)/sqrt(0.005))
~= P(Z > -1.41)
= 1 - P(Z <= -1.41)
= 1 - Φ(-1.41)
= 1 - 0.0793
= 0.9207

example:
X1,X2,...,X20 be a random sample of size n = 20, with probability density function
f(x) = {
	3/2(x^2), -1 <= x <= 1
	0,        otherwise
}
given that the population variance σ^2 = 0.6 calculate P(0 < X̄ < 0.2)
= ∫^1_-1 x * 3/2(x^2) dx
= ∫^1_-1 3/2(x^3) dx
= [3x^4/8]|_-1-1
= ((3/8) - (3/8))
= 0
~ N(0, 0.6/20) ~ N(0,0.03)
P((0 - 0)/sqrt(0.03) < Z < (0.2 - 0)/sqrt(0.03))
~= P(0 < Z < 1.15)
= P(Z < 1.15) - P(Z < 0)
= Φ(1.15) - Φ(0)
= Φ(1.15) = 0.8749
= Φ(0) = 0.5
= 0.8749 - 0.5
= 0.3749

example:
X1,X2,...,X25 be a random sample of size n = 25, with probability density function
f(x) = {
	3/8(x^2), 0 <= x <= 2
	0,        otherwise
}
given the population variance σ^2 = 0.15 calculate P(X̄ > 1.6)
= ∫^2_0 x * 3/8(x^2) dx
= ∫^2_0 3/8(x^3) dx
= [3x^4/32]|_0-2
= (48/32 - (0))
= 24/16 = 12/8 = 6/4 = 3/2
= 1.5
~ N(1.5, 0.15/25) ~ N(1.5,0.006)
P(Z > (1.6 - 1.5)/sqrt(0.006))
~= P(Z > 1.29)
= 1 - P(Z < 1.29)
= 1 - Φ(1.29)
= 1 - 0.9015
= 0.0985

Sums of I.I.D. Random variables
Assume that X1,X2,...,Xn is a random sample of size n from a population with a population mean μ and population SD σ the central limit theorem states that for sufficiently large n
X̄ ~= N(μ,σ^2/n)
an important consequence of the central limit theorem is that if X1,X2,...,Xn are I.I.D
X = Σ^n_i=1(Xi ~= N(nμ,nσ^2))
in other words a sum of I.I.D random variables is approximately normally distributed
if: X̄ = 1/n Σ^n_i=1(Xi ~= N(μ,σ^2/n))
then the random variable: X = nX̄ = X̄ + X̄ + ... + X̄ (n times)
is a sum of n (approximately) normally distributed random variables and is normally distributed, the mean and variance of X are
E[X] = n*μ, Var[X] = n^2 * σ^2/n = nσ^2
writing this in terms of X̄ we have
nX̄ ~= N(nμ,nσ^2)

Equivalent forms of the Central limit theorem
We can rewrite the central limit in several different ways
One way of restating the central limit theorem
X̄ - μ ~= N(0,σ^2/n)
this tells us that the deviation of X̄ from the mean μ is (approximately) normally distributed with a mean of zero and a variance thats the same as X̄
we can also rewrite CLT as
(X̄ - μ)/(σ/sqrt(n)) ~= N(0,1)
this statement tells us that z-scoring the sample mean gives a random variable that (approximately) follows a standard normal distribution
we saw
nX̄ ~= N(nμ,nσ^2)
z-score this result we get
(nX̄ - nμ)/sqrt(nσ^2) = n(X̄ - μ)/sqrt(n)*σ
= sqrt(n)(X̄ - μ)/σ
which means that we can express the central limit theorem in the form
sqrt(n)(X̄ - μ)/σ ~= N(0,1)

===================================================

Sampling proportions from finite populations
Suppose that a business is about to elect a new CEO, we're interested in determining the proportion p of a company's employees that will vote for "candidate A"
if a company has N = 50 employees and 30 of them will vote for candidate A then the proportion p is
p = 30/50 = 0.6
60% of the company's employees will vote for candidate A
N is the population size
p is the population proportion
the number of employees that will vote for candidate A is
Np = 50*0.6 = 30
Lets start by modeling the response from each member of the population as a random variable Xi defined by
Xi = {
	1, ith member of the population will vote for candidate A
	0, otherwise
}
for i = 1,...,50
Calculating the probability that a randomly selected member of the population will vote for candidate A is
P(Xi = 1) = # of members vote for candidate A/population size
= Np/N
= 30/50
= 0.6
its important to note that the Xi's are dependent
P(X2 = 1|X1 = 1) != P(X2 = 1)
to see why note P(X2 = 1) = 0.6 as before
P(X2 = 1|X1 = 1)
= (# of members vote for candidate A) - 1/population size - 1
= (Np - 1)/(N - 1)
= (50*0.6 - 1)/(50 - 1)
= (30 - 1)/49
= 29/49
~= 0.592
!= P(X2 = 1)
we know that the first member will vote for canadidate A so to compute the conditional probability that the second member will also vote for candidate A we consider a reduced population with N-1 = 49 members of which only 30 - 1 = 29 will vote for candidate A

finding aa conditional probability given a population proportion
Apple decided to elect a new board member, there are 50 workers and 60% of this worker population will vote for Tim Cook let the random variable Xi be
Xi = {
	1, ith member of the population will vote for Tim Cook
	0, otherwise
}
for i = 1,...,50 find P(X2 = 0|X1 = 0)
we have a population size N = 50 and p = 0.6 represents the proportion of the population that will vote for Tim Cook
The number of members that will vote for Tim Cook:
Np = 50(0.6) = 30
members that will not vote for Tim Cook:
N(1 - p) = 50(1 - 0.6) = 20
two members of the population at random, we need to find P(X2 = 0|X1 = 0) the probability that the second member will not vote for Tim Cook given that the first member will also not vote for Tim Cook
if first member does not vote for Tim Cook
N - 1 = 50 - 1 = 49 members remaining
N(1 - p) - 1 = 19 members remaining that will not vote for Tim Cook
P(X2 = 0|X1 = 0) = (N(1 - p) - 1)/(N - 1) = 19/49

example:
we have a population size N = 20 where 55% of the population has a particular gene
Xi = {
	1, ith member of the population has the gene
	0, otherwise
}
for i = 1,...,20 find P(X2 = 1|X1 = 1)
0.55(20) = 11 has the gene
the probability of the second person having the gene given the first person having it: 10/19

example:
Google decided to elect a new board member, there are 20 workers and 55% of this worker population will vote for Sergey Brin
Xi = {
	1, ith member that will vote for Sergey Brin
	0, otherwise
}
for i = 1,...,20. Find P(X2 = 1|X1 = 0)
0.55(20) = 11 will vote for Sergey Brin
P(X2 = 1|X1 = 0) = Np/N-1 = 11/19

Independence in large populations
population of size N = 1000 of which teh proportion p = 0.5 has a particular genetic
Xi = {
	1, ith member of the population has the genetic
	0, otherwise
}
for i = 1,...,1000
Xi's are dependent
this time since the population size N = 1000 is large we may approximate that the Xi's are independent
to see why we first note
P(X2 = 1) = Np/N = 0.5
computing P(X2 = 1|X1 = 1)
= (Np - 1)/(N - 1)
= (1000*0.5 - 1)/)(1000 - 1)
= 499/999
~= 0.5
P(X2 = 1|X1 = 1) ~= P(X2 = 1)
X1 and X2 are (approximately) independent

The number of sample elements with a genetic
Xi = {
	1, ith member of the sample has the genetic
	0, otherwise
}
for i = 1,...,n
Xi's can be modeled as mutually independent random variables provided that the population size N is significantly larger than the sample size n this typically means that the sample size should be no larger than 5% of the population size
The population size is much larger than the sample size is true in many cases. For example, the users using the Chrome browser consists of millions of people yet a typical sample from this population might consist of only a few thousand users.
X = Σ^n_i=1(Xi)
where Xi ~ Bernoulli(p)
since the Xi's take the value 1 if the ith element has the genetic or 0 if the ith element doesn't have the genetic, the statistic X can be used to count the number of elements with the genetic. X represents the number of sample elements with the genetic
Each Xi can be modeled as a Bernoulli random variable Xi ~ Bernoulli(p)
We're assuming N >> n it follows that X1,X2,...,Xn are (approximately) independent and identically distributed (I.I.D) Bernoulli random variables
A sum of n I.I.D. Bernoulli random variables with parameter p is a binomial random variable B(n,p)
process:
Xi ~ Bernoulli(p)
		↓
N >> n
   		↓
X1,X2,...,Xn ~= I.I.D
		↓
X = Σ^n_i=1(Xi ~= B(n,p))
using the formulas for the mean and variance of Binomial random variable we have the following approximations
E[X] = np, Var[X] = np(1 - p)

Properties of sums of bernoulli random variables
random sample of size n = 360 from a population where 35% of the population has a particular genetic
Xi = {
	1, ith member of the sample has the genetic
	0, otherwise
}
where i = 1,...,360
X = Σ^360_i=1(Xi)
find approximate values of E[X] and Var[X]
hint: we may assume that the population size is significantly larger than the sample size
provided that N >> n the random variables Xi can be considered independent and identically distributed
Xi ~ Bernoulli(p) 1 <= i <= n
where p is the proportion of the population that has the genetic
X = Σ^n_i=1(Xi)
can be approximated as a binomial random variable X ~= B(n,p)
E[X] = np, Var[X] = np(1 - p)
p = 35% = 0.35, n = 360
X ~= B(360,0.35)
mean and variance
E[X] = np
= 360*0.35
= 126
Var[X] = np(1 - p)
= 360*0.35 * (1 - 0.35)
= 81.9

example:
random sample size n = 20 from a population where 55% of the population has a particular genetic
Xi = {
	1, ith member of the sample has the genetic
	0, otherwise
}
where i = 1,...,20 approximate sampling distribution of the statistic X = Σ^20_i=1(Xi)
= B(20, 0.55)

example:
random sample size n = 20 from a population where 55% of the population has a particular genetic
Xi = {
	1, ith member of the sample has the genetic
	0, otherwise
}
where i = 1,...,20 if the statistic is defined as
X = Σ^20_i=1(Xi)
find approximate values of E[X], and Var[X]
E[X] = 20*0.55 = 11, Var[X] = 11 * (1 - 0.55) = 4.95

Mean and variance of sample proportions
random sample size n where some proportion p of the population has a particular genetic
Xi = {
	1, ith member of the sample has the genetic
	0, otherwise
}
for i = 1,...,n
X = Σ^20_i=1(Xi ~= B(n,p))
we can form an estimate for the population proportion p
p̂ = X/n = 1/n Σ^n_i=1(Xi) = X̄
E[p̂] = E[X/n]
= 1/n * E[X]
= 1/n * np
= p
Var[p̂] = Var[X/n]
= 1/n^2 * Var[X]
= 1/n^2 * np(1 - p)
= p(1 - p)/n
E[p̂] = p, Var[p̂] = p(1 - p)/n
we don't yet know the sampling distribution of p̂

The standard Error
the standard deviation of p̂ is called the standard error and is denoted SE[p̂]
SE[p̂] = sqrt(Var[p̂]) = sqrt(p(1 - p)/n)
if p is unknown we can replace it with its estimate p̂ in the standard error
SE[p̂] = sqrt(p̂(1 - p̂)/n)

Mean and variance of sample proportions
in a population of adults with only one computer 42% have an Apple. A random sample of n = 40 adults is taken from the population and asked if they have a windows or an apple.
What is the mean and variance of p̂ the proportion of adults in the sample that have an Apple
E[p̂] = 42% = 0.42 and n = 40
Var[p̂] = 0.42(1 - 0.42)/40
~= 0.0061

example:
45% of share holders plans to vote for Steve Jobs in the upcoming Apple's shareholders meeting. A random sample of size n = 20 is taken from the population and asked about their voting preference
What is the mean and variance of p̂

E[p̂] = 45% = 0.45
Var[p̂] = 0.45(1 - 0.45)/20 ~= 0.0124

example:
15% of a particular group of young adults ride skateboards for exercise, a random sample of n = 60 young adults is taken from the population and asked whether they ride a skateboard for exercise
What is the mean and variance of p̂ who ride skateboards?
E[p̂] = 0.15
Var[p̂] = 0.15(1 - 0.15)/60 ~= 0.0021

Proof that a sum of vernoulli random variables is binomial
X1,X2,...,Xn ~ Bernoulli(p) are independent
Y = X1,X2,...,Xn ~ B(n,p)
we will demonstrate why this result is true using moment-generating functions
Let MX_i(t) be the moment-generating functino Xi for i = 1,2,...,n using a table of known results
MX_i(t) = 1 - p + pe^t
By the multiplicative property of moment-generating functions we have that M_Y(t) = MX_1 + X2 + ... + Xn(t)
= MX_1(t) * MX_2(t) * ... * MX_n(t)
= (1 - p + pe^t) * (1 - p + pe^t) * ... * (1 - p + pe^t)
= (1 - p + pe^t)^n
which is the moment-generating function of a binomial random variable with distribution B(n,p)
since any given distribution is characterized by its moment-generating function (meaning that no other distribution can have the same moment-generating function)
Y ~ B(n,p)
