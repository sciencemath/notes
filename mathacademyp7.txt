Parametric Inference:

Point Estimation
Maximum likelihood
Hypothesis testing
Confidence Intervals

Note:
anything with Φ(z) denotes a z-table lookup

Note:
using the cumulative distribution function (CDF) is always by convention to format probabilities as P(Z < z) so if we end up with P(z > Z) or P(Z > z) we need to minus one (mirror distribution) (1 - P(Z < z))

--------------------------------------------

In statistics we often want ot use sample data to deduce or infer the values of various population parameters, the two most common population parameters
the population mean μ
the population variance σ^2
The population mean is the mean of the entire population, the population variance is the variance of the entire population we should consider these values as fixed unknowns
for example we want to find the mean number of pages per book at barnes and noble we wish to find the population mean μ, but it is impractactical to count teh pages in every book instead we migh approximate μ using the sampling procedure
1. Randomly choose 5 books off the shelf
2. count the number of pages in each book
3. compute the mean of the 5 observations
sample size n = 5
suppose we get the following observations
201, 506, 58, 104, 99
its convenient to denote the individual observations as xi
x1 = 201, x2 = 506, ..., x5 = 99
we can compute the mean x̄ of our sample
x̄ = 1/n*Σ^n_i=1(xi)
= 1/5(201 + 506 + 58 + 104 + 99)
= 1/5 * 968
= 193.6
this is called an estimate of the population mean μ, we sometimes write μ (hat) = 193.6 to denote that the value 193.6 is an estimate of μ
its important to realize that our estimate x̄ depends entirely on this particular sample we'd get a different estimate for μ if we took a different sample

The sample mean
it is helpful to think of the observations of a particular sample
x1,x2, ..., xn
as a particular instance of data generated by a sequence of random variables
X1,X2, ..., Xn
Xi is a random variable that denotes the ith observation in a random sample its value changes when we conduct a new sample
xi is the value of the ith observation in a particular sample
Our sequence of random variables X1,X2,...,Xn typically has these properties
they are independent and identically distributed (I.I.D) meaning they are indpendent and have the same probability distribution they have the same distribution as the population
their mean is equal to the population mean
E(Xi) = μ, 1 <= i <= n
their variance is equal to the population variance
Var(Xi) = σ^2, 1 <= i <= n
the sequence of random variables X1,X2,...Xn with these properties as a random sample size n
in general if X1,X2,...,Xn is a random sample of size n then the sample mean is given by
X̄ = 1/n*Σ^n_i=1(Xi)
the sample mean X̄ is an estimator of the population mean μ
X1,X2,...Xn are random variables so is X̄. The probability distribution of X̄ is called the sampling distribution

Estimating a population mean from the sample mean
data is sampled from a population, compute an estimate for the population mean
6, 13, 7, 5, 14, 11, 7
X1,X2,...Xn is a sequence of random variables representing a random sample of size n drawn from a population mean μ the sample mean X̄
X̄ = 1/n*Σ^n_i=1(Xi)
X̄ is the mean value of X1,X2,...,Xn x̄ is the mean of a specific sample x1,x2...,xn
the sample mean X̄ is an estimator of the population mean μ
the value of μ(hat) = x̄ is an estimate of the population mean μ
= 1/7(6 + 13 + 7 + 5 + 14 + 11 + 7)
= 63/7
= 9

example:
compute an estimate for the population mean
3, 8, 10, 5, 7
1/5(3 + 8 + 10 + 5 + 7)
= 33/5 = 6.6

example:
compute an estimate for the population mean
-2, 5, -3, 10
1/4(-2 + 5 - 3 + 10)
10/4 = 5/2 = 2.5

The sample mean as an unbiased estimator
One important feature of X̄ is that its an unbiased estimator of μ the expected value of X̄ = μ
E[X̄] = μ
we can show X̄ is an unbiased estimator using properties of expectation
E[X̄] = E[1/n*Σ^n_i=1(Xi)]
= 1/n * E[Σ^n_i=1(Xi)]
= 1/n * E[X1 + X2 + ... + Xn]
= 1/n * (E[X1] + E[X2] + ... + E[Xn])
= 1/n * (μ + μ + ... + μ)
= 1/n * nμ
= μ
any estimate of x̄ of the population mean μ found by computing the mean of a sample is called an unbiased estimate of μ

The expected value of the sample mean
A sample X1,X2 of two metallic rings is drawn from a population, the population has rings of two different diameters 16.5mm and 18mm distributed in the ratio 5:1 calculate E[X̄]
to compute the population mean we can consider a population consisting of 5+1 = 6 rings only with the following diameters
16.5mm, 16.5mm, 16.5mm, 16.5mm, 16.5mm, 18mm
the population mean is
1/6(5*16.5 + 18)
= 1/6(82.5 + 18)
= 100.5/6
= 16.75mm
E[X̄] = μ = 16.75mm

example:
if X1,X2,...,X50 is a sample size n = 50 drawn from a population with mean μ = 30 and variance σ^2 = 9 what is E[X̄]?
E[X̄] = μ
E[X̄] = 30

example:
A sample X1,X2 of two nails is drawn from a population, the population has nails of two different lengths 6cm,12cm distributed in the ratio 3:1 calculate E[X̄]
1/4(3*6 + 12)
= 1/4(18 + 12)
= 1/4(30)
= 7.5

===================================================

The sample mean is an example of a statistic. A statistic is a random variable computed using values from a sample. Statistics are often used to estimate population parameters, although they also have other uses
The following statistic could be used as an estimator for the population variance σ^2
1/n*Σ^n_i=1(Xi - X̄)^2
an estimator for the population maximum
max(X1,X2,...,Xn)
an estimator for the population range
max(X1,X2,...,Xn) - min(X1,X2,...,Xn)
an estimator for the population median
median(X1,X2,...,Xn)
statistics cannot include any unknown population parameters
if the population mean μ in unknown then this is not a statistic
1/n*Σ^n_i=1(Xi - μ)^2
however if the population parameters μ and σ are both known then this is a statistic
Σ^n_i=1((Xi - μ)/σ)^2
statistics are described using observations from a random sample, they are random variables and have a probability distribution. The probability distribution of a statistic is called the sampling distribution of the statistic.

Calculating statistics
The weights in stones of five randomly selected 24 year olds
12.5, 11.7, 13.2, 12.8, 12.1
calculate the value of the statistic Σ^n_i=1(Xi^2) for this particular sample
Σ^n_i=1(xi^2) = (12.5)^2 + (11.7)^2 + (13.2)^2 + (12.8)^2 + (12.1)^2
= 156.25 + 136.89 + 174.24 + 163.84 + 146.41
= 777.63

example:
25.2, 24.8, 28.9, 27.5, 28.9
calculate the value of the statistic max(X1,X2,...,Xn) - min(X1,X2,...,Xn)
28.9 - 24.8 = 4.1

example:
1.34, 1.24, 1.42, 1.28, 1.39, 1.44
Σ^n_i=1(Xi)
1.34 + 1.24 + 1.42 + 1.28 + 1.39 + 1.44
= 8.11

===================================================

Lets now find the variance of the sampling distribution of X̄ using the properties of variance for sums of independent variables
Var[X̄] = Var[1/n*Σ^n_i=1(Xi)]
= (1/n)^2 * Var[Σ^n_i=1(Xi)]
= 1/(n^2) * Var[X1 + X2 + ... + Xn]
= 1/(n^2) * (Var[X1] + Var[X2] + ... + Var[Xn])
= 1/(n^2) * (σ^2 + σ^2 + ... + σ^2)
= 1/(n^2) * nσ^2
= σ^2/n
Var[X̄] = σ^2/n
we dont yet know the sampling distribution of X̄. What we do know is that whatever the sampling distribution of X̄ is it has mean μ and variance σ^2/n

finding the variance of a sample mean
A sample X1,X2 of two pills is drawn from a population the population has pills of two different active ingredient concentrations 30mg/ml and 15mg/ml distributed in the ratio 1:2 calculate Var[X̄]
E[X̄] = μ, Var[X̄] = σ^2/n
to compute the population mean and variance, we can consider a population consisting of 1 + 2 = 3 pill concentrations
30mg/ml + 15mg/ml + 15mg/ml
μ = 1/3(30 + 2*15)
= 60/3
= 20mg/ml
variance
σ^2 = 1/3*Σ_i(xi^2 - μ^2)
= 1/3(30^2 + 2*15^2) - 20^2
= 1/3(900 + 450) - 400
= 1/3(1350) - 400
= 450 - 400
= 50(mg/ml)^2
sample size n = 2
Var[X̄] = σ^2/n = 50/2 = 25(mg/ml)^2

example:
if X1,X2,...,X100 is a sample size n = 100 mean μ = 30 and variance σ^2 = 9 calculate the value of Var[X̄]
9/100 = 0.09

example:
a sample X1,X2 of two nails is drawn from a population, the population has nails of two different lengths 6cm and 12cm distributed in the ratio 3:1 calculate Var[X̄]
E[X̄] = 1/4(6^2*3 + 12^2) - 7.5^2
= 1/4(108 + 144) - 7.5^2
= 63 - 56.25
= 6.75/2
= 3.375cm^2

The standard error
the standard deviation of the sample mean is called the standard error of the sample mean and is denoted SE[X̄]
SE[X̄] = sqrt(Var[X̄])
if we have a random sample of size n drawn from a population with mean μ and variance σ^2 then the standard error is
SE[X̄] = sqrt(σ^2/n) = σ/sqrt(n)
the population standard deviation σ is often unknown whenever we draw a random sample from a population, we can usually estimate its value by replacing σ with a suitable estimate say s
SE[X̄] = s/sqrt(n)

finding the standard error
if X1,X2,...,X200 is a sample size n = 200 drawn from a population with mean μ = 23 and variance σ^2 = 4 calculate the standard error of X̄
Var[X̄] = 4/200
= 0.02
SE[X̄] = sqrt(0.02) ~= 0.14

example:
X1,X2,...,X100 sample of size n = 100 with mean μ = 30 and variance σ^2 = 9 calculate standard error of X̄
9/100 = sqrt(0.09)
SE[X̄] = 0.3

example:
X1,X2,X3 of three nails is drawn from a population, the population has nails of two different lengths, 5cm and 10cm distributed in the ratio 4:1 calculate the standard error of X̄
E[X̄] = 1/5(4*5 + 10)
= 1/5(30)
= 6
σ^2 = 1/5(4*5^2 + 10^2) - 6^2
= 40 - 36
= 4cm^2
Var[X̄] = σ^2/n = 4/3cm^2
SE[X̄] = sqrt(4/3) ~= 1.15cm

The sample mean and large samples
As the sample size n becomes larger and larger the variance and standard error of X̄ become smaller and smaller it is easy to see that n -> ∞
Var[X̄] = σ^2/n -> 0
SE[X̄] = σ/sqrt(n) -> 0
when the sample size n is large, there is less variance in the sampling distribution of X̄ the larger the sample the more likely it is that X̄ will give good estimates for μ the individual sample elements do not have this property since Var[Xi] = σ^2
the sample mean X̄ becomes a better estimator for the corresponding population mean μ as the sample size n increases

calculating an appropiate sample size
X1,X2,...,Xn of n bananas is drawn from a population the population has bananas of two different weights 1.5lbs and 2lb distributed 2:3 determine the smallest sample size required to give a SE fo less than 0.02lb
E[X̄] = μ
Var[X̄] = σ^2/n
SE[X̄] = sqrt(Var[X̄]) = σ/sqrt(n)
population consisting of 2+3 = 5
1.5lb, 1.5lb, 2lb, 2lb, 2lb
population mean
= 1/5(2*1.5 + 3*2)
= 1/5(3+6)
= 9/5
= 1.8lb
variance
= 1/5(2*1.5^2 + 3*2^2) - 1.8^2
= 1/5(16.5) - 3.24
= 3.3 - 3.24
= 0.06lb^2
SD = σ = sqrt(0.06)
SE[X̄] = sqrt(0.06/n)
we require that the standard error is less than 0.02lb
sqrt(0.06/n) < 0.02
sqrt(0.06)/sqrt(n) < 0.02
sqrt(n) > sqrt(0.06)/0.02
sqrt(n) > sqrt(0.06/0.02^2)
sqrt(n) > sqrt(0.06/0.0004)
sqrt(n) > sqrt(150)
n > 150
smallest sample size is n = 151

example:
X1,X2,...,Xn is a sample size n drawn from a population with mean μ = 12 and variance σ^2 = 16 determine the smallest sample size required so that the SE of the mean is less than 0.1
SD = σ = sqrt(16) = 4
4/sqrt(n) < 0.1
sqrt(n) > 4/0.1
sqrt(n) > 40
n > 40^2
n > 1600
smallest sample size is n = 1601

example:
X1,X2,...,Xn population of bartenders with two different working hours 38 h/week and 40h/week distributed 3:1 determine the smallest sample size required so that the standard error of the mean is less than 0.5 h/week
population mean μ
= 1/4(38*3 + 40)
= 1/4(154)
= 38.5
variance
= 1/4(38^2*3 + 40^2) - 38.5^2
= 1/4(5932) - 38.5^2
= 1483 - 1482.25
= 0.75
sqrt(0.75/n) < 0.5
sqrt(0.75)/sqrt(n) < 0.5
sqrt(n) > sqrt(0.75)/0.5
sqrt(n) > sqrt(0.75/0.5^2)
sqrt(n) > sqrt(0.75/0.25)
sqrt(n) > sqrt(3)
n > 3
smallest sample size n = 4

===================================================

From the definition of the population variance you might expect
1/n*Σ^n_i=1(Xi - X̄)^2
is an unbiased estimator for σ^2, it can be shown that it is a biased estimator of σ^2
E[1/n*Σ^n_i=1(Xi - X̄)^2] != σ^2
To compute an unbiased estimate of σ^2 we use the sample variance
S^2 = 1/n-1*Σ^n_i=1(Xi - X̄)^2
Instead of dividing by n (as with our original biased estimator) we instead divide by n - 1 this is referred to as Bessel's correction it corrects the bias of the original estimator
we should think of S^2 as a random variable whose value varies according to the particular sample under consideration
since S^2 is a random variable it has a sampling distribution (probility distribution)
An alternative formula for a sample variance thats often more convenient in practice:
S^2 = n/n-1[X̄^2 - (X̄)^2]

Computing an estimate of the population variance
A random sample of size n = 81 is conducted from a population
Σ^81_i=1(xi - x̄)^2 = 180
each xi is a sample observation, compute an unbiased estimate for the population standard deviation
X1,X2,...Xn is a sequence of random variables representing a random sample of size n drawn from a population with a population mean μ and population variance σ^2 the sample variance S^2
S^2 = 1/n-1 Σ^n_i=1(Xi - X̄)^2 = n/n-1[X̄^2 - (X̄)^2]
X̄ is the sample mean
the sample variance S^2 is an unbiased esitmator of the population variance σ^2
σ^2 = s^2 denotes an unbiased estimate of σ^2 thats computed from the sample x1,x2,...,xn
Σ^81_i=1(xi - x̄)^2 = 180 and n = 81
= 1/n-1 Σ^n_i=1(xi - x̄)^2
= (1/81 - 1) * 180
= (1/80) * 180
= 2.25
an unbiased estimate of the population variance is σ^2 = 2.25 we take the square root to compute an unbiased estimate of the standard deviation
σ = sqrt(2.25) = 1.5

example:
sample size n = 50
Σ^50_i=1(xi - x̄)^2 = 1176
compute an unbiased estimate of the variance
= (1/49) * 1176
unbiased estimate = 24

compute an unbiased estimate of the standard deviation
unbiased 
sample size n = 100
Σ^100_i=1(xi - x̄)^2 = 1584
= 1/99 * 1584
σ^2 = 16
σ = sqrt(16) = 4

Computing an estimate of the population variance using the alternative formula
x1,x2,...,x9 is a random sample size n = 9 from a population x̄^2 - (x̄)^2 = 4
compute an unbiased estimate of the population variance
= n/n - 1[x̄^2 - (x̄)^2]
= 9/9-1 * 4
= 36/8
= 4.5

example:
x1,x2,...,x11 sample size 11 x̄^2 - (x̄)^2 = 7
compute an unbiased estimate of the population variance
= 11/10 * 7
= 77/10
= 7.7

example:
x1,x2,...,x6 sample size n = 6
x̄^2 - (x̄)^2 = 3
compute an unbiased esitmate of the population variance
= 6/5 * 3
= 18/5
= 3.6

Estimating the population variance from sample data
compute an unbiased estimate of the population variance
5, 3, 6, 4, 7
x̄ = 1/5(5 + 3 + 6 + 4 + 7)
= 25/5
= 5
x̄^2 = 1/5(5^2 + 3^2 + 6^2 + 4^2 + 7^2)
= 135/5
= 27
x̄^2 - (x̄)^2 = 27 - 5^2
= 2
σ^2 = s^2
= 5/5-1 * 2
= 2.5
unbiased estimate of population variance 2.5

example:
compute an unbiased estimate of the population variance
4, 8, 10, 6, 7
x̄ = 1/5(4 + 8 + 10 + 6 + 7)
= 1/5(35)
= 7
x̄^2 = 1/5(4^2 + 8^2 + 10^2 + 6^2 + 7^2)
= 265/5
= 53
x̄^2 - (x̄)^2 = 53 - 49
= 4
σ^2 = s^2
= 5/5-1 * 4
= 20/4
= 5

example:
compute an unbiased estimate of the population variance
-10, 20, -30, 40
x̄ = 1/4(-10 + 20 - 30 + 40)
= 1/4(20)
= 5
x̄^2 = 1/4(-10^2 + 20^2 - 30^2 + 40^2)
= 1/4(3000)
= 750
x̄^2 - (x̄)^2 = 750 - 5^2
= 725
σ^2 = s^2
4/3 * 725
= 2900/3
~= 966

Proof of the alternative formula
S^2 = n/n-1[X̄^2 - (X̄)^2]
definition
S^2 = 1/n-1 * Σ^n_i=1(X̄i - X̄)^2
expaning paranetheses and distributing
S^2 = 1/n-1 Σ^n_i=1(X̄i^2 - 2XiX̄ + (X̄)^2)
= 1/n-1[Σ^n_i=1(X̄i^2) - Σ^n_i=1(2XiX̄) + Σ^n_i=1(X̄)^2)]
= 1/n-1[Σ^n_i=1(X̄i^2) - 2Σ^n_i=1(XiX̄) + (X̄)^2*Σ^n_i=1(1))]
considering each sum separately
Σ^n_i=1(X̄i^2) = n * X̄^2 from the definition of the mean of X^2
Σ^n_i=1(Xi) = n * X̄ from the definition of the mean of X
Σ^n_i=1(1) = 1 + 1 + ... + 1 = n (n times)
S^2 = 1/n-1[Σ^n_i=1(X̄i^2) - 2Σ^n_i=1(XiX̄) + (X̄)^2*Σ^n_i=1(1))]
= 1/n-1[n * X̄^2 - 2X̄*n*X̄ + (X̄)^2*n]
= n/n-1[X̄^2 - 2(X̄)^2 + (X̄)^2]
= n/n-1[X̄^2 - (X̄)^2]

Proof that the sample variance is an unbiased estimator
S^2 is an unbiased estimator of σ^2
E[S^2] = σ^2
we'll prove
E[X̄^2 - (X̄)^2] = n-1/n * σ^2
X̄^2 - (X̄)^2 is the variance sample
X̄^2 - (X̄)^2 = 1/n Σ^n_i=1(X̄i - X̄)^2
the variance of the sample is not the same as the sample variance S^2
we start by computing the expected difference between σ^2 and the variance of the sample, simplify
σ^2 - (X̄^2 - (X̄)^2)
= 1/n Σ^n_i=1(Xi - μ)^2 - 1/n Σ^n_i=1(Xi - X̄)^2
= 1/n Σ^n_i=1[(Xi - μ)^2 - (Xi - X̄)^2]
= 1/n Σ^n_i=1[(Xi^2 - 2μXi + μ^2) - (Xi^2 - 2X̄Xi + (X̄)^2)]
= 1/n Σ^n_i=1[μ^2 - (X̄)^2 + 2X̄Xi - 2μXi]
compute the expectation, E[Xi] = X̄ and Var[X̄] = σ^2/n
E[σ^2 - (X̄^2 - (X̄)^2)]
= E[1/n Σ^n_i=1(μ^2 - (X̄)^2 + 2X̄Xi - 2μXi)]
= 1/n Σ^n_i=1(μ^2 - (X̄)^2 + 2X̄E[Xi] - 2μE[Xi])
= 1/n Σ^n_i=1(μ^2 - (X̄)^2 + 2(X̄)^2 - 2μX̄)
= 1/n Σ^n_i=1((X̄)^2 - 2X̄μ + μ^2)
= 1/n Σ^n_i=1(X̄ - μ)^2
= Var[X̄]
= σ^2/n

E[X̄^2 - (X̄)^2] = E[σ^2 - (X̄^2 - (X̄)^2)]
= E[σ^2] - E[σ^2 - X̄^2 - (X̄)^2]
= σ^2 - σ^2/n
= n-1/n * σ^2

E[S^2] = E[n-1/n[X̄^2 - (X̄)^2]]
= n/n-1 * E[X̄^2 - (X̄)^2]]
= n/n-1 * n-1/n*σ^2
= σ^2

===================================================

Sample means from normal populations
X1,X2,...Xn be a random sample of size n drawn from a normal population N(μ,σ^2)
X1,X2,...Xn ~ N(μ,σ^2)
sampling distribution of the sample mean
X̄ = 1/n Σ^n_i=1(Xi)
The sum of n independent and identically distributed normal random variables is normally distributed
Y = Σ^n_i=1(Xi)
a normally distributed random variable scaled by a constant factor is normally distributed
X̄ = 1/n * Y
expected value of the sample mean equals population mean
E[X̄] = μ
variance of sample mean
Var[X̄] = σ^2/n
altogether
X̄ ~ N(μ, σ^2/n)
sample mean X̄ is normally distributed with mean μ and variance σ^2/n

Stating the distribution of the sample mean
X1,X2,...,X28 ~ N(8,14^2) is a random sample size of n = 28 from a normal population what is the distribution of the sample mean X̄?
X̄ ~ N(μ, σ^2), 1 <= i <= n
sample mean X̄ has the distribution
X̄ ~ N(μ, σ^2/n)
n = 28, μ = 8, σ = 14
distribution of the sample mean X̄
X̄ ~ N(8, 14^2/28)
~ N(8,7)

example:
X1,X2,...,X50 ~ N(5,10^2) random sample size n = 50 what is the distribution of the sample mean X̄?
~ N(5,10^2/50) ~ N(5,2)

example:
X1,X2,...,X100 ~ N(16,20^2) sample size n = 100 what is the distribution of the sample mean X̄?
~ N(16,20^2/100) ~ N(16,4)

Calculating a probability involving sample mean
X1,X2,...,X100 ~ N(-4,20^2) is a random sample of size 100 from a normal population calculate P(-4.3 < X̄ < -3.9)
sample distribution of the sample mean X̄ is
X̄ ~ N(-4, 20^2/100)
~ N(-4,4)
tansform X into a standard normal random variable by z-scoring
P(-4.3 < X̄ < -3.9)
= P((-4.3 - (-4))/sqrt(4) < Z < (-3.9 - (-4))/sqrt(4))
= P(-0.15 < Z < 0.05)
= Φ(0.05) - Φ(-0.15)
Φ(0.05) = 0.5199
Φ(-0.15) = 0.4404
0.5199 - 0.4404
= 0.0795

example:
X1,X2,...,X50 ~ N(5,10^2) 
sample size of 50 calculate P(4.8 < X̄ < 5.2)
X̄ ~ N(5, 10^2/50) ~ N(5,2)
= P((4.8 - 5)/sqrt(2) < Z < (5.2 - 5)/sqrt(2))
= P(-0.14 < X̄ < 0.14)
Φ(0.14) - Φ(-0.14)
Φ(0.14) = 0.5557
symmetry of normal distribution
Φ(-0.14) = 1 - Φ(0.14)
= 1 - 0.5557
= 0.4443
= 0.5557 - 0.4443
= 0.1114

example:
X1,X2,...,X36 ~ N(0,18^2) is a random sample size of 36
calculate P(|X̄| > 0.8)
~ N(0,18^2/36) ~ N(0,9)
= 1 - P(|X̄| < 0.8)
= 1 - P(-0.8 < X̄ < 0.8)
= 1 - P(-(0.8 - 0)/sqrt(9) < Z < (0.8 - 0)/sqrt(9))
= 1 - P(-0.27 < Z < 0.27)
= 1 - (Φ(0.27) - Φ(-0.27))
= 1 + Φ(0.27) - Φ(-0.27)
Φ(0.27) = 0.6064
Φ(-0.27) = 1 - 0.6064
= 0.3936
= 1 + 0.3936 - 0.6064
= 0.7872

Calculating a probability involving a sample mean in context
blood pressure of adult women in a population that is normally distributed with mean 75mm and SD 10mm. 10 women are selected at random what is the probability that the blod pressure mean for this sample wil be less than 70mm?
X̄ ~ N(75, 10^2/10) ~ N(75,10)
P(X̄ < 70)
= P(Z < (70 - 75)/sqrt(10))
~= P(Z < -1.58)
= Φ(-1.58)
= 0.0571

example:
IQ scores are normally distributed with a mean of 100 and SD 15, 10 people are selected randomly. What is the probability that the mean score for this sample will be greater than 105?
X̄ ~ N(100, 15^2/10) ~ N(100,22.5)
P(X̄ > 105)
= P(Z > (105 - 100)/sqrt(22.5))
= 1 - Φ(1.05)
= 1 - 0.8531
= 0.1469

example:
weights of a particular breed of duck are normally distributed with a mean of 7kg and SD 1kg, 4 ducks are randomly selected. What is the probability that the mean for this sample will be more than 6.8kg but less than 7kg?
P(6.8 < X̄ < 7)
X̄ ~ N(7, 1^2/4) ~ N(7,0.25)
= P((6.8 - 7)/sqrt(0.25) < Z < (7 - 7)/sqrt(0.25))
= P(-0.4 < Z < 0)
= Φ(0.0) - Φ(-0.4)
= 0.5000 - 0.3446
= 0.1554

===================================================

The central limit theorem
if X1,X2,...,Xn is a random sample of size n drawn from a normal population N(μ, σ^2) then the sample mean X̄ is normally distributed with the sampling distribution
X̄ = 1/n Σ^n_i=1(Xi) ~ N(μ, σ^2/n)
The sampling distribution X̄ depends on the population distribution, no general result exists that tells us how X̄ is distributed for an arbitrary population distribution.
An important result, known as the central limit theorem, tells us that when the sample size n is large, the sample mean X̄ is approximately normally distributed the sampling distribution of X̄ for large n does not depend on the population distribution
theorem:
Suppose that X1,X2,...,Xn is a random sample of size n from a population with a population mean μ and population SD σ. THe centeral limit theorem (CLT) states that for sufficiently large n, the distribution of the sample mean X̄ can be approximated as
X̄ ~ N(μ, σ^2/n)
in other words as the sample size increases the distribution of the sample mean is approximately normal

We assume that X1,X2,...,Xn are independent and identically distributed and they can have any distribution (discrete or continuous)
the theorem is valid for sufficiently large n, typically n >= 30 is assumed to be sufficiently large, although this does vary in general the larger the better
CLT assumes that μ and σ both exist, this is not true for every probability distribution (e.g. the Cauchy distribution)

Consider a random variable X that follows a binomial distribution where
X ~ B(20, 0.1) the parameters are m = 20, p = 0.1 lets start by calculating the mean and the variance of X
mean μ is
μ = E[X]
= mp
= 20*0.1
= 2
variance σ^2
σ^2 = Var[X]
= mp(1 - p)
= 20 * 0.1 * 0.9
= 1.8
To understand the sampling distribution of X̄ for this population suppose we conduct the following experiment
1. Pick a value for the sample size n
2. Using a computer randomly generate 1000 sample size n drawn from our binomial population
3. Calculate the sample mean for each sample
4. Create a histogram of the sample means to visualize the approximate sampling distribution
5. repeat this process for increasing values of n
lets do this procedure for sample sizes of 2, 4 and 9
lets consider sample size n = 2
E[X̄] = 2, Var[X̄] = σ^2/n = 1.8/2 = 0.9
next generating 1000 sample of size n = 2 and calculating the corresponding sample mean for each sample, when visualizing the results (histogram) the sample mean does not closely resemble the normal distribution
n = 4
E[X̄] = 2, Var[X̄] = σ^2/n = 1.8/4 = 0.45
again 1000 samples of size n = 4, the visualization of this is closer to normal distribution than n = 2 case
n = 9
E[X̄] = 2, Var[X̄] = σ^2/n = 1.8/9 = 0.2
1000 samples of size n = 9, this is much closer to what appears to be a normal distribution compared to the n=2, and n=4 cases
As the sample size n increases the histograms become more and more similar to their corresponding normal distribution, and the standard error of the sample mean becomes smaller and smaller.

Finding an approximate probability using the central limit theorem
X1,X2,...,X120 be a random sample of size n = 120 from a population with a population mean μ = 100 and population SD σ = 60 find an approximation for the probability that the sample mean is between 102 and 105
n = 120, μ = 100, σ = 60
~ N(100, 60^2/120)
~ N(100, 30)
P(102 < X̄ < 105) = P((102 - 100)/sqrt(30) < Z < (105 - 100)/sqrt(30))
= P(2/sqrt(30) < Z < 5/sqrt(30))
~= P(0.37 < Z < 0.91)
= P(Z < 0.91) - P(Z < 0.37)
= Φ(0.91) - Φ(0.37)
= 0.8186 - 0.6443
= 0.1743

example:
X1,X2,...,X100 be a random sample of size n = 100 from a population mean μ = 500 and population SD σ = 80 find an approximation for the probability that the sample mean is between 490 and 510
n = 100, μ = 500, σ = 80
~ N(500, 80^2/100) ~ N(500,64)
P(490 < X̄ < 510) = P((490 - 500)/8 < Z < (510 - 500)/8)
P(-1.25 < Z < 1.25)
= Φ(1.25) - Φ(-1.25)
Φ(-1.25) = 1 - Φ(1.25)
= 0.8944 - 0.1056
= 0.7888

example:
X1,X2,...,X176 be a random sample of size n = 176 from a population with a population mean μ = 8 and population SD σ = 88 find an approximation for P(|X̄| > 4)
n = 176, μ = 8, σ = 88
~ N(8,88^2/176) ~ N(8,44)
= P(|X̄| < 4) = P(X̄ < -4) + P(X̄ > 4)
= P(Z < (-4 - 8)/sqrt(44)) + P(Z > (4 - 8)/sqrt(44))
~= P(Z < -1.81) + P(Z > -0.60)
= P(Z < -1.81) + (1 - P(Z <= -0.60))
= 1 + Φ(-1.81) - Φ(-0.60)
= 1 + 0.0351 - 0.2743

using the CLT with a population whose probability is discrete
x   | -3| -1|  1|  3|
f(x)|0.4|0.1|0.1|0.4|
X1,X2,...,X185 be a random sample of size n = 185 from a population with the probability mass function, find the approximation in terms of Φ(z) for P(|X̄| > 0.1)
Φ(z) is the cumulative distribution function for the standard normal distribution
n = 185
population mean
μ = E[X]
= Σ^n_i=1(xi * f(xi))
= -3 * 0.4 + (-1) * 0.1 + 1 * 0.1 + 3 * 0.4
= -1.2 - 0.1 + 0.1 + 1.2
= 0
population variance
σ^2 = Var[X]
= E[X^2] - E[X]^2
= ((-3)^2 * 0.4 + (-1)^2 * 0.1 + 1^2 * 0.1 + 3^2 * 0.4) - 0^2
= (3.6 + 0.1 + 0.1 + 3.6) - 0
= 7.4
by the CLT we have that the distribution of the sample mean
X̄ ~ N(μ, σ^2/n)
~ N(0, 7.4/185)
P(|X̄| > 0.1) = P(X̄ < -0.1) + P(X̄ > 0.1)
~= P(Z < (-0.1 - 0)/sqrt(0.04) + P(Z > (0.1 - 0)/sqrt(0.04)))
= P(Z < -0.5) + P(Z > 0.5)
= P(Z < -0.5) + 1 - P(Z < 0.5)
= 1 + Φ(-0.5) - Φ(0.5)
(Φ(-0.5) = 1 - Φ(0.5))
P(|X̄| > 0.1) = 1 + (1 - Φ(-0.5)) - Φ(0.5)
= 2 - 2Φ(0.5)
= 2(1 - Φ(0.5))

example:
x   |  1|  2|  3|  4|
f(x)|0.5|0.2|0.1|0.2|
X1,X2,...,X50 be a random sample of size n = 50, probability sample mean is greater than 2.2
n = 50
μ = 1*0.5 + 2*0.2 + 3*0.1 + 4*0.2
= 2
σ^2 = (1^2*0.5 + 2^2*0.2 + 3^2*0.1 + 4^2*0.2) - 2^2
= 5.4 - 4
= 1.4
~ N(2, 1.4/50) ~ N(2,0.028)
P(X̄ > 2.2)
~= P(Z > (2.2 - 2)/sqrt(0.028))
= P(Z > 1.20)
= 1 - Φ(1.20)

example:
x   | -2| -1|  0|  2|
f(x)|0.3|0.2|0.1|0.4|
X1,X2,...,X30 be a random sample of size n = 30, find an approximation for P(|X̄| > 0.2) = P(X̄ < -0.2) + P(X̄ > 0.2)
n = 30
μ = (-2)*0.3 + (-1)*0.2 + 0*0.1 + 2*0.4
= 0
σ^2 = ((-2)^2*0.3 + (-1)^2*0.2 + 0^2*0.1 + 2^2*0.4) - (0)^2
= 3 - 0
= 3
~ N(0, 3/30) ~ N(0,0.1)
~= P(Z < (-0.2 - 0)/sqrt(0.1) + P(Z > (0.2 - 0)/sqrt(0.1)))
~= P(Z < -0.63) + P(Z > 0.63)
= P(Z < -0.63) + 1 - P(Z < 0.63)
= 1 + Φ(-0.63) - Φ(0.63)
Φ(0.63) = 0.2643
Φ(0.63) = 1 - Φ(-0.63)
= 2Φ(0.63)
= 2 * 0.2643
= 0.5286

Using the CLT with a population is continuous
X1,X2,...,X100 be a random sample of size n = 100, with probability density function
f(x) = {
	2/9(x), 0 <= x <= 3
	0,      otherwise
}
given that the population variance σ^2 = 0.5 calculate P(X̄ > 1.9)
μ = E[X]
∫^∞_-∞ xf(x) dx
= ∫^3_0 x * 2/9(x) dx
= ∫^3_0 2/9(x^2) dx
= [2x^3/27]|_0-3
= 2
σ^2 = 0.5
~ N(2, 0.5/100) ~ N(2, 0.005)
= P(Z > (1.9 - 2)/sqrt(0.005))
~= P(Z > -1.41)
= 1 - P(Z <= -1.41)
= 1 - Φ(-1.41)
= 1 - 0.0793
= 0.9207

example:
X1,X2,...,X20 be a random sample of size n = 20, with probability density function
f(x) = {
	3/2(x^2), -1 <= x <= 1
	0,        otherwise
}
given that the population variance σ^2 = 0.6 calculate P(0 < X̄ < 0.2)
= ∫^1_-1 x * 3/2(x^2) dx
= ∫^1_-1 3/2(x^3) dx
= [3x^4/8]|_-1-1
= ((3/8) - (3/8))
= 0
~ N(0, 0.6/20) ~ N(0,0.03)
P((0 - 0)/sqrt(0.03) < Z < (0.2 - 0)/sqrt(0.03))
~= P(0 < Z < 1.15)
= P(Z < 1.15) - P(Z < 0)
= Φ(1.15) - Φ(0)
= Φ(1.15) = 0.8749
= Φ(0) = 0.5
= 0.8749 - 0.5
= 0.3749

example:
X1,X2,...,X25 be a random sample of size n = 25, with probability density function
f(x) = {
	3/8(x^2), 0 <= x <= 2
	0,        otherwise
}
given the population variance σ^2 = 0.15 calculate P(X̄ > 1.6)
= ∫^2_0 x * 3/8(x^2) dx
= ∫^2_0 3/8(x^3) dx
= [3x^4/32]|_0-2
= (48/32 - (0))
= 24/16 = 12/8 = 6/4 = 3/2
= 1.5
~ N(1.5, 0.15/25) ~ N(1.5,0.006)
P(Z > (1.6 - 1.5)/sqrt(0.006))
~= P(Z > 1.29)
= 1 - P(Z < 1.29)
= 1 - Φ(1.29)
= 1 - 0.9015
= 0.0985

Sums of I.I.D. Random variables
Assume that X1,X2,...,Xn is a random sample of size n from a population with a population mean μ and population SD σ the central limit theorem states that for sufficiently large n
X̄ ~= N(μ,σ^2/n)
an important consequence of the central limit theorem is that if X1,X2,...,Xn are I.I.D
X = Σ^n_i=1(Xi ~= N(nμ,nσ^2))
in other words a sum of I.I.D random variables is approximately normally distributed
if: X̄ = 1/n Σ^n_i=1(Xi ~= N(μ,σ^2/n))
then the random variable: X = nX̄ = X̄ + X̄ + ... + X̄ (n times)
is a sum of n (approximately) normally distributed random variables and is normally distributed, the mean and variance of X are
E[X] = n*μ, Var[X] = n^2 * σ^2/n = nσ^2
writing this in terms of X̄ we have
nX̄ ~= N(nμ,nσ^2)

Equivalent forms of the Central limit theorem
We can rewrite the central limit in several different ways
One way of restating the central limit theorem
X̄ - μ ~= N(0,σ^2/n)
this tells us that the deviation of X̄ from the mean μ is (approximately) normally distributed with a mean of zero and a variance thats the same as X̄
we can also rewrite CLT as
(X̄ - μ)/(σ/sqrt(n)) ~= N(0,1)
this statement tells us that z-scoring the sample mean gives a random variable that (approximately) follows a standard normal distribution
we saw
nX̄ ~= N(nμ,nσ^2)
z-score this result we get
(nX̄ - nμ)/sqrt(nσ^2) = n(X̄ - μ)/sqrt(n)*σ
= sqrt(n)(X̄ - μ)/σ
which means that we can express the central limit theorem in the form
sqrt(n)(X̄ - μ)/σ ~= N(0,1)

===================================================

Sampling proportions from finite populations
Suppose that a business is about to elect a new CEO, we're interested in determining the proportion p of a company's employees that will vote for "candidate A"
if a company has N = 50 employees and 30 of them will vote for candidate A then the proportion p is
p = 30/50 = 0.6
60% of the company's employees will vote for candidate A
N is the population size
p is the population proportion
the number of employees that will vote for candidate A is
Np = 50*0.6 = 30
Lets start by modeling the response from each member of the population as a random variable Xi defined by
Xi = {
	1, ith member of the population will vote for candidate A
	0, otherwise
}
for i = 1,...,50
Calculating the probability that a randomly selected member of the population will vote for candidate A is
P(Xi = 1) = # of members vote for candidate A/population size
= Np/N
= 30/50
= 0.6
its important to note that the Xi's are dependent
P(X2 = 1|X1 = 1) != P(X2 = 1)
to see why note P(X2 = 1) = 0.6 as before
P(X2 = 1|X1 = 1)
= (# of members vote for candidate A) - 1/population size - 1
= (Np - 1)/(N - 1)
= (50*0.6 - 1)/(50 - 1)
= (30 - 1)/49
= 29/49
~= 0.592
!= P(X2 = 1)
we know that the first member will vote for canadidate A so to compute the conditional probability that the second member will also vote for candidate A we consider a reduced population with N-1 = 49 members of which only 30 - 1 = 29 will vote for candidate A

finding aa conditional probability given a population proportion
Apple decided to elect a new board member, there are 50 workers and 60% of this worker population will vote for Tim Cook let the random variable Xi be
Xi = {
	1, ith member of the population will vote for Tim Cook
	0, otherwise
}
for i = 1,...,50 find P(X2 = 0|X1 = 0)
we have a population size N = 50 and p = 0.6 represents the proportion of the population that will vote for Tim Cook
The number of members that will vote for Tim Cook:
Np = 50(0.6) = 30
members that will not vote for Tim Cook:
N(1 - p) = 50(1 - 0.6) = 20
two members of the population at random, we need to find P(X2 = 0|X1 = 0) the probability that the second member will not vote for Tim Cook given that the first member will also not vote for Tim Cook
if first member does not vote for Tim Cook
N - 1 = 50 - 1 = 49 members remaining
N(1 - p) - 1 = 19 members remaining that will not vote for Tim Cook
P(X2 = 0|X1 = 0) = (N(1 - p) - 1)/(N - 1) = 19/49

example:
we have a population size N = 20 where 55% of the population has a particular gene
Xi = {
	1, ith member of the population has the gene
	0, otherwise
}
for i = 1,...,20 find P(X2 = 1|X1 = 1)
0.55(20) = 11 has the gene
the probability of the second person having the gene given the first person having it: 10/19

example:
Google decided to elect a new board member, there are 20 workers and 55% of this worker population will vote for Sergey Brin
Xi = {
	1, ith member that will vote for Sergey Brin
	0, otherwise
}
for i = 1,...,20. Find P(X2 = 1|X1 = 0)
0.55(20) = 11 will vote for Sergey Brin
P(X2 = 1|X1 = 0) = Np/N-1 = 11/19

Independence in large populations
population of size N = 1000 of which teh proportion p = 0.5 has a particular genetic
Xi = {
	1, ith member of the population has the genetic
	0, otherwise
}
for i = 1,...,1000
Xi's are dependent
this time since the population size N = 1000 is large we may approximate that the Xi's are independent
to see why we first note
P(X2 = 1) = Np/N = 0.5
computing P(X2 = 1|X1 = 1)
= (Np - 1)/(N - 1)
= (1000*0.5 - 1)/)(1000 - 1)
= 499/999
~= 0.5
P(X2 = 1|X1 = 1) ~= P(X2 = 1)
X1 and X2 are (approximately) independent

The number of sample elements with a genetic
Xi = {
	1, ith member of the sample has the genetic
	0, otherwise
}
for i = 1,...,n
Xi's can be modeled as mutually independent random variables provided that the population size N is significantly larger than the sample size n this typically means that the sample size should be no larger than 5% of the population size
The population size is much larger than the sample size is true in many cases. For example, the users using the Chrome browser consists of millions of people yet a typical sample from this population might consist of only a few thousand users.
X = Σ^n_i=1(Xi)
where Xi ~ Bernoulli(p)
since the Xi's take the value 1 if the ith element has the genetic or 0 if the ith element doesn't have the genetic, the statistic X can be used to count the number of elements with the genetic. X represents the number of sample elements with the genetic
Each Xi can be modeled as a Bernoulli random variable Xi ~ Bernoulli(p)
We're assuming N >> n it follows that X1,X2,...,Xn are (approximately) independent and identically distributed (I.I.D) Bernoulli random variables
A sum of n I.I.D. Bernoulli random variables with parameter p is a binomial random variable B(n,p)
process:
Xi ~ Bernoulli(p)
		↓
N >> n
   		↓
X1,X2,...,Xn ~= I.I.D
		↓
X = Σ^n_i=1(Xi ~= B(n,p))
using the formulas for the mean and variance of Binomial random variable we have the following approximations
E[X] = np, Var[X] = np(1 - p)

Properties of sums of bernoulli random variables
random sample of size n = 360 from a population where 35% of the population has a particular genetic
Xi = {
	1, ith member of the sample has the genetic
	0, otherwise
}
where i = 1,...,360
X = Σ^360_i=1(Xi)
find approximate values of E[X] and Var[X]
hint: we may assume that the population size is significantly larger than the sample size
provided that N >> n the random variables Xi can be considered independent and identically distributed
Xi ~ Bernoulli(p) 1 <= i <= n
where p is the proportion of the population that has the genetic
X = Σ^n_i=1(Xi)
can be approximated as a binomial random variable X ~= B(n,p)
E[X] = np, Var[X] = np(1 - p)
p = 35% = 0.35, n = 360
X ~= B(360,0.35)
mean and variance
E[X] = np
= 360*0.35
= 126
Var[X] = np(1 - p)
= 360*0.35 * (1 - 0.35)
= 81.9

example:
random sample size n = 20 from a population where 55% of the population has a particular genetic
Xi = {
	1, ith member of the sample has the genetic
	0, otherwise
}
where i = 1,...,20 approximate sampling distribution of the statistic X = Σ^20_i=1(Xi)
= B(20, 0.55)

example:
random sample size n = 20 from a population where 55% of the population has a particular genetic
Xi = {
	1, ith member of the sample has the genetic
	0, otherwise
}
where i = 1,...,20 if the statistic is defined as
X = Σ^20_i=1(Xi)
find approximate values of E[X], and Var[X]
E[X] = 20*0.55 = 11, Var[X] = 11 * (1 - 0.55) = 4.95

Mean and variance of sample proportions
random sample size n where some proportion p of the population has a particular genetic
Xi = {
	1, ith member of the sample has the genetic
	0, otherwise
}
for i = 1,...,n
X = Σ^20_i=1(Xi ~= B(n,p))
we can form an estimate for the population proportion p
p̂ = X/n = 1/n Σ^n_i=1(Xi) = X̄
E[p̂] = E[X/n]
= 1/n * E[X]
= 1/n * np
= p
Var[p̂] = Var[X/n]
= 1/n^2 * Var[X]
= 1/n^2 * np(1 - p)
= p(1 - p)/n
E[p̂] = p, Var[p̂] = p(1 - p)/n
we don't yet know the sampling distribution of p̂

The standard Error
the standard deviation of p̂ is called the standard error and is denoted SE[p̂]
SE[p̂] = sqrt(Var[p̂]) = sqrt(p(1 - p)/n)
if p is unknown we can replace it with its estimate p̂ in the standard error
SE[p̂] = sqrt(p̂(1 - p̂)/n)

Mean and variance of sample proportions
in a population of adults with only one computer 42% have an Apple. A random sample of n = 40 adults is taken from the population and asked if they have a windows or an apple.
What is the mean and variance of p̂ the proportion of adults in the sample that have an Apple
E[p̂] = 42% = 0.42 and n = 40
Var[p̂] = 0.42(1 - 0.42)/40
~= 0.0061

example:
45% of share holders plans to vote for Steve Jobs in the upcoming Apple's shareholders meeting. A random sample of size n = 20 is taken from the population and asked about their voting preference
What is the mean and variance of p̂

E[p̂] = 45% = 0.45
Var[p̂] = 0.45(1 - 0.45)/20 ~= 0.0124

example:
15% of a particular group of young adults ride skateboards for exercise, a random sample of n = 60 young adults is taken from the population and asked whether they ride a skateboard for exercise
What is the mean and variance of p̂ who ride skateboards?
E[p̂] = 0.15
Var[p̂] = 0.15(1 - 0.15)/60 ~= 0.0021

Proof that a sum of vernoulli random variables is binomial
X1,X2,...,Xn ~ Bernoulli(p) are independent
Y = X1,X2,...,Xn ~ B(n,p)
we will demonstrate why this result is true using moment-generating functions
Let MX_i(t) be the moment-generating functino Xi for i = 1,2,...,n using a table of known results
MX_i(t) = 1 - p + pe^t
By the multiplicative property of moment-generating functions we have that M_Y(t) = MX_1 + X2 + ... + Xn(t)
= MX_1(t) * MX_2(t) * ... * MX_n(t)
= (1 - p + pe^t) * (1 - p + pe^t) * ... * (1 - p + pe^t)
= (1 - p + pe^t)^n
which is the moment-generating function of a binomial random variable with distribution B(n,p)
since any given distribution is characterized by its moment-generating function (meaning that no other distribution can have the same moment-generating function)
Y ~ B(n,p)

===================================================

Point estimates of population proportions
Xi = {
	1, ith member of the sample has the characteristic
	0, otherwise
}
Xi ~ Bernoulli(p)
Lets assume the sample size is <= 5% of the population size X1,X2,...,Xn can be considered to be (approximately) independent and identically distributed which means that 
X = Σ^n_i=1(Xi ~= B(n,p))
B(n,p) is a binomial distribution
E[X] = np, Var[X] = np(1 - p)
X represents the number of sample members with the characteristic
assume that np > 5 and n(1 - p) > 5 we can apply the normal approximation of the binomial theorem (i.e. central limit theorem)
X ~= N(np, np(1 - p))
we can construct an estimator p̂
p̂ = X/n
E[p̂] = p, Var[p̂] = p(1 - p)/n
since X is approximately normally distributed p̂ is also normally distributed, the sampling distribution is
p̂ = N(p, p(1 - p)/n)
we usually don't know p so we can use an estimate to approximate E[p̂] and Var[p̂]

A summary of the sample distribution model
Suppose we have a population size N in which a proportion p has a particular characteristic. Consider a sample of size n drawn from the population where
n <= 5% * N (the sample size is smaller than or equal to 5% of the population size)
np > 5
n(1 - p) > 5
then the sampling distribution of the sample proportion p̂ can be approximated as the noramlly distributed random variable
p̂ ~ N(p, p(1 - p)/n)

Xi ~ Bernoulli(p)
		↓
N >> n
   		↓
X1,X2,...,Xn ~= I.I.D
		↓
X = Σ^n_i=1(Xi ~= B(n,p))
		↓
np > 5, n(1 - p) > 5
		↓
X ~= N(np, np(1 - p))
		↓
p̂ = X/n ~= N(p, p(1 - p)/n)

np > 5 means that at least five members of the sample have the characteristic
n(1 - p) > 5 means that at least five members of the sample do not have the characteristic

Identifying situations when the CLT for proportions is appropiate
p̂ ~ N(p, p(1 - p)/n)
where p is the population proportion?
1. A sample of 120 apples from a population of 20000 where 75% of the apples weigh more than 50g
2. A sample of 25 students from a school containing 200 students where 80% of the students study for more than 100 minutes a day
3. A sample of 45 ubers at a mall given 90% of drivers arrive on time you may assume the population size is significantly larger than the sample size
situation 1:
n = 120
<= 5% * N
= 0.05 * 20000
= 1000 ✔
np = 120(0.75)
= 90
> 5 ✔
n(1 - p) = 120(1 - 0.75)
= 30
> 5 ✔
we can approximate the distribution of p̂ using this
in situation 2:
n = 25
= 0.05 * 200
= 10
< 25
sample size is more than 5% if the population size
situation 3:
since we are given that the population is significantly larger than the sample size we can assume the first condition is satisfied
np = 45(0.9)
= 40.5
> 5 ✔
n(1 - p) = 45(1 - 0.9)
= 4.5
!> 5

Finding an approximate probability using the CLT for proportions
random sample size n = 84 from population where 42% of the population has a particular characteristic find a normal approximation for the probability that more than 50% of the sample has the characteristic, assume that the population size is significantly larger than the sample size.
n = 84
population proportion is p = 0.42
np = 84(0.42) = 35.28 > 5
n(1 - p) = 84(1 - 0.42) = 48.72 > 5
~ N(0.42, 0.42(1 - 0.42)/84)
~ N(0.42, 0.0029)
P(p̂ > 0.5) = P(Z > (0.5 - 0.42)/sqrt(0.0029))
= P(Z > 1.49)
= 1 - P(Z < 1.49)
= 1 - Φ(1.49)
Φ(1.49) = 0.9319
= 1 - 0.9319
= 0.0681

example:
a random sample of size n = 100 from a population where 60% of the population has a particular characteristic, find a normal approximation for the probability that between 55% and 65% of the sample have the characteristic
~ N(0.60, 0.60(1 - 0.60)/100)
~ N(0.60, 0.0024)
P(0.55 < p̂ < 0.65)
= P((0.55 - 0.60)/sqrt(0.0024) < Z < (0.65 - 0.60)/sqrt(0.0024))
-1.02 < Z < 1.02
Φ(1.02) - Φ(-1.02)

example:
a random sample of size n = 80 from a population where 42% of the population has a particular characteristic, find a normal approximation for the probability that more than 35% of the sample has the characteristic.
~ N(0.42, 0.42(1 - 0.42)/80)
~ N(0.42, 0.0030)
P(0.35 > p̂) = P(Z > (0.35 - 0.42)/sqrt(0.0030))
P(Z > -1.28)
= 1 - P(Z < -1.28)
= 1 - Φ(-1.28)
= 1 - 0.1003
= 0.8997

Finding an approximate probability using the CLT for proportions applications
Spotify has a db of 100 million songs, 64 million have a duration of less than 3 minutes, if a user creates a playlist with 128 songs find a normal approximation for the probability that between 64 and 96 (inclusive) songs in the sample have a duration less than 3 minutes. You may assume that the population size is significantly large than the sample size.
n = 128, poppulation proportion is p = 64000000/100000000 = 0.64
np = 128(0.64) = 81.92 > 5
n(1 - p) = 128(1 - 0.64) = 46.08 > 5
~ N(0.64, 0.64(1 - 0.64)/128)
~ N(0.64, 0.0018)
probability between 64 and 96 of the songs in the play list last less than 3 min
64/128 <= p̂ 96/128
0.5 <= p̂ <= 0.75
P(0.5 <= p̂ <= 0.75)
= P((0.5 - 0.64)/sqrt(0.0018) <= Z <= (0.75 - 0.64)/sqrt(0.0018))
= P(-3.30 <= Z <= 2.59)
= P(Z <= 2.59) - P(Z <= -3.30)
= Φ(2.59) - Φ(-3.30)
= 0.9952 - 0.0005
= 0.9947

example:
38% of households owns a computer. If a town randomly samples 200 households find a normal approximation for the probability that more than 80 of them have a computer.
n = 200
np = 200(0.38) = 76 > 5
n(1 - p) = 200(1 - 0.38) = 124 > 5
~ N(0.38, 0.38(1 - 0.38)/200)
~ N(0.38, 0.0011)
p > 80/200 = 0.4
(p̂ > 0.4) = P(Z > (0.4 - 0.38)/sqrt(0.0012))
= P(Z > 0.58)
= 1 - P(Z < 0.58)
= 1 - Φ(0.58)

example:
an online class of 900 students, 432 are female, the admins sample 50 students find a normal approximation for the probability that between 20 and 23 (inclusive) of students in the sample are female
n = 50, p = 432/900 = 0.48
np = 50(0.48) = 24 > 5
n(1 - p) = 50(1 - 0.48) = 26 > 5
~ N(0.48, 0.48(1 - 0.48)/50)
~ N(0.48, 0.005)
20/50 = 0.4, 23/50 = 0.46
P(0.4 <= p̂ <= 0.46)
= P((0.4 - 0.48)/sqrt(0.005) <= Z <= (0.46 - 0.48)/sqrt(0.005))
= P(-1.13 <= Z <= -0.28)
= P(Z <= -0.28) - P(Z <= -1.13)
= Φ(-0.28) - Φ(-1.13)
= 0.3897 - 0.1292
= 0.2605

===================================================

The sample covariance matrix
number of courses taken per semester and average final grade in a sample of 4 college students
# courses| 4| 3| 5| 4|
grade    |80|85|75|72|
collect data in a matrix
X = [
	 4  3  5  4
	80 85 75 72
]
matix X is called the obersation matrix
we want to determine the mean number of courses and the mean average grade of this sample, the sample mean vector denoted m
m = 1/n Σ^n_i=1(xi)
where x1,x2,...,xn are the individual (columns of X)
x1 = [4,80], x2 = [3,85], x3 = [5,75], x4 = [4,72]
sample mean vector
m = 1/4(x1 + x2 + x3 + x4)
= 1/4([4,80] + [3,85] + [5,75] + [4,72])
= 1/4[16,312]
= [4,78]
ther average # of courses 4 and average final grade is 78

Finding the sample mean of an observation matrix
X = [
	1 1 0 2
	2 5 3 2
]
x1 = [1,2], x2 = [1,5], x3 = [0,3], x4 = [2,2]
m = 1/4(x1 + x2 + x3 + x4)
= 1/4([1,2] + [1,5] + [0,3] + [2,2])
= 1/4[4,12]
= [1,3]

example:
X = [
	1 0 -2 5
	2 4 12 2
]
= 1/4([1,2] + [0,4] + [-2,12] + [5,2])
= 1/4([4,20])
= [1,5]

example:
X = [
	 7  8  0 -3
	-2 10 -3  3
]
= 1/4([7,-2] + [8,10] + [0,-3] + [-3,3])
= 1/4([12,8])
= [3,2]

Mean-Deviation form
to find the mean-deviation form of X first lets start out with observation matrix
X = [
	 4  3  5  4
	80 85 75 72
]
x1 = [4,80], x2 = [3,85], x3 = [5,75], x4 = [4,72]
mean vector
m = [4,78]
how much each observation differs from the mean values
b1 = x1 - m = [4,80] - [4,78] = [0,2]
b2 = x2 - m = [3,85] - [4,78] = [-1,7]
b3 = x3 - m = [5,75] - [4,78] = [1,-3]
b4 = x4 - m = [4,72] - [4,78] = [0,-6]
B = [
	0 -1  1  0
	2  7 -3 -6
]
B is the mean-deviation form of X its easier to work with the mean-deviation form especially if the original data contains large numbers, the mean of a mean-deviation form equals the zero vector:
m_B = 1/4([0,2] + [-1,7] + [1,-3] + [0,-6])
= 1/4([0,0])
= [0,0]

finding the mean deviation form of an observation matrix
X = [
	 5  9 4
	15 -7 1
]
find the mean deviation
x1 = [5,15], x2 = [9,-7], x3 = [4,1]
= 1/3([5,15] + [9,-7] + [4,1])
= 1/3[18,9]
= [6,3]
b1 = x1 - m = [5,15] - [6,3] = [-1,12]
b2 = x2 - m = [9,-7] - [6,3] = [3,-10]
b3 = x3 - m = [4,1] - [6,3] = [-2,-2]
mean-deviation
B = [
	-1  3  -2
	12 -10 -2
]

example:
X = [
	1 0 2
	2 3 1
]
x1 = [1,2], x2 = [0,3], x3 = [2,1]
= 1/3([1,2] + [0,3] + [2,1])
= 1/3[3,6]
= [1,2]
b1 = x1 - m = [1,2] - [1,2] = [0,0]
b2 = x2 - m = [0,3] - [1,2] = [-1,1]
b3 = x3 - m = [2,1] - [1,2] = [1,-1]

example:
X = [
	 7  6  8
	-1 -3 -2
]
x1 = [7,-1], x2 = [6,-3], x3 = [8,-2]
= 1/3([7,-1] + [6,-3] + [8,-2])
= 1/3[21,-6]
= [7,-2]
b1 = x1 - m = [7,-1] - [7,-2] = [0,1]
b2 = x2 - m = [6,-3] - [7,-2] = [-1,-1]
b3 = x3 - m = [8,-2] - [7,-2] = [1,0]

The covariance matrix
mean deviation matrix
B = [
	0 -1  1  0
	2  7 -3 -6
]
calculating the product BB^T
[
	0 -1  1  0
	2  7 -3 -6
][
	 0  2
	-1  7
	 1 -3
	 0 -6
] = [
	 2 -10
	-10 98
]
The entry in the first row first column (2) is the sum of the squares of the mean deviations of the number of courses
The entry in the second row second column (98) is the sum of the squares of the mean deviations of the final grades
The off diagonal entries (-10) are the sum of the products of the mean deviations
since there were 4 observations in total, if we divide each entry by 4 - 1 = 3 we will get a matrix C with the sample variances in the diagonal and the sample covaraince in the off-diagonal positions
C = 1/3[
	 2 -10
	-10 98
]
this matrix is called the covariance matrix of the data
in general the sample covariance matrix is
C = 1/n-1(BB^T)
B is the observation matrix in the mean-deviation form, and n is # of observations

Finding the covariance matrix
X = [
	 2 6 4
	-4 1 6
]
find the sample covariance matrix of data
sample covariance matrix
C = 1/n-1(BB^T)
sample mean
= 1/3([2,-4],[6,1],[4,6])
= 1/3[12,3]
= [4,1]
b1 = x1 - m = [2,-4] - [4,1] = [-2,-5]
b2 = x2 - m = [6,1] - [4,1] = [2,0]
b3 = x3 - m = [4,6] - [4,1] = [0,5]
mean-deviation form
B = [
	-2 2 0
	-5 0 5
]
C = 1/3-1[
	-2 2 0
	-5 0 5
][
	-2 -5
	 2  0
	 0  5
]
= 1/2[
	 8 10
	10 50
]

example:
B = [
	1 -2  4 -3
	0  3 -1 -2
]
find the sample covariance matrix
1/3[
	1 -2  4 -3
	0  3 -1 -2
][
	 1  0
	-2  3
	 4 -1
	-3 -2
] = 1/3[
	30 -4
	-4 14
]

example:
X = [
	1 -10 0
	3   3 0
]
find the sample covariance matrix
x1 = [1,3], x2 = [-10,3], x2 = [0,0]
= 1/3([1,3] + [-10,3] + [0,0])
= 1/3[-9,6]
= [-3,2]
b1 = x1 - m = [1,3] - [-3,2] = [4, 1]
b2 = x2 - m = [-10,3] - [-3,2] = [-7,1]
b3 = x3 - m = [0,0] - [-3,2] = [3,-2]
B = [
	 4 -7  3
	 1  1 -2
][
	 4  1
	-7  1
	 3 -2
] = 1/2[
	74 -9
	-9  6
]

===================================================

Product notation
summation is usually written using sigma notation
Σ^4_i=1(2i - 3)
represents the sum of the first 4 terms of the sequence ai = 2i - 3
= (2(1) - 3) + (2(2) - 3) + (2(3) - 3) + (2(4) - 3)
= (-1) + 1 + 3 + 5
= 8
similar compact notation for products
Π^4_i=1(2i - 3)
represents the product of the first 4 terms of the sequence ai = 2i - 3
Π^4_i=1(2i - 3)
= (2(1) - 3) * (2(2) - 3) * (2(3) - 3) * (2(4) - 3)
= (-1) * 1 * 3 * 5
= -15

Evaluating a product
Π^4_k=1(3k-1/6k-1)
expand the product by multiplying over the index k = (1-4)
= (3(1)-1/6(1)-1) * (3(2)-1/6(2)-1) * (3(3)-1/6(3)-1) * (3(4)-1/6(4)-1)
= 2/5 * 5/11 * 8/17 * 11/23
(before multiplying we can cross cancel the 11s and 5s)
= 2*8/17*23
= 16/391

example:
Π^6_k=2(2i + 1)
= (2(2) + 1) * (2(3) + 1) * (2(4) + 1) * (2(5) + 1) * (2(6) + 1)
= 5 * 7 * 9 * 11 * 13
= 45045

example:
Π^8_k=5(2k+1/1-2k)
= (2(5)+1/1-2(5)) * (2(6)+1/1-2(6)) * (2(7)+1/1-2(7)) * (2(8)+1/1-2(8))
= -11/9 * -13/11 * -15/13 * -17/15
= (-1)^4 * 17/9
= 17/9

Writing a product using product notation
(2 - 3^2) * (2 - 4^2) * (2 - 5^2) * ... * (2 - 12^2)
we can collapse the given expression using the product notation over the index i from i = 3 to i = 12
= Π^12_i=3(2 - i^2)

example:
(2*3^2 - 1) * (2*4^2 - 1) * (2*5^2 - 1) * ... * (2*n^2 - 1)
= Π^n_i=3(2*(i)^3 - 1)

example:
1^2/1^3-1 * 2^2/2^3-1 * 3^2/3^3-1 * ... * 10^2/10^3-1
Π^10_i=1((i)^2/(i)^3 - 1)

Simplifying a product
express Π^m_n=3(n+1/n-1) as a function of m
fist expand the product by multiplying over the index n = 3 to n = m
= 3+1/3-1 * 4+1/4-1 * 5+1/5-1 * 6+1/6-1 * ... * (m-1)+1/(m-1)-1 * m+1/m-1
= 4/2 * 5/3 * 6/4 * 7/5 * ... * m/m-2 * m+1/m-1
(canceling out common terms 7=m-2, 6=m-1)
= m*(m+1)/2*3
= m*(m+1)/6

example:
Π^n-1_m=2(2(m) + 2)
(substituting last term)
(2m+2) = (2(n-1)+2) = 2n-2+2 = 2n
= 6 * 8 * 10 * ... * 2n

example:
Π^m_r=2(r(r + 1)/r - 1)
= (2(2+1)/2-1) * (3(3+1)/3-1) * (4(4+1)/4-1) * ... * (m(m+1)/m-1)
= 3*2/1 * 4*3/2 * 5*4/3 * ... * (m(m+1)/m-1)
(canceling out common terms)
= 3 * 4 * 5 * ... * m*(m+1)
= (1 * 2 * 3 * 4 * 5 * ... * m * (m+1))/2
= (m + 1)!/2

===================================================

Logarithmic differentiation is a technique to compute derivatives that are difficult to find using the usual rules of differentiation such as the product, quotient, and chain rules
y = x^x 
we want to compute dy/dx
both the base and the exponent are functions of x
this means we cannot apply the power rule since the exponent is not a fixed number
We also cannot apply the rules for differentiating exponentials since the base is not a fixed number
so instead we'll use logarithmic differentiation
step 1: we take the natural logarithm of both sides and apply the power rule for logarithms:
y = x^x
ln(y) = ln(x^x)
ln(y) = xln(x)
step 2: we differentiate both sides of the above equation with respect to x using implicit differentiation and the product rule:
d/dx(ln(y)) = d/dx(xln(x))
1/y * dy/dx = d/dx(x) * ln(x) + x * d/dx(ln(x))
1/y * dy/dx = 1 * ln(x) + x * (1/x)
1/y * dy/dx = ln(x) + 1
step 3: now we solve for dy/dx
dy/dx = y(ln(x) + 1)
step 4: we substitute back our original expression for y = x^x
dy/dx = x^x(ln(x) + 1)

Differentiating X raised to the power of a function
find the derivative of the function y = x^(x^3)
first take the natural logarithm of both sides
ln(y) = ln(x^(x^3))
ln(y) = x^3ln(x)
next differentiate both sides with respect to x
d/dx(ln(y)) = d/dx(x^3ln(x))
1/y * y' = (x^3)' * ln(x) + (x^3) * ln(x)'
1/y * y' = 3x^2 * ln(x) + x^3 * 1/x
y'/y = 3x^2ln(x) + x^2
now we solve for y'
y' = y(3x^2ln(x) + x^2)
substitute y = x^(x^3)
y' = x(^(x^3)+2)(3ln(x) + 1)

example:
y = x^(2x) its derivative is given by
y' = 2x^(2x) * g(x)
find the function g(x)

ln(y) = ln(x^(2x))
ln(y) = 2xln(x)
respect to x
d/dx(ln(y)) = d/dx(2xln(x))
1/y * y' = (2x)' * ln(x) + 2x * (ln(x))'
y'/y = 2 * ln(x) + 2x * 1/x
solve for y'
y' = y(2ln(x) + 2)
substitute
y' = 2x^(2x)(ln(x) + 1)
g(x) = ln(x) + 1
(noticed we factored out a 2)

example:
consider the function y = x^(cos(x)) its derivative is
dy/dx = x^cos(x - 1) * g(x)
find the function g(x)
y = x^(cos(x))
ln(y) = ln(x^(cos(x)))
ln(y) = cos(x)ln(x)
respect to x
d/dx(ln(y)) = d/dx(cos(x)ln(x))
1/y * dy/dx = d/dx(cos(x)) * ln(x) + (cos(x)) * d/dx(ln(x))
1/y * dy/dx = (-sin(x)) * ln(x) + (cos(x)) * 1/x
1/y * dy/dx = -ln(x)sin(x) + cos(x)/x
solve for dy/dx
dy/dx = y(cos(x)/x - ln(x)sin(x))
substitute y = x^(cos(x))
(common denominator)
= x^(cos(x))(cos(x)/x - xln(x)sin(x)/x)
= x^(cos(x - 1))(cos(x) - xln(x)sin(x))
g(x) = cos(x) - xln(x)sin(x)

Differentitating a function raised to the power of X
find the derivative of the function
y = (x^2 - 1)^x
first we take the natrual logarithm of both sides
ln(y) = ln((x^2 - 1)^x)
ln(y) = xln(x^2 - 1)
respect to x
d/dx(ln(y)) = d/dx(xln(x^2 - 1))
1/y * dy/dx = d/dx(x) * ln(x^2 - 1) + x * d/dx(ln(x^2 - 1))
1/y * dy/dx = 1 * ln(x^2 - 1) + x * ((1/x^2 - 1) * 2x)
1/y * dy/dx = ln(x^2 - 1) + (2x^2/x^2 - 1)
now solve for dy/dx
dy/dx = y(ln(x^2 - 1) + (2x^2/x^2 - 1))
substitute
= (x^2 - 1)^x(ln(x^2 - 1) + (2x^2/x^2 - 1))
(common denominator)
= (x^2 - 1)^x((x^2 - 1)ln(x^2 - 1)/(x^2 - 1) + (2x^2/x^2 - 1))
= (x^2 - 1)^(x-1)((x^2 - 1)ln(x^2 - 1) + 2x^2)

example:
consider the function y = (2x)^x its derivative is
y' = (2x)^x * g(x)
first we take the natrual logarithm of both sides
ln(y) = ln((2x)^x)
ln(y) = xln(2x)
respect to x
d/dx(ln(y)) = d/dx(xln(2x))
1/y * dy/dx = d/dx(x) * ln(2x) + x * d/dx(ln(2x))
1/y * dy/dx = ln(2x) + x * 2 * 1/2x
1/y * dy/dx = ln(2x) + 1
substitute
y' = y(ln(2x) + 1)
y' = (2x)^x(ln(2x) + 1)
g(x) = ln(2x) + 1

example:
consider the function y = (x + 1)^x its derivative is
y' = (x + 1)^(x-1) * g(x)
find the function g(x)
first we take the natrual logarithm of both sides
ln(y) = ln((x + 1)^x)
ln(y) = xln(x + 1)
respect to x
d/dx(ln(y)) = d/dx(xln(x + 1))
1/y * dy/dx = d/dx(x) * ln(x + 1) + x * d/dx(ln(x + 1))
1/y * dy/dx = ln(x + 1) + (x/x + 1)
substitute
y' = y(ln(x + 1) + (x/x + 1))
y' = (x + 1)^x(ln(x + 1)(x + 1)/x + (x/x + 1))
y' = (x + 1)^(x-1)(ln(x + 1)(x + 1) + (x))
y' = (x + 1)^(x-1)((x + 1)ln(x + 1) + (x))
g(x) = (x + 1)ln(x + 1) + x

Differentiating a function raised to the power of a function
find the derivative of the function
y = (sin(x))^(cos(x))
first we take the natrual logarithm of both sides
ln(y) = ln(sin(x)^(cos(x)))
ln(y) = cos(x)ln(sin(x))
respect to x
d/dx(ln(y)) = d/dx(cos(x)ln(sin(x)))
1/y * y' = cos(x)' * (ln(sin(x))) + cos(x) * ln(sin(x))'
1/y * y' = (-sin(x)) * ln(sin(x)) + cos(x) (1/sin(x) * cos(x))
y'/y = cos(x)cot(x) - sin(x)ln(sin(x))
solve for y'
y' = y(cos(x)cot(x) - sin(x)ln(sin(x)))
substitute
y' = (sin(x))^(cos(x))(cos(x)cot(x) - sin(x)ln(sin(x)))

example:
consider the function y = (cos(x)^sin(x)) its derivative is
y' = (cos(x))^(sin(x)) * g(x)
find the function g(x)
first we take the natrual logarithm of both sides
ln(y) = ln(cos(x))^(sin(x))
ln(y) = sin(x)ln(cos(x))
respect to x
d/dx(ln(y)) = d/dx(sin(x)ln(cos(x)))
1/y * y' = (sin(x))' * ln((cos(x))) + sin(x) * (ln(cos(x)))'
1/y * y' = cos(x) * ln((cos(x))) + sin(x) * (1/cos(x) * (-sin(x)))
y'/y = cos(x)ln(cos(x)) - sin^2(x)/cos(x)
solve for y'
y' = y(cos(x)ln(cos(x)) - sin^2(x)/cos(x))
substitute
y' = cos(x)^(sin(x))(cos(x)ln(cos(x)) - sin^2(x)/cos(x))
= cos(x)^(sin(x))(cos(x)ln(cos(x)) - sin(x)tan(x))
g(x) = cos(x)ln(cos(x)) - sin(x)tan(x)

example:
find the slope of the tagent to the curve
y = (x + 1)^(x^2) at x = 1
first we take the natrual logarithm of both sides
ln(y) = ln((x + 1)^(x^2))
ln(y) = x^2ln((x + 1))
respect to x
1/y * y' = (x^2)' * ln(x + 1) + (x^2) * ln(x + 1)'
1/y * y' = 2x * ln(x + 1) + x^2 * 1/x+1
y'/y = 2x * ln(x + 1) + x^2/x+1
substitute:
y' = y(2xln(x + 1) + x^2/x+1)
y' = (x + 1)^(x^2)(2x * ln(x + 1) + x^2/x+1)
at x = 1
y'|_x=1 = (1 + 1)^(1^2)(2(1) * ln(1 + 1) + 1^2/1+1)
= 2^(1)(2 * ln(2) + 1/2)
= 4ln(2) + 1

===================================================

NOTE:
You may see a weird (4,xi) notation I use after the condensed product notation, think of it as a column 4 choose xi

Likelihood functions for discrete probability distributions
We might know the general form of the probability distribution for a population yet we may not know some of its underlying parameters. We want to develop strategies to estimate unknown population parameters from sample data. One strategy is to use likelihood functions.
suppose we have an Idependent and Identically distributed (I.I.D.) random sample
X1,X2,...,Xn
where the probability mass function of each Xi is given by
f(x;θ)
θ is an unknown a fixed parameter
and we have a sample from this distribution
x1,x2,...,xn
we define the likelihood function L(θ)
L(θ) = P(X1 = x1,X2 = x2,...,Xn = xn)
the likelihood function gives the probability of getting a particular smaple for a specific parameter value.
Since we assumed that all Xi's are independent and identically distributed by the multiplication law we have
L(θ) = P(X1 = x1,X2 = x2,...,Xn = xn)
= P(X1 = x1) * P(X2 = x2) ... P(Xn = xn)
= Π^n_i=1(P(Xi = xi))
= Π^n_i=1(f(xi;θ))
likelihood function is defined as
L(θ) = Π^n_i=1(f(xi;θ))

Worked example
suppose that
X1, X2, X3, X4, X5, X6
is an I.I.D random sample from a population where
Xi ~ Bernoulli(θ)
and θ is the unknown probability of success
we conduct a sample and get the following data
x1 = 0, x2 = 1, x3 = 1, x4 = 0, x5 = 1, x6 = 1
lets compute the likelihood
if X1, X2,...,Xn are I.I.D random variables with probability mass function f(x;θ) then the likelihood function of a random sample x1,x2,...,xn is
L(θ) = P(X1 = x1,X2 = x2,...,Xn = xn) = Π^n_i=1(f(xi;θ))
the probability mass function for a Bernoulli random variable with an unknown probability of success θ is
f(x;θ) = θ^x(1 - θ)^(1-x), x = 0,1
L(θ) = Π^n_i=1(f(xi;θ))
= Π^n_i=1(θ^(xi)(1 - θ)^(1-xi))
= (θ^(x1)(1 - θ)^(1-x1)) * (θ^(x2)(1 - θ)^(1-x2)) ... (θ^(xn)(1 - θ)^(1-xn))
= θ^(Σ(xi))(1 - θ)^(Σ(1-xi)))
= θ^(Σ(xi))(1 - θ)^(n - Σ(1-xi)))
= θ^(S)(1 - θ)^(n - S))
S = Σ^n_i=1(xi)
our sample we have n = 6
= 0 + 1 + 1 + 0 + 1 + 1
= 4
the likelihood function for this sample
L(θ) = θ^4(1 - θ)^(6 - 4)
= θ^4(1 - θ)^2
L(θ) has a maximum inside the interval [0,1] the value of θ(hat) that corresponds to the maximum likelihood is called the maximum likelihood estimate of the parameter θ for a given sample.

Likelihood functions for Bernoulli Random variables
X1,X2,...,X10 is an I.I.D random sample with Xi ~ Bernoulli(θ) and unknown probability of success θ for a particular smaple x1,x2,...,x10 given
Σ^10_i=1(xi = 7)
find the likelihood function of the sample
Hint: the probability mass function for a Bernoulli random variable is given by
f(x) = θ^x(1 - θ)^(1-x), x = 0,1
X1,X2,...,Xn are independent and identically distributed discrete random variables with probability mass function f(x;θ) where θ is an unknown parameter then the likelihood function of a random sample x1,x2,...,xn is
L(θ) = P(X1 = x1,X2 = x2,...,Xn = xn) = Π^n_i=1(f(xi;θ))
in this case sample of n = 10 independent Bernoulli random variables with unknonw parameter θ for which the probability mass function is
f(x;θ) = θ^x(1 - θ)^(1-x), x = 0,1
S = Σ^n_i=1(xi = 7) and n = 10
L(θ) = θ^7(1 - θ)^(10 - 7)
= θ^7(1 - θ)^3

example:
Σ^6_i=1(xi = 5)
= θ^5(1 - θ)^(6 - 5)
= θ^5(1 - θ)

example:
X1,X2,X3,X4,X5, is an I.I.D random sample with Xi ~ Bernoulli(θ) and unknown probability of success θ, find the likelihook of the sample 1,0,0,1,0
Σ^5_i=1(xi = 2)
= θ^2(1 - θ)^(5 - 2)
= θ^2(1 - θ)^3

Likelihood functions for Binomial random variables
X1,X2,...,X12 is an I.I.D random sample with Xi ~ B(4,θ) and unknown probability of success θ for a sample x1,x2,...,x12
Σ^12_i=1(xi = 22)
find the likelihood function of the sample up to a constant C
Hint: The probability mass function for a binomial random variable is given by:
f(x) = (4,x)θ^x(1 - θ)^(n - x), x = 0,1,2,3,4
in our case we have sample n = 12 binomial random variables with unknown probability of success θ and N = 4 trails for which the probability mass function is
f(x;θ) = (4,x)θ^x(1-θ)^(4-x), x = 0,1,2,3,4
L(θ) = Π^n_i=1(f(xi;θ))
= Π^n_i=1(4,xi)θ^xi(1 - θ)^(4-xi)
= ((4,x1)^x1(1 - θ)^(4-x1)) ... ((4,xn)^xn(1 - θ)^(4-xn))
= Cθ^(Σ(xi))(1 - θ)^(Σ(4 - xi))
= Cθ^(Σ(xi))(1 - θ)^(4n - Σ(xi))
= Cθ^S(1 - θ)^(4n - S)
where C = Π^n_i=1(4,xi) is a constant and S = Σ^n_i=1(xi)
S = Σ^n_i=1(xi = 22) and n = 12
L(θ) = Cθ^22(1 - θ)^(4(12) - 22)
= Cθ^22(1 - θ)^26

example:
X1,X2,...,X10 is an I.I.D random sample with Xi ~ B(5,θ) and unknown probability of success θ for a particular sample x1,x2,...,x3
Σ^10_i=1(xi = 36)
find the likelihood function of the sample up to a constant C
Hint: The probability mass function for a binomial random variable is given by
f(x) = (5,x)θ^x(1 - θ)^(n - x), x = 0,1,2,...,5
L(θ) = Cθ^36(1 - θ)^(5(10) - 36)
= Cθ^36(1 - θ)^14

example:
X1,X2,X3,X4 is an I.I.D random sample with Xi ~ B(6,θ) and unknown probability of success θ find the likelihood function of the sample 3,0,2,5 up to a constant C
= 3 + 0 + 2 + 5
= 10
Σ^4_i=1(xi = 10)
L(θ) = Cθ^10(1 - θ)^(6(4) - 10)
= Cθ^10(1 - θ)^14

Likelihood Functions for poisson random variables
X1,X2,X3,X4,X5 is an I.I.D random sample with Xi ~ Po(θ) and unknown rate parameter θ find the likelihood function of the sample 0,2,3,1,1
in our case we are given a sample of n = 5 independent Poisson random variables with unknown parameter θ for which the PMF is
f(x;θ) = θ^xe^-θ/x!, x = 0,1,2...
L(θ) = Π^n_i=1(f(xi;θ))
= Π^n_i=1(θ^xie^-θ/xi!)
= (θ^x1e^-θ/x1!) * (θ^x2e^-θ/x2!) ... (θ^xne^-θ/xn!)
= θ^(Σ(xi))*e^(-Σ(θ)) * Π^n_i=1(1/(xi)!)
= θ^(Σ(xi))*e^(-nθ) * 1/Π^n_i=1(xi)!
= 1/C(θ^S)*e(-nθ)
S = Σ^n_i=1(xi)
= 0 + 2 + 3 + 1 + 1
= 7
C = Π^n_i=1(xi)!
= 0! * 2! * 3! * 1! * 1!
= 1 * 2 * 6 * 1 * 1
= 12
n = 5
L(θ) = 1/12(θ^7)e^(-5θ)

example:
X1,X2,...,X16 is an I.I.D random sample with Xi ~ Po(θ) and unknown rate parameter θ for a particular sample x1,x2,...,x16
Σ^16_i=1(xi = 18), Π^16_i=1(xi!) = 6
find the likelihood function of a sample
Hint probability mass function for a Poisson distribution is
f(x) = (θ^xe^-θ/x!), x = 0,1,2,...
L(θ) = 1/6(θ)^18*e^(-16θ)

example:
X1,X2,X3,X4,X5 is an I.I.D random sample with Xi ~ Po(θ) and unknown rate parameter θ find the likelihood function of the sample 1,3,3,1,4
S = Σ^n_i=1(xi)
1 + 3 + 3 + 1 + 4
= 12
C = Π^n_i=1(xi!)
1! * 3! * 3! * 1! * 4!
= 1 * 6 * 6 * 1 * 24
= 864
L(θ) = (1/864)(θ^12)(e^(-5θ))

===================================================

NOTE:
binomial coefficient (n, k) is calculated as follows
(n
 k) = n!/k!(n-k)!
example:
(5
 3) = 5!/3!(5 - 3)! = 5!/3!*2! = 5*4/2*1 = 10

Log-likelihood functions for discrete probability distributions
if X1,X2,...,Xn are independent and indentically distributed discrete random variables with probability mass function f(x;θ) where θ is an unkown parameter then the likelihood function of a random sample x1,x2,...,xn is
L(θ) = Π^n_i=1f(xi;θ)
if: X1,X2,X3,X4,X5,X6
is an I.I.D random sample with Xi ~ Bernoulli(θ) where θ is the unknown probability of success then the likelihood function of the sample
x1 = 0, x2 = 1, x3 = 1, x4 = 0, x5 = 1, x6 = 1
is given by
L(θ) = θ^4(1 - θ)^2
The likelihood function contains lots of products which can be cumbersome to make things easier we convert the products into sums by finding the natural logarithm of L(θ)
l(θ) = ln(L(θ))
= ln(Π^n_i=1(f(xi;θ)))
= ln(f(x1;θ) * f(x2;θ) ... f(xn;θ))
= ln(f(x1;θ)) + ln(f(x2;θ)) + ... + ln(f(xn;θ))
= Σ^n_i=1(ln(f(xi;θ)))
This new function l(θ) is called the log-likelihood function of the sample
the corresponding log-likelihood function
l(θ) = ln(θ^4(1 - θ)^2)
= ln(θ^4) + ln((1 - θ)^2)
= 4ln(θ) + 2ln(1 - θ)

Log-likelihood functions for Bernoulli random variables
X1,X2,...,X10 is an I.I.D random sample where Xi ~ Bernoulli(θ) with unknown probability of success θ for a particular sample x1,x2,...,x10 you're given that there are 7 successes find the log-likelihood function of the sample.
we are given a sample of n = 10 independent Bernoulli random variables with unknown parameter θ therefore the probability mass function is
f(x;θ) = θ^x(1 - θ)^(1 - x), x = 0,1
l(θ) = Σ^n_i=1ln(θ^(xi)(1 - θ)^(1-xi))
= Σ^n_i=1(xi)ln(θ^(xi)) + ln((1 - θ)^(1-xi))
= ln(θ)Σ^n_i=1(xi) + ln(1 - θ)Σ^n_i=1(1 - xi)
= Sln(θ) + (n - S)ln(1 - θ)
S = Σ^n_i=1(xi) is the number of successes in the sample
finally since there are 7 successes in the sample
l(θ) = 7ln(θ) + (10 - 7)ln(1 - θ)
= 7ln(θ) + 3ln(1 - θ)

example:
X1,X2,...,X12 is an I.I.D random sample where Xi ~ Bernoulli(θ) with unknown probability of success θ for a particular sample, x1,x2,...,x12 you're given that there are 5 successes find the log-likelihood function of the sample
l(θ) = 5ln(θ) + (12 - 5)ln(1 - θ)
= 5ln(θ) + 7ln(1 - θ)

example:
X1,X2,...,X20 is an I.I.D random sample where Xi ~ Bernoulli(θ) with unknown probability of success θ for a sample x1,x2,...,x20 you're given that there are 14 successes find the log-likelihood function of the sample
l(θ) = 14ln(θ) + (20 - 14)ln(1 - θ)
= 14ln(θ) + 6ln(1 - θ)

Log-Likelihood functions for binomial random variables
X1,X2,X3 is an I.I.D random sample Xi ~ B(5,θ) with unknown probability of success θ you're given the particular sample
x1 = 4, x2 = 1, x3 = 1
find the log-likelihood function of this sample
Hint: The probability mass function for a binomial random variable is given by
f(x) = (5,x)θ^x(1 - θ)^(n - x), x = 0,1,...,5
in our case we are given a sample of n = 3 independent binomial random variables with an unknown probability of success θ and N = 5 as the number of trials, the probability mass function is
f(x,θ) = (N,x)θ^x(1 - θ)^(N - x), x = 0,1,...,N
= (5,x)θ^x(1 - θ)^(5 - x), x = 0,1,...,5
l(θ) = Σ^n_i=1(ln((5,xi)θ^xi(1 - θ)^(5 - xi)))
= Σ^n_i=1(ln(5,xi) + ln(θ^xi) + ln((1 - θ)^(5 - xi)))
= Σ^n_i=1(ln(5,xi) + Σ^n_i=1(xiln(θ)) + Σ^n_i=1(5-xi)ln(1 - θ))
= Σ^n_i=1(ln(5,xi) + ln(θ)Σ^n_i=1(x1) + ln(1 - θ)Σ^n_i=1(5-xi))
= Σ^n_i=1(ln(5,xi) + Sln(θ) + (5n - S)ln(1 - θ))
Σ^n_i=1(ln(5,xi) = ln(5,x1) + ln(5,x2) + ln(5,x3))
= ln(Π^n_i=1(5,xi))
l(θ) = ln(Π^n_i=1(5,xi)) + Slnθ + (5n - S)ln(1 - θ)
sample data with n = 3
Π^n_i=1(5,xi) = (5,4)*(5,1)*(5,1)
= 5*5*5
= 125
S = 4 + 1 + 1 = 6
substitution
l(θ) = ln(125) + 6ln(θ) + (5 * 3 - 6)ln(1 - θ)
= ln(125) + 6ln(θ) + 9ln(1 - θ)

example:
X1,X2,X3,X4 is an I.I.D random sample with Xi ~ B(3,θ) with unknown probability of success θ you're given the sample
x1 = 2, x2 = 1, x3 = 2, x4 = 0
l(θ) = ln(a) + bln(θ) + cln(1 - θ)
find the value of a + b + c
Hint: the probability mass function for a binomial random variable is given by
f(x) = (3,x)θ^x(1 - θ)^(n - x), x = 0,1,2,...,3
(3,2)*(3,1)*(3,2)*(3,0)
3*3*3*1 = 27
2 + 1 + 2 + 0 = 5
= ln(27) + 5ln(θ) + (3 * 4 - 5)ln(1 - θ)
= ln(27) + 5ln(θ) + 7ln(1 - θ)
a + b + c = 39

example:
X1,X2,X3,X4 is an I.I.D random sample with Xi ~ B(5,θ) with unknown probability of success θ given the sample
x1 = 5, x2 = 3, x3 = 2, x4 = 1
ln(θ) = ln(a) + bln(θ) + cln(1 - θ)
find the value of a + b + c
(5,5)(5,3)(5,2)(5,1)
1*10*10*5 = 500
5+3+2+1 = 11
substituting
ln(500) + 11ln(θ) + 9ln(1 - θ)
500 + 11 + 9 = 520

Log-likelihood functions for Poisson random variables
X1,X2,X3 is an I.I.D random sample with Xi ~ Po(θ) with unknown rate parameter θ with sample
x1 = 3, x2 = 4, x3 = 1
find the log-likelihood function
In our case we are given a sample of n = 3 independent Poisson random variables with unknown parameter θ the probability mass function is
f(x,θ) = e^-θ * θ^x/x!
l(θ) = Σ^n_i=1(ln(e^-θ * θ^x/x!))
= Σ^n_i=1(ln(e^-θ) + ln(θ^xi) ln(x!))
= Σ^n_i=1(-θ) + Σ^n_i=1(ln(θ^xi)) - Σ^n_i=1(ln(xi!))
= Σ^n_i=1(-θ) + Σ^n_i=1(xiln(θ)) - Σ^n_i=1(ln(xi!))
= -θΣ^n_i=1(1) + ln(θ)Σ^n_i=1(xi) - Σ^n_i=1(ln(xi!))
= -nθ + lnθΣ^n_i=1(xi) - ln(Π^n_i=1(xi!))
using the same data with n = 3
Π^n_i=1(xi!) = 3! * 4! * 1! = 6 * 24 * 1 = 144
Σ^n_i=1(xi) = 3 + 4 + 1 = 8
l(θ) = -3θ + 8ln(θ) - ln(144)

example:
X1,X2,X3,X4 is an I.I.D random sample with Xi ~ Po(θ) with unknown rate parameter θ given the sample
x1 = 4, x2 = 2, x3 = 1, x4 = 2
l(θ) = aθ + bln(θ) - lnc
find the value of a + b + c
Hint: the probability mass function for a poisson distribution is
f(x) = θ^xe^-θ/x!, x = 0,1,2,...
4! * 2! * 1! * 2! = 96
l(θ) = -4θ + 9ln(θ) - ln(96)
a + b + c = 101

example:
X1,X2,X3 is an I.I.D random sample with Xi ~ Po(θ) with unknown rate parameter θ given the sample
x1 = 3, x2 = 4, x3 = 2
3! * 4! * 2! = 288
3+4+2 = 9
l(θ) = -3θ + 9ln(θ) - ln(288)
a + b + c = 294

===================================================

Likelihood functions of samples drawn from populations modeled using continuous random variables are defined similarly to discrete variables. The only difference is that we use probability density functions instead of probability mass functions
if X1,X2,...,Xn are independent and identically distributed continuous random variables with probability density function f(x;θ) then the likelihood function of a random sample x1,x2,...,xn
L(θ) = P(X1 = x1,X2 = x2,...,Xn = xn) = Π^n_i=1f(xi;θ)
let X1,X2,X3 be continuous, I.I.D random variables with the following probability density function
f(x) = θx^(-θ-1), x >= 1
θ is an unknown parameter, conduct our random sample 
x1 = 2.5, x2 = 3.2, x3 = 1.2
compute the likelihood
L(θ) = Π^n_i=1(θxi^(-θ-1))
= (θx1^(-θ-1)) * (θx2^(-θ-1)) ... (θxn^(-θ-1))
= θ^n (x1^(-θ-1)) * (x2^(-θ-1)) ... (xn^(-θ-1))
= θ^n(x1 * x2 ... xn)^(-θ-1)
= θ^n(Π^n_i(xi))^(-θ-1)
our sample n = 3
Π^n_i(xi) = 2.5 * 3.2 * 1.2 = 9.6
L(θ) = θ^3(9.6)^(-θ-1)

Likelihood functions for continuous random variables
X1,X2,X3 be I.I.D. random variables with probability density function
f(x) = (θ + 1)x^(-θ-2), x >= 1
where θ is an unknown parameter, find the likelihood of the sample 2.0, 4.5, 5.1
Π^n_i=1(xi) = 2.5 * 4.5 * 5.1 = 45.9
n = 3
L(θ) - (θ + 1)^3(45.9)^(-θ-2)

example:
X1,X2,...,X15 be I.I.D. random variables with probability density function
f(x) = θx^(-θ-1), x >= 1
where θ is an unknown parameter for a particular sample x1,x2,...,x15
Π^15_i=1(xi) = 40.6
= θ^15(40.6)^(-θ-1)

example:
X1,X2,X3 be I.I.D random variables with probability density function
f(x) = θx^(-θ-1), x >= 1
where θ is an unknown parameter find the likelihood function of the sample:
2.1, 3.2, 5.0
Π^n_i=1(xi) = 2.1 * 3.2 * 5.0 = 33.6
n = 3
L(θ) - (θ + 1)^3(33.6)^(-θ-1)

Likelihood functions for exponential random variables
X1,X2,...X6 is an I.I.D random sample with Xi ~ Exp(θ) and unknown rate parameter θ find the likelihood of the sample
1.5, 2.0, 1.1, 0.4, 3.3, 2.7
sample of n = 6 independent exponential random variables with unknown parameter θ for which the probability density function is
f(x,θ) = θe^(-θx), x >= 0
calculate the likelihood function
L(θ) = Π^n_i=1(θe^(-θxi))
= (θe^(-θx1)) * (θe^(-θx2)) ... (θe^(-θxn))
= θ^n e^(-θ(x1 + x2 + ... + xn))
= θ^n e^(-θΣ(xi))
= θ^n e^(-Sθ)
= 1.5 + 2.0 + 1.1 + 0.4 + 3.3 + 2.7
= 11
L(θ) = θ^6e^(-11θ)

example:
X1,X2,...X7 is an I.I.D random sample with Xi ~ Exp(θ) and unknown rate parameter θ for a sample x1,x2,...,x7
Σ^7_i=1(xi) = 18.2
find the likelihood sample
Hint: The probability density function for an exponential random variable is given by
f(x) = θe^(-θx), x >= 0
= θ^7e^(-18.2θ)

example:
X1,X2,X3,X4 is an I.I.D random sample with Xi ~ Exp(θ) and unknown rate parameter θ find the likelihood of sample 2.1, 5.0, 4.2, 1.4
= 12.7
L(θ) = θ^4e^(-12.7θ)

The normal distibution
the probability density function of a normally distributed random variable X ~ N(μ,σ^2)
f(x) = 1/σsqrt(2pi)e^(-1/2(x-μ/σ))^2
if we set σ = 1 then f(x) simplifies
f(x) = 1/sqrt(2pi)e^-(x-μ)^2/2
this is a standard normal random variable whose mean is shifted right by μ units
finally setting the unknown parameter as θ when discussing likelihood functions is common, following this convention we set μ = θ
f(x;θ) = 1/sqrt(2pi)e^-(x-θ)^2/2

Likelihood functions for normal random variables
X1,X2,X3,X4 is an I.I.D random sample with Xi ~ N(θ,1) where θ is an unknown mean find the likelihood function of the sample
0.4, -0.3, -2.2, -0.4
sample n = 4 independent normal random variables with unknown mean θ and variance σ^2 = 1 for which the probability density function is
f(x,θ) = 1/σsqrt(2pi)e^(-1/2(x-θ/σ))^2 = 1/sqrt(2pi)e^-(x-θ)^2/2
we can calculate the likelihood
L(θ) = Π^n_i(1/sqrt(2pi)e^-(x-θ)^2/2)
= (2pi)^(-n/2)e^-Σ(xi-θ)^2/2
= (2pi)^(-n/2)e^-(Σ(xi^2-2θ)Σ(xi+nθ^2))/2
= (2pi)^(-n/2)e^-(C - 2Sθ + nθ^2)/2
S = Σ^n_i=1(xi) and C = Σ^n_i=1(xi^2)
sample is n = 4
S = Σ^n_i=1(xi)
= 0.4 + (-0.3) + (-2.2) + (-0.4)
= -2.5
C = Σ^n_i=1(xi^2)
= (0.4)^2 + (-0.3)^2 + (-2.2)^2 + (-0.4)^2
= 5.25
L(θ) = (2pi)^(-4/2)e^-(5.25 - 2(-2.5)θ + 4θ^2)/2
= 1/4pi^2e^(-2.625 - 2.5θ - 2θ^2)

example:
X1,X2,...,X12 is an I.I.D random sample with Xi ~ N(θ,1) where θ is an unknown mean for a sample x1,x2,...,x12
Σ^12_i=1(xi) = 7.4, Σ^12_i=1(xi^2) = 16.8
given that the likelihood function of the sample is
L(θ) = 1/64pi^6e^g(θ)
what is the expression for g(θ)
Hint: the probability density function for a normal random variable with mean θ and variance 1
f(x) = 1/sqrt(2pi)e^-((x-θ)^2/2)
= 1/64pi^6(-8.4 + 7.4θ - 6θ^2)
g(θ) = -8.4 + 7.4θ - 6θ^2

example:
X1,X2,X3,X4 is an I.I.D random sample with Xi ~ N(θ,1) where θ is an unknown mean given the likelihood of the sample -1.2, 0.4, 2.2, 0.8
L(θ) = 1/4pi^2e^(g(θ))
what is the expression for g(θ)
S = Σ^n_i=1(xi)
= (-1.2) + 0.4 + 2.2 + 0.8
= 2.2
C = Σ^n_i=1(xi^2) 
= (-1.2)^2 + 0.4^2 + 2.2^2 + 0.8^2
= 7.08
= 1/4pi^2e^-(7.08 - 2(2.2)θ + 4θ^2)/2
= 1/4pi^2e^(-3.54 + 2.2θ - 2θ^2)

===================================================

Similar to the case of discrete random variables the log-likelihood function for continuous probability distributions
l(θ) = ln(L(θ))
= ln(Π^n_i=1(f(xi;θ)))
= ln(f(x1;θ) * f(x2;θ) ... f(xn;θ))
= ln(f(x1;θ)) + ln(f(x2;θ)) + ... + ln(f(xn;θ))
= Σ^n_i=1(ln(f(xi;θ)))

Log-likelihood function for continuous random variables
X1,X2,X3,X4 be I.I.D random variables with probability density function
f(x) = θx^(-θ-1), x >= 1
where θ is unknown, find the likelihood function of the sample
1.3, 2.4, 1.0, 1.7
first the log-density function
ln(f(x;θ)) = ln(θx^-θ-1)
= ln(θ) + ln(x^-(θ + 1))
= ln(θ) - (θ + 1)ln(x)
calculate the log-likelihood
l(θ) = Σ^n_i=1(ln(θ) - (θ + 1)ln(xi))
= Σ^n_i=1(ln(θ)) - Σ^n_i=1(θ + 1)ln(xi)
= nln(θ) - (θ + 1)Σ^n_i=1(ln(xi))
for the sample n = 4
Σ^n_i=1(ln(xi)) = ln(1.3) + ln(2.4) + ln(1.0) + ln(1.7)
~= 1.67
ln(θ) ~= 4ln(θ) - (θ + 1) * 1.67
= 4ln(θ) - 1.67(θ + 1)

example:
X1,X2,...,X12 be I.I.D random variables with probability density function
f(x) = θx^-θ-1, x >= 1
θ is an unknown parameter for a sample x1,x2,...,x12
Σ^12_i=1(ln(xi)) ~= 13.45
the log-likelihood function
l(θ) = aln(θ) - b(θ + 1)
what is the value of a + b?
l(θ) = 12ln(θ) - 13.45(θ + 1)
a = 12 + 13.45

example:
X1,X2,X3 be I.I.D random variables with probability density function
f(x) = θx^-θ-1, x >= 1
θ unknown, the log-likihood function of the sample 2.0, 3.2, 5.5
l(θ) = aln(θ) - b(θ + 1)
what is the value of a + b?
Σ^n_i=1(ln(xi)) = ln(2.0) + ln(3.2) + ln(5.5)
~= 3.56
l(θ) = 3ln(θ) - 3.56(θ + 1)
a + b = 3 + 3.56 ~= 6.56

Log-likelihood functions for exponential random variables
X1,X2,X3,X4,X5 is an I.I.D random sample Xi ~ Exp(θ) and unknown rate parameters θ find the log-likelihood of the sample 2, 4, 1, 3, 7
Σ^n_i=1(xi) = 2 + 4 + 1 + 3 + 7 = 17
n = 5
l(θ) = 5ln(θ) - θ * 17
= 5ln(θ) - 17θ

example:
X1,X2,...,X8 is an I.I.D random sample with Xi ~ Exp(θ) and unknown rate parameter θ for a sample x1,x2,...,x8
given:
Σ^8_i=1(xi) = 28.4
l(θ) = aln(θ) + bθ
what is a + b?
l(θ) = 8ln(θ) + (-28.4)θ
a + b = 8 + (-28.4) = -20.4

example:
X1,X2,X3 is an I.I.D random sample Xi ~ Exp(θ) and an unknown rate parameter θ the log-likelihood function of the sample 5.1, 4.2, 6.3
l(θ) = aln(θ) + bθ
Σ^n_i=1(xi) = 5.1 + 4.2 + 6.3 = 15.6
n = 3
l(θ) = 3ln(θ) + (-15.6)θ
a + b = 3 + (-15.6) = -12.6

Log-Likelihood functions for normal random variables
X1,X2,...,X8 is an I.I.D random sample with Xi ~ N(θ,1^2) where θ is an unknown mean we are given
Σ^8_i=1(xi) = 11.8, Σ^8_i=1(xi^2) = 25.2,
Hint: The probability density function for a normal random variable with mean θ and SD 1
f(x) = 1/sqrt(2pi)e^-(x-θ)^2/2
first we can write down the log-density function
ln(x,θ) = ln(1/sqrt(2pi)e^(-(x-θ)^2/2))
= ln(1/sqrt(2pi)) + ln(e^(-(x-θ)^2/2))
= -1/2ln(2pi) - (x - θ)^2/2
calculate
l(θ) = Σ^n_i=1(-1/2 * ln(2pi) - (xi - θ)^2/2)
= -n/2 * ln(2pi) - Σ^n_i=1((xi - θ)^2/2)
= -n/2 * ln(2pi) - 1/2(Σ^n_i=1(xi^2) - 2θΣ^n_i=1(xi) + nθ^2)
Σ^8_i=1(xi) = 11.8, Σ^8_i=1(xi^2) = 25.2, and n = 8
l(θ) = -8/2 * ln(2pi) - 1/2(25.2 - 2θ * 11.8 + 8θ^2)
= -4 * ln(2pi) - 12.6 + 11.8θ - 4θ^2

example:
X1,X2,...,X12 is an I.I.D random sample with Xi ~ N(θ,1^2) where θ is an unknown mean for a sample x1,x2,...,x12
given
Σ^12_i=1(xi) = 30.2, Σ^12_i=1(xi^2) = 90.6
l(θ) = -6ln(2pi) + a + bθ + cθ^2
what is the value of a + b + c
the probability density function for a normal random variable with mean θ and SD 1
f(x) = 1/sqrt(2pi)e^(-(x-θ)^2)/2
ln(θ) = -12/2(2pi) - 1/2(90.6 - 2θ*30.2 + 12θ^2)
= -6ln(2pi) + (-45.3) + (30.2)θ + (-6)θ^2
a + b + c = (-45.3) + 30.2 + (-6) = -21.1

example:
X1,X2,X3,X4 is an I.I.D random sample with Xi ~ N(θ,1^2) where θ is an unknown mean, the log-likelihood function of the sample 1.2, 0.4, 0.2, -2.0
ln(θ) = -2(2pi) + a + bθ + cθ^2
what is the value of a + b + c?
Σ^4_i=1(xi) = -0.2, Σ^4_i=1(xi^2) = 5.64
ln(θ) = -4/2(2pi) - 1/2(5.64 - 2θ*(-0.2) + 4θ^2)
= -2(2pi) - 2.82 - 0.2θ - 2θ^2)
a + b + c = -2.82 + (-0.2) + (-2) = -5.02

===================================================

Maximum likelihood estimation
we have a random sample X1,X2,X3 drawn from a population where Xi ~ B(5,θ) where θ is an unknown probability of success, given the data
x1 = 4, x2 = 1, x3 = 1
it can be shown that the log-likelihood for this sample is
l(θ) = ln(125) + 6ln(θ) + 9ln(1 - θ)
goal is to form an estimate for the unkown θ to do this we find the value of θ that maximizes the probability of getting the observed sample data, we need to maximize the likelihood function L(θ) since the natural logarithm is an increasing function, a value of θ that maximizes the likelihood function L(θ) will also maximize the log-likelihood function l(θ)
Estimates of an unknown parameter θ by maximizing the likelihood function (or log-likelihood function) are called maximum likelihood estimates, we'll use the θ(hat) notation to denote a max likelihood estimate of θ
To find the max likelihood estimate of θ we calculate the derivative of the log-likelihood function, set the derivative equal to zero and solve for θ
first take the derivative of l(θ)
dl/dθ = d/dθ(ln(125) + 6lin(θ) + 9ln(1 - θ))
= 6/θ + 9/1-θ * (-1)
= 6/θ + 9/θ-1
set the derivative equal to 0 solve for θ
6/θ + 9/θ-1 = 0
(distribute each denominator)
(6(θ - 1) + 9θ)/(θ(θ - 1)) = 0
6(θ - 1) + 9θ = 0
15θ - 6 = 0
15θ = 6
θ = 6/15
for this sample the max likelihood estimate of θ is θ(hat) = 6/15
its easy to check that this is a max of l(θ) by calculating second derivative

Maximum likelihood estimators for discrete probability distributions
given that the log-likelihood function for a particular sample of independent Bernoulli random variables is
l(θ) = 3ln(θ) + 4ln(1 - θ)
what is the max likelihood estimate θ(hat) from this sample?
In order to find the maximum likelihood estimate of θ we calculate the derivative of the log-likelihood function set the derivative to 0 and solve for θ
derivative of l(θ)
dl/dθ = d/dθ(3ln(θ) + 4ln(1 - θ))
= 3/θ + 4/1-θ * (-1)
= 3/θ + 4/θ-1
then set the derivative equal to 0 and solve for θ
3/θ + 4/θ-1 = 0
(3(θ - 1) + 4θ)/(θ(θ - 1)) = 0
3(θ - 1) + 4θ = 0
7θ - 3 = 0
7θ = 3
θ = 3/7
the max likelihood esitmate of θ is θ(hat) = 3/7

example:
given that the log-likelihood function for a particular sample of independent Bernoulli random variables is
l(θ) = 5ln(θ) + ln(1 - θ)
what is the max likelihood estimate θ(hat) from this sample?
dl/dθ = d/dθ(5ln(θ) + ln(1 - θ))
= 5/θ + 1/1-θ * (-1)
= 5/θ + 1/θ-1
5/θ + 1/θ-1 = 0
(5(θ-1) + 1(θ-1))/θ(θ-1)
5θ - 5 + θ = 0
6θ = 5
θ = 5/6

example:
given the log-liklihood function for a particular sample of independent binomial random variables is
l(θ) = ln(27) + 5ln(θ) + 7ln(1 - θ)
what is the max likelihood estimate from this sample?
dl/dθ = d/dθ(ln(27) + 5ln(θ) + 7ln(1 - θ))
= 5/θ + 7/(1 - θ) * (-1)
= 5/θ + 7/(θ - 1)
5/θ + 7/(θ - 1) = 0
(5(θ - 1) + 7θ)/θ(θ - 1) = 0
5θ - 5 + 7θ = 0
12θ = 5
θ = 5/12
max likelihood of θ is 5/12

example:
given that the log-likelihood for a particular sample of independent Poisson random variables is
l(θ) = -16θ + 18ln(θ) - ln(2)
dl/dθ = d/dθ(-16θ + 18ln(θ) - ln(2))
= -16 + 18/θ
(-16θ + 18)/θ = 0
-16θ + 18 = 0
-16θ = -18
θ = 18/16
θ = 9/8
max likelihood is 9/8

Maximum likelihood estimators for continuous probability distributions
given that the log-likelihood function for a particular sample of independent normal random variables Xi ~ N(θ,1)
l(θ) = -6ln(2pi) - 8.4 + 12.1θ - 6θ^2
what is the maximum likelihood estimate θ for this sample?
d/dθ = d/dθ(-6ln(2pi) - 8.4 + 12.1θ - 6θ^2)
= 12.1 - 12θ
set the derivative equal to 0 and solve θ
12.1 - 12θ = 0
12θ = 12.1
θ ~= 1.008
max likelihood estimate of θ is ~1.008 (rounded to 3 decimal places)

example:
given that the log-likelihood function for a particular sample of independent exponential random variables is
l(θ) = 8ln(θ) - 28.4θ
what is the max likelihood estimate θ
d/dθ = d/dθ(8ln(θ) - 28.4θ)
= 8/θ - 28.4θ
8/θ - 28.4 = 0
8/θ = 28.4
8 = 28.4θ
θ ~= 2.82

example:
given that the log-likelihood function for a particular sample of the independent normal random variables
l(θ) = -6ln(2pi) - 45.3 + 30.2θ - 6θ^2
ehat is the max likelihood?
d/dθ = d/dθ(-6ln(2pi) - 45.3 + 30.2θ - 6θ^2)
= 30.2 - 12θ
30.2 - 12θ = 0
12θ = 30.2
θ ~= 2.517

Deriving a maximum likelihood estimator for Bernoulli Distributions
lets derivate a general expression for the maximum likelihood estimator for the unknown parameter θ for a set of n independent and identically distributed Bernoulli random variables
X1,X2,...,Xn is an I.I.D random sample where Xi ~ Bernoulli(θ) with unknown probability of success θ for a particular sample x1,x2,...,xn the log-likelihood function is given
l(θ) = Sln(θ) + (n - S)ln(1 - θ)
S = Σ^n_i=1(xi) is the number of successes in the sample
to compute a general expression for the max likelihood estimate we differentiate l(θ) set the derivative equal to zero solve for θ
dl/dθ = d/dθ(Sln(θ) + (n - S)ln(1 - θ))
= S/θ + (n - S)/(1 - θ) * (-1)
= S/θ + (n - S)/(θ - 1)
set the derivative to 0 and solve for θ
S/θ + (n - S)/(θ - 1) = 0
(S(θ - 1) + (n - S)θ)/θ(θ - 1) = 0
S(θ - 1) + (n - S)θ = 0
Sθ - S + nθ - Sθ = 0
-S + nθ = 0
nθ - S = 0
nθ = S
θ = S/n
θ = 1/nΣ^n_i=1(xi)
max likelihood estimate of θ is
θ(hat) = 1/nΣ^n_i=1(xi)
which is simply the mean of the sample
the maximum likelihood estimate for other common distributions can be derived similarly

max likelihood for several common probability distributions. These results can be derived by maximixing the log-likelihood function
distribution | PMF f(x;θ)
--------------------------------------------------
Bernoulli    |θ^x(1-θ)^(1-x)
Binomial     |(N,x)θ^x(1-θ)^(N-x)
Poisson	     |θ^xe^-θ/x!
Geometric    |(1 - θ)^(x-1)θ
Exponential  |θe^(-θx)
Normal       |1/θ_2sqrt(2pi)e^(-1/2(x-θ_1/θ_2)^2)

===================================================

Hypothesis testing is a statistical technique used to make inferences about population parameters based on sample data
we have a coin that we suspect is biased towards landing on heads. We wish to design and conduct a statistical experiment to determine whether or not our suspicions are correct we can use a hypothesis test for this purpose
we first define the population parameter we're interested in so we define p as the probability that the coin lands on heads when tossed randomly
next specify hypotheses
form a null hypothesis the null hypothesis states that the coin is not biased toward landing on heads we write this as
H_0 : p = 1/2
next form an alternative hypothesis the alternative hypothesis states that the coin is biased toward landing on heads
H_1 : p > 1/2
greater than symbol if the coin is biased towards heads, then the probability that the coin lands on heads must be greater than 1/2
Test experiment, flip the coin 10 time and count the total number of heads.
The test statistic is computed from experimental data, the test statistic must provide evidence for or against the population parameter p we wish to test.
in this case we might define a suitable test statistic as follows
X = the number of times the coin lands on heads after 10 random tosses.
we have defined suitable null hypotheses, designed an experiment and specified an appropriate test statistic we can compute using results from the experiment
To confirm our suspicions we need to collect enough data to reject the null hypothesis in favor of the alternative hypothesis
The experiment we've designed says that we should toss the coin 10 times and compare the proportion of tosses that land on heads with the value of p given by the null hypothesis
if the result of the experiment is statistically significant, it is unlikely to have happened purley by chance under the assumptions laid out by the null hypothesis then we reject the null hypothesis in favor of the alt hypothesis and conclude the coin is biased
Otherwise if there is insufficient statistical evidence we fail to reject the null hypothesis
Since the alternative hypothesis involves an inequality we call this a one-tailed hypothesis test.

The types of population parameters that we might make inferences about using hypothesis tests
A population mean μ for example the average IQ score among a certain population
A population variance σ^2 for example the variance of the IQ scores amount a certain population
A population proportion (or probability) p. For example the probability that a coin lands on heads when tossed randomly
A population average rate λ for example the average number of sales per hour made through a particular e-commerce website

Identifying null and alternative hypothesis
Tesla produces cars with a mean battery efficiency of 35mpb. This year Tesla released a new model and some customers believe that the new model is ueses less battery, they wish to prove this claim with a hypothesis test let μ represent the mean fuel efficiency of the new model. Describe null and alt hypotheses that the customer could use.
The null hypothesis H_0 is the hypothesis we assume to be correct unless proven otherwise it is our default assumption
The alt hypothesis H_1 is what we conclude about the population parameter if our null hypothesis is shown to be wrong.
We assume that the mean battery life is the same as before μ = 35
if it turns out that this is wrong then we conclude that the new model's mean battery efficiency has declined that is the number of miles per battery has decreased
the null hypothesis is H_0 : μ = 35mpb
alt is H_1 : μ < 35mpb

example:
A casino has a 6-sided die and a gambler suspects it is biased towards landing on 1, let p represents the probability that the die lands on 1, which of the following could be the null hypothesis?
H_0 : p = 1/6

example:
previous same question but what is the alt?
H_1 : p > 1/6

Significance levels in hypothesis testing
we defines p as the probability that a coin lands on heads when tossed randomly
we want ot check whether the coin is biased toward landing on heads we have the following null and alternative hypotheses
H_0 : p = 1/2
H_1 : p > 1/2
the test statistic is X = the number of times the coin lands on heads after 10 tosses
we conduct our experiment and get 9 heads out of 10 tosses intuitively 9 heads from 10 tosses would suggest that the coin is biased toward landing on heads, but we do have enough statistical evidence to conclude that the coin is biased?
Whether we have a statistically significant result we need to figure out whether the probability of getting 9 from 10 tosses is small enough to conclude that the coin is biased.
we must first quantify what we mean when we say a probability is small enough so we set a threshold for the experiment called a significance level often denoted α the significance level specifies a probability that would lead to a statistically significant result for this experiment say
α = 5%
under the conditions specified in the null hypothesis the random variable X is a binomial random variable
X ~ B(10,1/2)
we can compute the probability of getting X >= 9 heads under the null hypothesis using our knowledge of the binomial distribution
P(X >= 9) = P(X = 9) + P(X = 10)
= (10,9)(1/2)^9(1/2)^10-9 + (10,10)(1/2)^10(1/2)^10-10
= 10 * (1/2)^10 + 1 * (1/2)^10
= 11 * (1/2)^10
= 0.0107
= 1.07%
This probability is smaller than our significance level of 5% this means that our result is statistically significant in other words it is unlikely that this event could have occured if the null hypothesis is true.
Therefore we should reject the null hypothesis and conclude that the coin is biased.

Critical regions and critical values
The significance level α referes not just to a single probability but to all x-values within the critical region. The critical region contains all x-values that are collectively unlikely under the null hypothesis and therefore cause the null hypothesis to be rejected.
consider random variable X
X ~ B(10,1/2)
Getting 8-10 heads out of 10 tosses causes us to reject the null hypothesis its easy to show
P(X >= 8) = 4.4% < α and P(X >= 10) = 0.1% < α
however x = 7 does not lie in the critical region
P(X >= 7) = 11.72% > α
the critical region for this hypothesis test at the 5% significance level is x ∈ {8,9,10}
the value x = 8 is called the critical value since it lies on the boundary between the critical region and the region where we do not reject H_0
So the idea behind the significance level α = 5% is that the sum of all probabilities inside the critical region is less than 5%
α = 5% is a common significance level other common values include α = 10% and α = 1% selecting a different significance level will generally change the critical region
The good choice of significance level depends on the experiment but as a rule of thumb α = 5% is deemed unlikely while α = 1% is very unlikely

Identifying a critical region
An Olive Garden suspects that the average number of customers per hour has decreased since the opening of Red Lobster, before the opening of Red Lobster 8 customers per hour visted Olive Garden, let X represent the number of customers arriving at Olive Garden in a randomly selected one hour period. Under the null hypothesis that the average number of customers is the same as before, what is the critical region of a one-tailed test at a significance level of 5%?
x        |   0  |   1  |   2  |   3  |   4  |   5  |   6  |
P(X <= x)|0.0003|0.0030|0.0138|0.0424|0.0996|0.1912|0.3134|
-----------------------------------------------------------
let λ be the average number of customers per hour that visit the restaurant then we have the null and alt hypotheses
H_0 : λ = 8
H_1 : λ < 8
the critical region is the set of values of X for which we reject the null hypothesis
this is a one sided test where the restaurant owner wishes to conclude that the average number of customers has decreased this would correspond to observing an abnormally small value of X
to reject the null hypothesis at a significance level of 5% we must observe a value x such that P(X <= x) = 0.05 under the null hypothesis
P(X <= 0) = 0.0003 < 0.05
P(X <= 1) = 0.0030 < 0.05
P(X <= 2) = 0.0138 < 0.05
P(X <= 3) = 0.0424 < 0.05
P(X <= 4) = 0.0996 !< 0.05
the values of X that would cause the null hypothesis to be rejected at a significance level of 5% are 0,1,2, and 3
the critical region is X <= 3

Identifying a critical region
A KFC manager things that the average number of customers per hour has decreased since the opening of a competing restaurant, before the competing restaurant opened 10 customers per hour visited KFC Let X represent the number of customers during one hour. Under the null hypothesis that the average number of customers is the same as before what is the critical region of a one-tailed test at a significance level of 1%
x        |  15  |  16  |  17  |  18  |  19  |  20  |
P(X <= x)|0.9513|0.9730|0.9857|0.9928|0.9965|0.9984|
-----------------------------------------------------
λ = be the average number of customers per hour, null and alt hypotheses
H_0 : λ = 10
H_1 : λ > 10
the critical region is the set of values of X for which we reject the null hypothesis
this is a one sided test where the manager wishes to conclude that the number of customers has increased this would correspond to observing an abnormally large value of X
To reject the null at 1% we must observe a value x such that P(X >= x) = 0.01 under the null hypothesis
under the table we have
P(X >= 19) = 1 - P(X <= 18)
= 1 - 0.9928
= 0.0072
< 0.01
P(X >= 18) = 1 - P(X <= 17)
= 1 - 0.9857
= 0.0143
!< 0.01
So the values of X that would cause the null hypothesis to be rejected at a significance level of 1% are 19 or more
critical region is X >= 19

A casino has 6 sided dice a gambler suspects it is biased towards landing on 1, X represents the number of times the die lands on 1 when rolled a total of 5 times, under the null hypothesis that the die is fair what is the critical region of a one tailed test at a significance level of 5%?
x       |  0   |   1  |   2  |   3  |   4  |   5  |
P(X = x)|0.4019|0.4019|0.1608|0.0322|0.0032|0.0001|
---------------------------------------------------
H_0 : p = 1/6
H_1 : p > 1/6
to reject the null hypothesis at a significance level of 5% we must observe a value x such taht P(X >= x) = 0.05 under the null hypothesis
P(X >= 5) = P(X = 5)
= 0.0001
< 0.05
P(X >= 4) = P(X = 4) + P(X = 5)
= 0.0032 + 0.0001
= 0.0033
< 0.05
P(X >= 3) = P(X = 3) + P(X = 4) + P(X = 5)
= 0.0322 + 0.0032 + 0.0001
= 0.0355
< 0.05
P(X >= 2) = P(X = 2) + P(X = 3) + P(X = 4) + P(X = 5)
= 0.1608 + 0.0322 + 0.0032 + 0.0001
= 0.1963
!< 0.05
the values of X that would cause the null hypothesis to be rejected at a significance level of 5% are 3,4,5
critical region is X >= 3

Identifying a critical value
A casino dealer has a 6 sided die and a craps gambler suspects it is biased towards landing on 1 let X represent the number of times the die lands on 1 when rolled a total of 5 times under the null hypothesis that the die is fair what is the critical value of a one-tailed test at a significance level of 2.5%
x       |  0   |   1  |   2  |   3  |   4  |   5  |
P(X = x)|0.4019|0.4019|0.1608|0.0322|0.0032|0.0001|
---------------------------------------------------
H_0 : p = 1/6
H_1 : p > 1/6
to reject the null hypothesis at a significance level of 2.5% we must observe a value x such that P(X >= x) = 0.025 under the null hypothesis
P(X >= 5) = P(X = 5)
= 0.0001
< 0.025
P(X >= 4) = P(X = 4) + P(X = 5)
= 0.0032 + 0.0001
= 0.0033
< 0.025
P(X >= 3) = P(X = 3) + P(X = 4) + P(X = 5)
= 0.0322 + 0.0032 + 0.0001
= 0.0355
!< 0.025
the values of X that would cause the null hypothesis to be rejected at a significance level of 2.5% are the values such that X >= 4, the critical value is 4

===================================================

Two-tailed hypothesis tests
we have a coin that we suspect is unfair we wish to conduct a hypothesis test at the 5% level of significance to determine whether or not our suspicions are correct
First we define p as the probability that the coin lands on heads
second form a null hypothesis, states the coin is fair
H_0 : p = 1/2
third we form a alt hypothesis, coin is unfair
H_1 : p != 1/2
the not equal to symbol is different from the one-tailed cases, we're not specifying whether the coin is biased toward heads or tails. Instead we include the possibility that is biased toward either heads or tails
In a two-tailed test, the alternative hypothesis always involves a not equal to symbol
Fourth we must specify a test statistic in this case a suitable test statistic could be
X = the number of times the coin lands on heads after 10 tosses

Identifying two-tailed alternative hypotheses
let μ represent the average IQ among a particular population, given the null hypothesis H_0 : μ = 105 which of the following are valid two-tailed alternative hypotheses
1. H_1 : μ < 105
2. H_1 : μ > 105
3. H_1 : μ != 105
the alternative hypothesis H_1 is what we conclude about the population parameter if our null hypothesis is shown to be wrong.
A two-tailed alternative hypothesis states that the population parameter is not equal to the value given by the null hypothesis
here the null hypothesis is H_0 : μ = 105 if this is shown to be wrong then there is one valid two-tailed alternative hypothesis
H_1 : μ != 105
correct answer is 3 only

Conducting a two-tailed hypothesis test
test whether a coin is unfair
p is the probability that the coin lands on heads when tossed
we want to check whether the coin is unfair we have the null and alt hypotheses
H_0 : p = 1/2
H_1 : p != 1/2
the significance level is α = 5%
under the conditions specified in the null hypothesis, the random variable X is a biomial random variable given by
X ~ B(10,1/2)
when we select significance level α in a two-tailed test, the convention is to allow α/2 at either tail
so if α = 5%, α/2 = 2.5% at either tial.
We conduct our experiment and get 2 heads out of 10 tosses
if the result X = 2 is statistically significant it will lie in the critical region in the left tail of the probability distribution of f(x)
we can compute the probability of getting X <= 2 heads under the null hypotheses using binomial distribution
P(X <= 2) = P(X = 0) + P(X = 1) + P(X = 2)
= (10,0)(1/2)^0(1/2)^10-0 + (10,1)(1/2)^1(1/2)^10-1 + (10,2)(1/2)^2(1/2)^10-2
= 1 * (1/2)^10 + 10 * (1/2)^10 + 45 * (1/2)^10
= 56 * (1/2)^10
= 0.055
= 5.5%
the probability is larger than α/2 = 2.5% this means that our result is not statitically significant, it is likely enough that this event could have occured if the null hypothesis is true
We should not reject the null hypothesis, concluding the coin is fair

The critical region contains all x-values that are collectively unlikely under the null hypothesis and cause the null hypothesis to be rejected
For two tailed tests the critical region typically consists of two disjoint sets, there are typically two critical values

Olive Garden changed some of its menu items and thinks this could change the number of customers with the old menu items an average of 7 customers per hour visited. X represents the number of customers that arrive at the restaurant during a randomly selected one hour period. Under the null hypothesis that the number of customers is the same as before what is the critical region of a two tailed test at a significance level of 5%?
x P(X <= x)
0 |0.0009|
1 |0.0073|
2 |0.0296|
3 |0.0818|
4 |0.1730|
..|  ... |
10|0.9015|
11|0.9467|
12|0.9730|
13|0.9872|
14|0.9943|
..|  ....|
λ = the average number of customers visiting the restaurant per hour null and alt hypotheses
H0 : λ = 7
H1 : λ != 7
the critical region is set of values of C for which we reject the null hypothesis
to reject null hypothesis we need to observe an abnormally large or abnormally small value of X
to reject null at significance 5% we must observe a value x such that P(X <= x) = 0.025 or P(X >= x) = 0.025 ybder the null hypothesis
left tail
P(X <= 0) = 0.0009 < 0.025
P(X <= 1) = 0.0073 < 0.025
P(X <= 2) = 0.0296 !< 0.025
right tail
P(X >= 15) = 1 - P(X <= 14)
= 1 - 0.9943
= 0.0057
< 0.025
P(X >= 14) = 1 - P(X <= 13)
= 1 - 0.9872
= 0.0128
< 0.025
P(X >= 13) = 1 - P(X <= 12)
= 1 - 0.9730
= 0.0270
!< 0.025
the values of X that would cause the null hypotheesis to be rejected at a significance level of 5% are the values such that X <= 1 and X >= 14
critical region is X <= 1 or X >= 14

Identifying critical values
Milk bar decides to use a new cake recipe, 55% of customers bought at least one cake with the previous recipe. X represents the number of customers that buy at least one cake with the new recipe in a random sample of 6 customers, under the null hyothesis that the proportion of customers that buy a cake with the new recipe is the same as before, what are the critical values of a two-tailed test at a significance level of 10%
x        |   0  |   1  |   2  |   3  |   4  |   5  |   6  |
P(X <= x)|0.0083|0.0692|0.2553|0.5585|0.8364|0.9723|1.0000|
-----------------------------------------------------------
Let p be the probability that a randomly selected customer buys at least one cake, we have the following null and alt hypotheses
H0 : p = 55%
H1 : p != 55%
To reject the null hypothesis at a significance level of 10% we must observe a value x such that P(X <= x) = 0.05 or P(X >= x) = 0.05 under the null hypothesis
left tail
P(X <= 0) = P(X = 0)
= 0.0083
< 0.05
P(X <= 1) = 0.0692
!< 0.05
right tail
P(X >= 6) = 1 - P(X <= 5)
= 1 - 0.09723
= 0.0277
< 0.05
P(X >= 5) = 1 - P(X <= 4)
= 1 - 0.8364
= 0.1636
!< 0.05
the values of X that would cause the null hyopthesis to be rejected at a significance level of 10% are the values X <= 0 and X >= 6
critical values are 0 and 6

===================================================

In statistical hypothesis testing
A type 1 error occurs if we reject the null hypothesis even though its true type 1 errors are also known as false-positive
A type 2 error occurs if we do not reject the null even though its false type 2 errors are also known as false-negatives
         | H0 is true | H0 is false|
Accept H0|     ✔      |type 2 error|
Reject H0|type 1 error|     ✔      |
------------------------------------
For example, we have the following null and alt hypotheses regarding a population mean μ
H0 : μ = 2.5
H1 : μ != 2.5
a type 1 error would occur if we reject H0 when μ = 2.5
a type 2 error would occur if we accept H0 when μ != 2.5

Identifying type 1 errors
given the following null and alternative hypotheses which of the following would be type 1 errors?
H0 : μ = 3.5
H1 : μ < 3.5
1. Accept H0 when μ < 3.5
2. Accept H0 when μ = 3.5
3. Reject H0 when μ = 3.5
type 1 occurs when we reject the null H0 even though it is true.
1. is type 2 error, 2. is not an error,
the only correct answer is 3. 

Type 1 errors in modeling contexts
Larry Page wants to test whether a new feature in google is more effective than the old feature. What would be an example of a type 1 error in this context? For the null hypothesis you should assume that the new feature is as effective as the older one
A type 1 error occurs when we reject the null hypothesis H0 even though it is true
in this case the null hypothesis is that the new feature is as effective as the older one
A type 1 error would consist of Larry Page concluding that the new feature is more effective when it is as effective as the older feature.

Identifying type 2 errors
given the following null and alternative hypotheses which of the following would be type 2 errors?
H0 : μ = 100
H1 : μ < 100
1. Accept H0 when μ < 100
2. Reject H0 when μ < 100
3. Reject H0 when μ = 100
A type 2 error occurs when we accept the null hypothesis H0 even though it is false
1. this is a type 2 error, 2. is not an error, 3. is a type 1 error

Type 2 error modeling contexts
An SAT admin whats to test whether students score higher under a new SAT format than under the existing one. What would be an example of a type 2 error in this context? For the null hypothesis should assume that the students score is the same under the new format format as the existing one.
A type 2 error occurs when we accept the null hypothesis H0 even though it is false
in this case the null hypothesis is that students score the same under both formats
A type 2 error would consist of the administrator concluding that the students score is the same under the new format when they in fact scored higher

===================================================

NOTE:
when testing alt hypothesis with μ < x we should consider left tail
and vise versa for one-tail.

NOTE:
insufficient evidence means we accept the null hypothesis and is NOT within the critical areas (left or right tails).

Hypothesis tests for one mean: known variance
Suppose the scores on a particular math test are normally distributed with mean μ = 69 points and SD σ = 14 points after changing some test criteria the test admins suspect that the mean score is now greater than 69 points, they decide to carry out a hypothesis at the 5% significance level, they sample 30 test results and found taht the sample mean was x̄ = 75 points.
is there sufficient evidence to conclude that the mean score is now greater than 69 points?
First we'll write down the null and alt hypotheses and establish the critical region of the test
Second we'll compute the test statistic and determine whether the result is statistically significant
The population is normally distributed, therefore the distribution of the sample mean is also normal
X̄ ~ N(μ, σ^2/n)
and we have
(X̄ - μ)/(σ/sqrt(n)) ~ N(0,1)
X̄ = the sample mean
μ = the population mean
σ^2 = population variance
n = sample size
H0 : μ = 69 is the null hypothesis
H1 : μ > 69 is the alt (one-tailed) hypothesis
to find the critical region for this test at the α = 5% level of significance we need to find a particular value zp of Z
P(Z >= zp) = α = 0.05
we can use the following percentage points table
p |0.100|0.050|0.025|0.010|0.005|
zp|1.282|1.645|1.960|2.326|2.576|
---------------------------------
P(Z > 1.645) = 0.05
z0.05 = 1.645 is our critical value
Z > 1.645 the critical region
out of a sample of 30 tests, the mean of the sample was 75 points therefore we have the following sample data
x̄ = 75, n = 30
assuming the null hypothesis is true, μ = 69 and σ = 14 we can compute the test statisitc as follows
z = (x̄ - μ)/(σ/sqrt(n))
= (75 - 69)/(14/sqrt(30))
= 2.347
if we assume that the population mean is μ = 69 the null hypothesis is true getting a sample mean of x̄ = 75 or more has a probability that is smaller than 0.05 = 5% our significance level.
we have a statistically significant result and reject the null hypothesis
there is sufficient evidence that at the 5% level of significance we have μ > 69

To conduct a one-tailed hypothesis test for the population mean with known population variance
step 1: check the conditions
The population variance σ^2 must be known
The distribtion must be normal (or the sample size must be sufficiently large)
step 2: define the test
pick a significance level (%)
state the null and alternative hypotheses
H0 : μ = μ0
H1 : μ > μ0 for a right-tailed test or H1 : μ < μ0 for a left-tailed test
μ0 is the value of μ under the null hypothesis
step 3: compute the test statistic
assuming the null hypothesis compute the test statistic
z = (x̄ - μ)/(σ/sqrt(n))
compute the critical value using the standard normal distribution and write down the critical region
step 4: interpret the result:
reject the null hypothesis if the test statistic z lies inside the critical region, we say there is sufficient evidence to reject the null hypothesis at the given significance level
dont reject the null hypothesis if the test statistic z lies outside the critical region, we say that there is insufficient evidence to reject the null hypothesis at the given significance level

Testing a hypothesis given a normal population: one-tailed tests
consider a sample of size n = 45 from a normal population with a SD σ = 7 we wish to carry out a hypothesis test at a 5% significance level to determine whether there is sufficient evidence that the population mean μ is smaller than 18
given that the mean of the sample is x̄ = 17 which of the following statments are true?
1. The one-tailed critical region for the test statistic is approximately Z <= -2.576
2. At the 5% level of significance there is insufficient evidence that μ < 18
3. At the 5% level of significance there is sufficient evidence that μ < 18
Hint: given a random variable Z ~ N(0,1) the table shows the z-scores zp such that P(Z >= zp) = p for some particular values of p
p |0.100|0.050|0.025|0.010|0.005|
zp|1.282|1.645|1.960|2.326|2.576|
---------------------------------
H0 : μ = 18 is the null hypothesis
H1 : μ < 18 is the alt (one-tailed) hypothesis
assuming the null hypothesis (i.e. μ = 18)
we compute the test statistic
z = (x̄ - μ)/(σ/sqrt(n))
= (17 - 18)/(7/sqrt(45))
~= -0.958
statement 1 is false according to the table the 5% one-tailed value is z ~= 1.645
since the alt hypothesis is μ < 18 we must consider the left tail we do this using the symmetry of the normal distibution so our critical region is
Z <= -1.645
statement 2 is true, while statement 3 is false our test statistic (-0.958) does not lie in the critical region
so we do not reject the null hypothesis H0
we conclude: there is insufficient evidence that at the 5% level of significance we have μ < 18
the only correct answer is 2

example:
consider sample of size n = 60 from a normal population with a SD σ = 4 we wish to carry out a hypothesis test at 1% significance level to determine whether there is sufficient evidence that the population mean μ is larger than 31
given that the sample mean is x̄ = 33, which statements are true
1. the one-tailed critical region for the test statistic is approximately Z >= 2.326
2. at the 1% level of significance there is insufficient evidence that μ > 31
3. at the 1% level of significance there is sufficient evidence that μ > 31
= (33 - 31)/(4/sqrt(60))
= 2*sqrt(60)/4
= 3.87
statement one is true 1% ~= 2.326 (from the table above)
since alt is μ > 31 we must consider right tail critical region is
Z >= 2.326
statement 2 is false, while statement 3 is true. our test statistic 3.873 lies in the critical region. (lower than 1%)
so we reject the null hypothesis H0 there is sufficient evidence at the 1% level of significance we have μ > 31

example:
Consider a sample of size n = 20 from a normal population with SD σ = 5 we wish to carray out a hypothesis that at a 1% significance level to determine whether there is sufficient evidence that the population mean μ is smaller than 50
given that the sample mean x̄ = 49, which of the following statements is true?
1. the one-tailed critical region for the test statistic is approximately Z <= -2.326
2. at the 1% level significance there is insufficient evidence that μ < 50
3. at the 1% level significance there is sufficient evidence that μ < 50
= (49 - 50)/(5/sqrt(20))
= -0.894
statement 1 is true account to the table the 1% one-tailed critical value is z ~= 2.326
since the alt hypothesis is μ < 50 we must consider the left tail, we do this by symmetry of the normal distribution, our critical region is Z <= -2.326
statement 2 is true while 3 is false our test statistic is -0.894 does not lie in the critical region (IT IS NOT LOWER THAN THE LEFT TAIL OF Z = INSUFFICENT outside the bounds)
we do not reject the null hypothesis H0 we conclude
there is insufficient evidence that at the 1% level of significance we have μ < 50

Two-tailed hypothesis tests
to conduct a two-tailed hypothesis test for the population mean with known population variance we proceed similarly to the one-tailed case. its similar to the one-tailed case the only differences
the alt hypothesis will be H1 : μ != μ0
We compute the critical value and write down the critical region by considering both tails of the distribution if the significance level is α then we allow α/2 at either tail.

Testing a hypothesis given a normal population: two-tailed tests
Consider a sample of size n = 50 from a normal population with a SD σ = 12 we wish to carry out a hypothesis test at the 10% level of significance to determine whether there is sufficient evidence that the population mean μ does not equal 26
given that the mean of the sample x̄ = 25 which of the following statements are true?
1. The two-tailed critical region for the test statistic is approximately Z <= - 1.645 or Z >= 1.645
2. At the 10% level of significance there is insufficient evidence that μ != 26
3. At the 10% level of significance there is sufficient evidence that μ != 26
(same table as before)
p |0.100|0.050|0.025|0.010|0.005|
zp|1.282|1.645|1.960|2.326|2.576|
---------------------------------
H0 : μ = 26 is the null hypothesis
H1 : μ != 26 is the alternative (two-tailed) hypothesis
assuming the null computing the statistic
z = (x̄ - μ)/(σ/sqrt(n))
= (25 - 26)/(12/sqrt(52))
~= -0.589
statement 1 is true, according to the table the 5% two-tailed critical value the same as the 10%/2 = 5%, z ~= 1.645
since both tails our critical region is
Z <= -1.645 or Z >= 1.645
statement 2 is true, while statement 3 is false our test statistic -0.589 does not lie in the critical region (non-critical between the Z values)
so we do not reject the null hypothesis H0 as a result we conclude there is insfficient evidence that at the 10% level of significance we have μ != 26 therefore correct answer is 1 and 2 only

Large samples
We've assumed that the underlying population is normally distributed, if we have sufficiently large sample according to the central limit theorem we can use
(X̄ - μ)/(σ/sqrt(n)) ~= N(0,1)
sufficiently large means that n >= 30
even through we might not know the underlying distribution we can still use the following formula for the test statistic:
z = (x̄ - μ)/(σ/sqrt(n))

Testing a hypothesis for a large sample
Consider a sample of size n = 250 from a population with a SD σ = 7 we wish to carry out a hypothesis test at the 2.5% significance level to determine whether there is a sufficient evidence that a population mean μ is smaller than 10
given that the mean of the sample is x̄ = 9, which of the following is true?
1. The critical region for the test statistic is approximately Z <= -2.576
2. At the 2.5% level of significance there is insufficient evidence that μ < 10
3. At the 2.5% level of significance there is sufficient evidence that μ < 10
H0 : μ = 10 is the null hypothesis
H1 : μ < 10 is the alternative (one-tailed) hypothesis
(9 - 10)/(7/sqrt(250))
~= -2.259
statement 1 is false 2.5% (one-tailed) critical calue is ~= 1.960
p |0.100|0.050|0.025|0.010|0.005|
zp|1.282|1.645|1.960|2.326|2.576|
---------------------------------
since the alt is μ < 10 we must consider the left tail so our critical region is Z <= -1.960
statement 2 is false while 3 is true our test statistic -2.259 lies in the critical region, so we reject the null hypothesis H0 so we conclude that there is sufficient evidence that at the 2.5% level of significance we have μ < 10
the only correct answer is 3

Applications of hypothesis testing
Ben and Jerrys claims that the weight of the vanilla flavor has population mean μ = 50g and population SD σ = 5, an qa team member selected 150 ice cream containers of vanilla ice cream and found that their mean weight is 49.3g. They wish to carry out a hypothesis test to determine whether there is sufficient to challenge the manufacturer's claim
using a 5% significance level to determine whether there is sufficient evidence that the population mean μ does not equal 50g determine which of the following statements are true
1. The critical region for the test statistic is approximately Z <= -1.645 or Z >= 1.645
2. at the 5% level of significance there is insufficient evidence that μ != 5g
3. at the 5% level of significance there is sufficient evidence that μ != 50g
H0 : μ = 50 is the null hypothesis
H1 : μ != 50 is the alt (two-tailed) hypothesis
we have
x̄ = 49.3g, n = 150, σ = 5g
z = (x̄ - μ)/(σ/sqrt(n))
= (49.3 - 50)/(5/sqrt(150))
= -1.715
statement 1 is false according to the table 5% of two tails critical value the same as the 5%/2 = 2.5% z ~= 1.960
p |0.100|0.050|0.025|0.010|0.005|
zp|1.282|1.645|1.960|2.326|2.576|
---------------------------------
Since we are considering both tails our critical region is
Z <= -1.960 or Z >= 1.960
statement 2 is true while statement 3 is false out test statistic -1.715 does not lie in the critical region.
we can't reject the null hypothesis H0, there is insufficient evidence that at the 5% level of significance we have μ != 50
correct answer is 2 only

===================================================

NOTE:
some of the exercises were long to write, and just be confusing to read later (less is more sometimes), most of the time I just used the formula below and reasoned about the given statements. 

NOTE:
when to use one-tail, its when we are testing the sample mean > or < in the alternative, two-tail if alt !=
(< left tail) (> right tail)

Always having the variance (σ^2) when conducting a hypothesis test is often unrealistic its doubtful that we'll know the population variance yet not know the population mean.
A more realistic situation is that σ^2 is unknown and we must estimate it from the sample data
to compute an unbiased estimate of the population variance σ^2 we use the sample variance S^2 given by
S^2 = 1/n-1Σ^n_i=1(Xi - X̄)^2
Xi is a sample element, X̄ sample mean, n sample size
it can be shown that the random variable
(X̄ - μ)/(S/sqrt(n)) ~ T_n-1
T_n-1 is a student's t-distribution with n - 1 degrees of freedom
if the variance is unknown we use the t-distribution instead of a normal distribution when conducting our hypothesis test other than that the process is the same as before

Describing the null and alternative hypotheses
Suppose the waiting time to get a popeyes chicken sandwhich is normally distributed the team lead target is that the mean waiting time should be no longer than 10 minutes after some changes to their processes the team lead now believe that the mean waiting time is longer than 10 minutes and decide to conduct a hypothesis test at the 1% significance level.
The team lead samples 18 customers and found that their mean waiting time is x̄ = 11min the sample SD is s = 1.5min, is there sufficient evidence to conclude that the mean waiting time is greater than 10min? we are told that the population is normally distributed however we do not know the population variance σ^2 therefore we will use the fact that the random variable
(X̄ - μ)/(S/sqrt(n))
follows a student's t-distribution with n - 1 degrees of freedom
H0 : μ = 10min is the null hypothesis
H1 : μ > 10min is the alternative (one-tailed) hypothesis
the critical region contains all t-values that are collectively unlikely under the null hypothesis and therefore cause the null to be rejected
Let T be a t-distributed random variable with k = 18 - 1 = 17 degrees of freedom to find the critical region for this test at the α = 1% level of significance we need to find a particular value t_17,0.01
P(T > t_17,0.01) = α = 0.01
k\p|0.100|0.050|0.025|0.010|0.005|
15 |1.341|1.753|2.131|2.602|2.947|
16 |1.337|1.746|2.120|2.583|2.921|
17 |1.333|1.740|2.110|2.567|2.898|
----------------------------------
P(T > 2.567) = 0.01
t_17,0.01 = 2.567 is our critical value
T >= 2.567 the critical region
(from our table)

Computing the test statistic
we have the following critical region at the 1% significance level
we're told that out of a sample of 18 customers the mean of the sample was 11 minutes and the variance was 1.5min
x̄ = 11min, s = 1.5min, n = 18
assuming the null hypothesis
t = (x̄ - μ)/(s/sqrt(n))
= (11 - 10)/(1.5/sqrt(18))
~= 2.828
our test statistic 2.828 lies in the critical region
(which is higher than 1% at 2.567)
if we assume that the population mean is μ = 10min (the null is true) getting a sample with a mean of x̄ = 11min or more has a probability that is smaller than 0.01 = 1% our significance level
Therefore we have a statistically sigificant result and reject the null hypothesis
in conclusion there is sufficient evidence that at the 1% level of significance we have μ > 10min

Testing a hypothesis given a normal population on tailed tests
consider a sample of size n = 6 from a normal population we want to test at 5% significance level to determine whether there is sufficient evidence that the population mean μ is smaller than 2
the mean of the sample is x̄ = 0 and the sample SD is s = 4 which statements are true?
1. The one-tailed critical region for the test statistic is approximately T <= -2.015
2. At the 5% level of significance there is insufficient evidence that μ < 2
3. At the 5% level of significance there is sufficient that μ < 2
k\p|0.100|0.050|0.025|0.010|0.005|
15 |1.533|2.132|2.776|3.747|4.604|
16 |1.476|2.015|2.571|3.365|4.032|
17 |1.440|1.943|2.447|3.143|3.707|
----------------------------------
we are told that the population is normally distributed but we do not know the population variance σ
H0 : μ = 2 is the null hypothesis
H1 : μ < 2 is the alt (one-tailed) hypothesis
compute test statistic:
= (0 - 2)/(4/sqrt(6))
~= -1.225
statement 1 is true, according to the table 5% one tailed critical value for a t-distributed random variable with
n - 1 = 6 - 1 = 5
degrees of freedom 5 and 5%
t = 2.015
since the alt hypothesis is μ < 2 we must consider the left tail so critical region is
T <= -2.015
statement 2 is true while statement 3 is false our test statistic (-1.225) does not lie in the critical region
we do not reject the null hypothesis H0 as a result we conclude
that there is insufficient evidence that at the 5% level of significance we have μ < 2
correct answer is 1 and 2 only

A Two-tailed hypothesis test
To conduct a two tail with known population variance we proceed similarly to the one-tailed case
the alternative hypothesis will be H1 : μ != μ0
we compute the critical value and write down the critical region by considering both tails of the distribution, if the significance level is α so α/2 at either tail

Testing a hypothesis given a normal population two-tailed tests
Consider a sample of size n = 17 from a normal population, we wish to carry out a hypothesis test at the 5% level of significance to determine whether there is sufficent evidence that the population mean μ does not equal 5
given that the mean of the sample is x̄ = 7 and the sample SD s = 5 which statements are true?
1. The two-tailed critical region for the test statistic is approximately T <= -1.746 or T >= 1.746
2. At the 5% level of significance there is insufficient evidence that μ != 5
3. At the 5% level of significance there is sufficient evidence that μ != 5 
k\p|0.100|0.050|0.025|0.010|0.005|
16 |1.337|1.746|2.120|2.583|2.921|
17 |1.333|1.740|2.110|2.567|2.898|
18 |1.330|1.734|2.101|2.552|2.878|
----------------------------------
H0 : μ = 5 is the null hypothesis
H1 : μ != 5 is the alternative (two-tailed) hypothesis
(7 - 5)/(5/sqrt(17))
~= 1.649
statement 1 is false according to the table the 5% two-tailed critical value (the same as the 5%/2 = 2.5%) for a t-distributed random variable n - 1 = 17 - 1 = 16
degrees of freedom (16 and 2.5%)
since we are considering both tails our critical ragion is
T <= -2.120 or T >= 2.120
statement 2 is true while statement 3 is false, our test statistic (1.649) does not lie in the critical region
we do not reject the null hypothesis H0, there is insufficient evidence that at the 5% level of significance we have μ != 5

Large samples
we can still use the same formula since n is sufficiently large σ^2 can be approximated as S^2
(X̄ - μ)/(S/sqrt(n))
typically "sufficiently large" means that n >= 30

Testing a hypothesis for a large sample
consider a sample of size n = 70 from a population we wish to carry out a hypothesis test at the 10% significance level whether there is sufficient evidence that the population mean μ is smaller than 24
given that the mean of the sample x̄ = 23 and the sample standard deviation is s = 5 which of the statements are true?
1. The critical region for the test statisitc is approximately T <= 1.294
2. At the 10% level of significance there is insufficient evidence that μ < 24
3. At the 10% level of significance there is sufficient evidence that μ < 24
k\p|0.100|0.050|0.025|0.010|0.005|
69 |1.294|1.667|1.995|2.382|2.649|
70 |1.294|1.667|1.994|2.381|2.648|
71 |1.294|1.667|1.994|2.380|2.647|
----------------------------------
We do not know the distribution of the population nor do we know the population variance σ^2 the sample size n = 70 >= 30 is sufficiently large
H0 : μ = 24 is the null hypothesis
H1 : μ < 24 is the alt (one-tailed) hypothesis
= (23 - 24)/(5/sqrt(70))
~= -1.673
statement 1 is true, according to the table the 10% one-tailed critical calue for a t-distributed random variable with
n - 1 = 70 - 1 = 69
degrees of freedom (69, 10%) is t ~= 1.294
since the alternative hypothesis is μ < 24 we must consider the left tail so the critical region
T <= -1.294
statement 2 is false, while statement 3 is true our test statistic (-1.673) lies in the critical region
So we reject the null hypothesis H0 we conclude there is sufficient evidence that at the 10% level of significance we have μ < 24
therefore the correct statements is 1 and 3 only

Applications of Hypothesis testing
A pharmaceutical company used a large group of people to test a new drug designed to reduce cholesterol levels. The mean cholesterol level for the group before teh treatment was μ = 189 milligrams per decliter(mg/dL)
After treatment a scientist sampled 40 people from the group and found that the cholesterol levels of those sampled had a mean of 187 mg/dL and a SD of s = 12mg/dL the scientist wishes to conduct a hypothesis test to determine whether sufficient evidence exists to claim that the drug works.
By carrying out the hypothesis test at a 10% significance level to determine whether there is sufficient evidence that the population mean μ is smaller than 189mg/dL determine which of the following statements are true
1. the critical region for the test statistic is approximately T <= -1.304
2. At the 10% level of significance there is insufficient evidence that μ < 189mg/dL
3. At the 10% level of significance there is sufficient evidence that μ < 189mg/dL
k\p|0.100|0.050|0.025|0.010|0.005|
39 |1.304|1.685|2.023|2.426|2.708|
40 |1.303|1.684|2.021|2.423|2.704|
41 |1.303|1.683|2.020|2.421|2.701|
----------------------------------
H0 : μ = 189 is the null hypothesis
H1 : μ < 189 is the alt (one-tailed) hypothesis
x̄ = 187mg/dL, n = 40, s = 12mg/dL
(187 - 189)/(12/sqrt(40))
~= -1.054
statement 1 is false according to the table the 10% one-tailed critical value for a t-distributed random variable with
n - 1 = 40 - 1 = 39
degrees of freedom (39,10%)
t ~= 1.304
since the alt hypothesis is μ < 189 we must consider the left tail so our critical region is T <= -1.304
statement 2 is true while statement 3 is false our test statistic (-1.054) does not lie in the critical region
so we can't reject the null hypothesis H0 as a result there is insufficient evidence that at the 10% level of significance we have μ < 189
correct answer is 2 only.

===================================================

NOTE:
Most of the examples, we just have to plug in values and use the formula and reasoned about the values obtained.

There are cases where we need to use the hypothesis tests to show a statistically significant difference between two population means in cases where the population variances are known 
We have two normally distributed populations X and Y where
X ~ N(μx,σx^2), Y ~ N(μy,σy^2)
if we conduct a random smaple of size nx from the first population and a second independent random sample of size ny from the second population
X̄ ~ N(μx,σx^2/nx), Ȳ(μy,σy^2/ny)
where X̄ and Ȳ are sample means
we know that the sum or difference of two independent norally distributed random variables is also normal, using our usual results for subtracting means and variances
X̄ - Ȳ ~ N(μx - μy, σx^2/nx + σy^2/ny)
this means the the random variable Z is
Z = (X̄ - Ȳ - (μx - μy))/(sqrt(σx^2/nx + σy^2/ny))
follows a normal distribution N(0,1)

Independent vs Dependent samples
We assume that samples from two populations X and Y are independent two samples are independent if they are not directly related or connected
The selection or outcome of one sample does not influence the selection or outcome of the other
the individuals or data points within each sample are not paired or matched in any way, and there is no inherent relationship between the observartions in the two groups
Independent Samples
A pharmaceutical company wants to test the effectiveness of a new drug for treating high blood pressure, so they recruit 100 participants with high blood pressure, 50 of whom are randomly assigned to receive the new drug (the treament group) and 50 to receive a placebo (the control group) the blood pressure of participants in both groups is measured after a certain period
in this case, the treatment and control groups represent independent samples as the outcomes in one group are not influenced by the outcomes in the other group and participants are not paired or matched in any way
Dependent Samples
The pharmaceutical company wants to test the effectiveness of the high blood pressure drug, they recruit 50 participants all of whom have high blood pressure each participant's blood pressure is measured before starting the drug treatment (baseline measurement). Then all participants receive the new drug for a certain period and their blood pressure is measured again after completing the treatment (post-treatment measurement)
The two samples (basline and post-treatment measurements) represents dependent samples. This is because the samples are collected from the same group of participants at two different points in time, and each participant's post-treatment blood pressure is related to their baseline blood pressure.

The null and alternative hypotheses
A factory has two machines, machine X and machine Y that independently produce table tennis balls. The diameters of the balls made by the machines are known to be normally distributed with SD of σx = 0.25mm and σy = 0.3mm
Engineers want to know whether the population mean diameter μx of balls produced by machine X is larger than the population mean diameter μy of balls made by machine Y they decide to conduct a hypothesis test at the 5% significant level.
The engineer sample 14 balls produced by machine X and 16 balls made by machine Y and found that their mean are 40.2mm and 39.9mm respectively is there sufficient evidence that μx > μy based on data from this sample?
The populations are normally distributed and the sample are independent therefore the distribution of the difference of sample means is also normal
X̄ - Ȳ ~ N((μx - μy), (σx^2/nx + σy^2/ny))
H0 : μx = μy is the null hypothesis
H1 : μx > μy is the alt (one-tailed) hypothesis
α = 5%
find the critical region
P(Z >= zp) = α = 0.05
p |0.100|0.050|0.025|0.010|0.005|
zp|1.282|1.645|1.960|2.326|2.576|
---------------------------------
P(Z > 1.645) = 0.05
Z_0.05 = 1.645 is our critical value
Z >= 1.645 the critical region
sample data
x̄ = 40.2,  ȳ = 39.9
nx = 14,   ny = 16
σx = 0.25, σy = 0.3
assuming the null hypothesis μx = μy test statistic
z = (x̄ - ȳ - (μx - μy))/(sqrt(σx^2/nx + σy^2/ny))
= (40.2 - 39.9 - (0))/(sqrt(0.25^2/14 + 0.3^2/16))
~= 2.987
if we assume μx = μy (null is true) getting two samples where the means differ by x̄ - ȳ = 0.3mm or more has a probability that is smaller than 0.05 = 5% our significance level our significance level
we have a statistically significant result and reject the null hypothesis
in conclusion there is sufficient evidence that at the 5% level of significance we have μx > μy

Testing a hypothesis given two normal populations: one-tailed test
consider two independent samples of sizes nx = 35 and ny = 15 from normal populations X and Y with SD σx = 2 and σy = 3 testing the hypothesis test at the 5% significance level to determine whether there is sufficient evidence that the population mean μx of X is smaller than the population mean μy of Y
the sample means are x̄ = 6 and ȳ = 7 which statements are true
1. the 5% one-tailed critical region for the test statistic is approximately Z <= -1.960
2. at the 5% level of significance there is insufficient evidence that μx < μy
3. at the 5% level of significance there is sufficient evidence that μx < μy
p |0.100|0.050|0.025|0.010|0.005|
zp|1.282|1.645|1.960|2.326|2.576|
---------------------------------
H0 : μx = μy is the null hypothesis
H1 : μx < μy is the alt one-tailed hypothesis
assuming null
z = (x̄ - ȳ - (μx - μy))/(sqrt(σx^2/nx + σy^2/ny))
= (6 - 7 - (0))/(sqrt(2^2/35 + 3^2/15))
~= -1.183
statement 1 is false according to the table, the 5% one-tailed critical value is z ~= 1.645
since the hypothesis is μx < μy we must consider the left tail we do this using the symmetry of the normal distribution so the critical region is
Z <= -1.645
statement 2 is true while statement 3 is false -1.183 is above the table at 0.05 being at -1.645 so it does not lie in the critical region we do not reject the null hypothesis H0 there is insufficient evidence that at the 5% level of significance we have μx < μy

Testing a hypothesis given two normal populations: two-tailed tests
consider two independent samples of sizes nx = 12 and ny = 15 from normal population X and Y with SD σx = 2 and σy = 4, test the hypothesis at 10% significance level to determine whether there is sufficient evidence that the population mean μx of X is not equal to the population mean μy of Y
sample means are x̄ = 25 and ȳ = 24 which statements are true?
1. the 10% two-tailed critical region for the test staatistic is approximately Z <= -1.645 or Z >= 1.645
2. at the 10% level of significance there is insufficient evidence that μx != μy
3. at the 10% level of significance there is sufficient evidence that μx != μy
p |0.100|0.050|0.025|0.010|0.005|
zp|1.282|1.645|1.960|2.326|2.576|
---------------------------------
H0 : μx = μy null hypothesis
H1 : μx != μy alt two-tailed hypothesis
z = (x̄ - ȳ - (μx - μy))/(sqrt(σx^2/nx + σy^2/ny))
= (25 - 24 - (0))/(sqrt(2^2/12 + 4^2/15))
~= 0.845
statement 1 is true, according to the table the 10% two-tailed critical value (same as 10%/2 = 5%) is z ~= 1.645
critical region is Z <= -1.645 or Z >= 1.645
statement 2 is true, while statement 3 is false our test statistic 0.845 does not lie in the critical region
reject the null hypothesis H0, there is insufficient evidence that at the 10% level of significance we have μx != μy
correct statements are 1 and 2 only.

Sufficiently large means that nx >= 30 and ny >= 30

Testing a hypothesis given two large samples
Consider independent two samples of sizes nx = 82 and ny = 71 from populations X and Y with SD σx = 12 and σy = 9 we want to carry out hypothesis test at 5% significance level to determine whether there is sufficient evidence that the population mean μx of X is smaller than the population mean μy of Y
given that the sample means x̄ = 12 ȳ = 17
1. the 5% critical region for the test statistic is approximately Z <= -1.645
2. At the 5% level of significance there is insufficient evidence that μx < μy
3. At the 5% level of significance there sufficient evidence that μx < μy
samples are independent and nx = 82 > 30, ny = 71 >= 30
H0 : μx = μy null hypothesis
H1 : μx < μy alt one-tailed hypothesis
z = (x̄ - ȳ - (μx - μy))/(sqrt(σx^2/nx + σy^2/ny))
= (12 - 17 - (0))/(sqrt(12^2/82 + 9^2/71))
~= -2.938
statement 1 is true according to the table the 5% one-tailed critical value is z ~= 1.645
since at is μx < μy we must consider the left tail using the symmetry of the normal distribution so our critical region is
Z <= -1.645
statement 2 is false, while statement 3 is true, test statistic (-2.938) lies in the critical region so we reject the null hypothesis H0 there is sufficient evidence that at the 5% level of significance we have μx < μy
correct answer is 1 and 3 only.

Applications of hypothesis testing
Previous studies show that the scores of men and women on a particular test have SD of 17 and 14 points. Scientists want to determine whether the population mean μx for men is the same as the population mean μy for women, hypothesis test at 10% significance level
given that the scientists sampled 150 men and 125 women found that their mean scores on the test are 99.7 points and 101.2 points
1. the 10% critical region for the test statistic is approximately Z <= -1.645 or Z >= 1.645
2. the 10% level of significance there is insufficient evidence that μx != μy
3. the 10% level of significance there is sufficient evidence that μx != μy
p |0.100|0.050|0.025|0.010|0.005|
zp|1.282|1.645|1.960|2.326|2.576|
---------------------------------
samples are independent nx = 150 >= 30, and ny = 125 >= 30 are sufficienlty large
H0 : μx = μy null hypothesis
H1 : μx != μy alt two-tailed hypothesis
we have
x̄ = 99.7, ȳ = 101.2, nx = 150, ny = 125, σx = 17, σy = 14
= (99.7 - 101.2 - (0))/(sqrt(17^2/150 + 14^2/125))
~= -0.802
statement 1 is true, according to the table, 10% two-tailed critical value (10% / 2 = 5%) for the z-score ~= 1.645
critical region is
Z <= -1.645 or Z >= 1.645
statement 2 is true while 3 is false, our test statistic (-0.802) does not lie in the critical region, so we can reject the null hypothesis, there is insufficient evidence that at 10% level of significance μx != μy
correct answer is 1 and 2

===================================================

Confidence intervals for one mean: known population variance
We conduct a random sample of size n = 10 from a normal population with the unknown population mean μ and known population variance σ^2 = 9 after processing our results we compute the mean of this sample using the usual methods
x̄ = 12
this is an unbiased estimate of the population mean μ. However this is not enough data to know regarding its reliability.
For this reason its more helpful to give a range of possible values for μ, in other words instead of reporting a single esitmate x̄ we might insteead report a so-called confidence interval which is an interval of the form
(x̄ - E, x̄ + E)
x̄ is our estimate of population mean
E is some margin of error
we need to give some indication regarding the reliability of our confidence interval with this in mind we will construct a 95% confidence interval for the population mean μ.

Constructing confidence intervals
The population is normally distributed, therefore the sample mean X̄ is also normally distributed
X̄ ~ N(μ, σ^2/n)
by tansforming X̄ to a standard normal random variable
Z = (X̄ - μ)/(σ/sqrt(n)) ~ N(0,1)
we wish to find a z-interval that we're 95% confident that the random variable Z lies within this interval, to help with the notation we define α since we're computing a 95% confidence interval
α = 1 - 0.95 = 0.05 => α/2 = 0.025
α/2 is precisely the area bounded by each tail that we're excluding from our confidence interval, the critical values at the endpoints of our interval as +/-z_α/2
P(Z > z_0.025) = P(Z < -z_0.025) = 0.025
using a percentage points table for the standard normal distribution we find that z_0.025 ~= 1.96
P(Z > 1.96) = P(Z < -1.96) = 0.025
or simply
P(-1.96 < Z < 1.96) = 0.95
there is a 95% probability that our random variable Z will lie in the interval (-1.96,1.96)
we solve the inequality inside the parentheses of the last probability statement for the population mean μ
-1.96 < Z < 1.96
-1.96 < (x̄ - μ)/(σ/sqrt(n)) < 1.96
-1.96 * σ/sqrt(n) < (x̄ - μ) < 1.96 * σ/sqrt(n)
-x̄ - 1.96 * σ/sqrt(n) < -μ < -x̄ + 1.96 * σ/sqrt(n)
x̄ + 1.96 * σ/sqrt(n) > μ > x̄ - 1.96 * σ/sqrt(n)
x̄ - 1.96 * σ/sqrt(n) < μ < x̄ + 1.96 * σ/sqrt(n)
A 95% confidence interval for the population mean μ is
(x̄ - 1.96 * σ/sqrt(n), x̄ + 1.96 * σ/sqrt(n))
substituting
n = 10, x̄ = 12, σ = 3
95% confidence interval for μ
(12 - 1.859, 12 + 1.859)

Confidence intervals for normal populations with known population variance
we have a random sample of size n from a normal population with the unknown population mean μ and known population variance σ^2 then for a given value α between 0 and 1 a [100(1 - α)]% confidence interval for the population mean μ
(x̄ - z_a/2 * σ/sqrt(n), x̄ + z_a/2 * σ/sqrt(n))
P(Z > z_a/2) = α/2 and Z ~ N(0,1)
the endpoints of our confidence interval are called confidence limits
x̄ +/- z_a/2 * σ/sqrt(n)
x̄ = estimate of population mean
σ/sqrt(n) = standard error of the mean
z_a/2  = corresponding z-score
E = z_a/2 * σ/sqrt(n) is the margin of error
confidence interval can be written as follows:
(x̄ - [margin of error], x̄ + [margin of error])
(x̄ - [z-score] * [standard error], x̄ + [z-score] * [standard error])
(x̄ - z_a/2 * σ/sqrt(n), x̄ + z_a/2 * σ/sqrt(n))
computing a confidence interval amount to finding the corresponding confidence limits

Finding confidence intervals from normal populations
consider a sample of size n = 9 from a normal population with SD σ = 2 given that the mean of the sample is x̄ = -5, find a 90% confidence interval for the population mean μ of the distribution
Hint: use the face that P(Z > 1.645) = 0.05, where Z ~ N(0,1)
given a value α between 0 and 1 the corresponding [100(1 - α)]% confidence interval for the population mean μ of the original distribution
x̄ +/- z_a/2 * σ/sqrt(n)
where P(Z > z_a/2) = α/2 and Z ~ N(0,1)
90% confidence interval
α = 1 - 0.9 - 0.1 => α/2 = 0.05
were given that P(Z > 1.645) = 0.05
z_a/2 = z_0.05 = 1.645
therefore a 90% confidence interval for the population mean μ
-5 +/- 1.645 * 2/sqrt(9)
= -5 +/- 1.097

Interpreting confidence intervals
its important to be able to interpret confidence intervals correctly Imagine we conduct several independent random samples from a population. The mean of the sample will be different for each sample some values of x̄ might lie close to the population mean μ and some could lie further away.
If we contruct 90% confidence intervals one for each sample then approximately 90% of theseintervals will contain the population mean μ

Finding confidence intervals from large samples
Consider a sample of size n = 196 from a population with SD σ = 7 given that the mean of the sample is x̄ = 24 find a 95% confidence interval for the population mean μ of the distribution
Hint: Use P(Z > 1.96) = 0.025 where Z ~ N(0,1)
sample size n = 196 >= 30 sufficiently large
finding a 95% confidence interval
α = 1 - 0.95 = 0.05 => α/2 = 0.025
P(Z > 1.96) = 0.025
z_a/2 = z_0.025 = 1.96
the 95% condfidence interval for the population mean μ
24 +/- 1.96 * 7/sqrt(196)
24 +/- 0.98

Finding confidence intervals: applications
The daily percentage return of Apple stock has a population SD σ = 5% a sample of 90 randomly selected trading days was examined and it was found that the mean daily return of the stock over these days was 7.5% find a 90% confidence interval for the mean daily percentage return μ of the entire population of trading days 
p |0.100|0.050|0.025|0.010|0.005|
zp|1.282|1.645|1.960|2.326|2.576|
---------------------------------
we don't know the distribution of the population, the sample size n = 90 >= 30 is sufficiently large
x̄ = 7.5, n = 90, σ = 5
we are interested finding a 90% confidence interval
α = 1 - 0.9 = 0.1 => α/2 = 0.05
from the table z_0.05 = 1.645
90% confidence interval for the population mean μ
7.5 +/- 1.645 * 5/sqrt(90)
7.5 +/- 0.867

(rest of these examples are just looking up percentage table with the confidence percentage e.g. α = 1 - 0.99 = 0.01 => α/2 = 0.005, and substituting in all the values given)

===================================================

If σ^2 is unknown we must estimate it using the sample data to estimate the population variance σ^2 we use the sample variance S^2
S^2 = 1/n-1 Σ^n_i=1(Xi - X̄)^2
(X̄ - μ)/(S/sqrt(n)) ~ T_n-1
where T_n-1 is student's t-distribution with n - 1 degrees of freedom

Constructing confidence intervals
suppose we have a random sample of size n = 9 drawn from a normal population. The sample mean is x̄ = 30 and the sample SD is s = 3.3 we wish to compute a 95% confidence interval for the population mean μ a confidence interval is an interval of the form
(x̄ - E, x̄ + E)
x̄ is an estimate of the population mean
E is the margin of error
we wish to find a t-interval that we're 95% confident that the random variable T lies within
we define our parameter α
α = 1 - 0.95 = 0.05 => α/2 = 0.025
α/2 is precisely the area bounded by each tail that we're excluding from our confidence interval.
P(T > t_8,0.025) = P(T < -t_8,0.025) = 0.025
using a table of values for the t-distribution we find that t_8,0.025 ~= 2.306
P(T > 2.306) = P(T < -2.306) = 0.025
more simply
P(-2.306 < T < 2.306) = 0.95
95% probability that our random variable T will lie in the interval (-2.306,2.306)
Similar to the case where σ^2 was known we find the appropriate confidence interval by solving the inequality inside the parentheses of the last probability statement for the population mean μ
-2.306 < T < 2.306
-2.306 < (x̄ - μ)/(s/sqrt(n)) < 2.306
-2.306 * s/sqrt(n) < x̄ - μ < 2.306 * s/sqrt(n)
-x̄ - 2.306 * s/sqrt(n) < -μ < -x̄ + 2.306 * s/sqrt(n)
x̄ + 2.306 * s/sqrt(n) > μ > x̄ - 2.306 * s/sqrt(n)
x̄ - 2.306 * s/sqrt(n) < μ < x̄ + 2.306 * s/sqrt(n)
a 95% confidence interval for the population mean μ is given by
(x̄ - 2.306 * s/sqrt(n), x̄ + 2.306 * s/sqrt(n))
substituting values
n = 9, x̄ = 30, s = 3.3
we obtain that our 95% confidence interval for μ is
(30 - 2.537, 30 + 2.537)
confidence interval using confidence limits
30 +/- 2.537

Confidence intervals for normal populations with unknown population variance
suppose we have a random sample of size n from a normal population with the unknown population mean μ and sample variance s^2 for a given value α between 0 and 1 a [100(1 - α)]% confidence interval for the population mean μ
(x̄ - t_n-1,a/2 * s/sqrt(n), x̄ + t_n-1,a/2 * s/sqrt(n))
where P(T > t_n-1,a/2) = α/2 and T ~ T_n-2
the endpoints of our confidence interval are called confidence limits are given by
x̄ +/- t_n-1,a/2 * s/sqrt(n)
x̄ - population mean
s/sqrt(n) - standard error of the mean
t_n-1,a/2 - corresponding t-score
E = t_n-1,a/2 * s/sqrt(n) is the margin of error
our confidence interval
(x̄ - [margin of error], x̄ + [margin of error])
(x̄ - [t-score] * [standard error], x̄ + [t-score] * [standard error])
(x̄ - t_n-1,a/2 * s/sqrt(n), x̄ + t_n-1,a/2 * s/sqrt(n))
notice that the expression for the confidence interval is very similar to when the population variance was known. The only difference is that we now use the t-scores instead of z-scores and the sample SD s instead of the population SD σ

Finding confidence intervals from normal populations
A sample of size n = 9 from a normal population given the sample mean is 50 and the sample SD is 1.5 find a 99% confidence interval for the population mean μ of the distribution
Hint: Use the fact that P(T > 3.355) = 0.005 where T has a student's t-distribution with 8 degrees of freedom
we do not know the population variance σ^2 but the population is normally distributed 
(X̄ - μ)/(S/sqrt(n))
x̄ = 50, n = 9, s = 1.5
we are interested in finding a 99% confidence interval
α = 1 - 0.99 = 0.01 => α/2 = 0.005
given P(T > 3.355) = 0.005
t_n-1,α/2 t_8,0.005 = 3.355
a 99% confidence interval for the population mean μ
50 +/- 3.355 * 1.5/sqrt(9)
50 +/- 1.678

For large samples if the population is not normally distributed then the sample size n must be sufficiently large for this approximation to apply typically n >= 30 is sufficient

Finding confidence intervals from large samples
consider a sample of size n = 100 from a population. Given that the sample mean is 30 and the sample SD is 8 find a 90% confidence interval for the population mean μ of the distribution
Hint: P(T > 1.66) = 0.05 where T has a student's t-distribution with 99 degrees of freedom
n = 100 >= 30 sufficiently large
x̄ = 30, n = 100, s = 8
find a 90% confidence interval
α = 1 - 0.9 = 0.1 => α/2 = 0.05
given P(T > 1.66) = 0.05
t_n-1,α/2 = t_99,0,05 = 1.66
90% confidence interval for the population mean μ
30 +/- 1.66 * 8/sqrt(100)
= 30 +/- 1.328

Finding Confidence intervals: applications
a tire manufacturer measures the stopping distance of a new tire model from 60mph on a standard test car. A sample of 81 stopping distances yielded a sample mean of 132ft with a sample SD of 5.4ft find a 95% confidence interval for the mean stopping distance μ of these tires
Hint: given a random variable T that has a student's t-distribution T_k with k defgrees of freedom the table shows the t-scores such that P(T > t_k,p) = p for some particular values of k and p
k\p|0.100|0.050|0.025|0.010|0.005|
79 |1.292|1.664|1.990|2.374|2.640|
80 |1.292|1.664|1.990|2.374|2.639|
81 |1.292|1.664|1.990|2.373|2.638|
----------------------------------
sample size n = 81 >= 30 is sufficiently large
x̄ = 132ft, n = 81, s = 5.4ft
finding a 95% confidence interval
α = 1 - 0.95 = 0.05 => α/2 = 0.025
we also need to find the t-score value t_80,0.025 P(T > t_80,0.025) = 0.025 where T has a student's t-distribution with n - 1 = 81 - 1 = 80 degrees of freedom.
t_80,0.025 = 1.990
the 95% confidence interval for the population mean μis
132 +/- 1.99 * 5.4/sqrt(81)ft
= 132 +/- 1.194ft

===================================================

How to construct a condifence interval for the proportion of the population whose members have a particular characteristic
Let p represent the proportion of the United States voting population that will vote for candidate A in the next presidential election
We conduct a random sample of size n = 40 from out population after processing our results we find the the proportion p̂ of sample members that plan to vote for candidate A is given by
p̂ = 0.3
estimate of population proportion p
the quantity that we're really interested in is p the proportion of the entire voting population that will vote for candidate A. We want to get an idea of how accurate our estimate is, we wish to construct a confidence interval
(p̂ - E, p̂ + E)
where E is some margin of error
constructing a 95% confidence interval for the population proportion p
the first thing to do is to establish the sampling distribution of p(hat)
since the United States has around 240 million registered voters, the sample size n = 40 is less than 10% of the population size, provided certain conditions are met the following can be applied
p̂ ~ N(p, (p(1 - p))/n)
lets check that our usual conditions hold in this case (where we use p̂ as an estimate for p)
np̂ = 40 * 0.3
= 12
> 5
n(1 - p̂) = 40 * (1 - 0.3)
= 28
> 5
since all three conditions hold the approximation is applicable
by transforming p̂ to a standard normal random variable
Z = (p̂ - p)/sqrt(p̂(1 - p̂)/n) ~ N(0,1)
95% confidence interval
α = 1 - 0.95 = 0.05 => α/2 = 0.025
α/2 is the area bounded by eachg tail we're exluding from our confidence interval.
P(Z > z_0.025) = P(Z < -z_0.025) = 0.025
using a percentage points table for the standard normal distribution we find that z_0.025 ~= 1.96
P(Z > 1.96) = P(Z < -1.96) = 0.025
= P(-1.96 < Z < 1.96) = 0.95
there is a 95% probability that our random variable Z will lie in the interval (-1.96,1.96)
-1.96 < Z < 1.96
-1.96 < (p̂ - p)/sqrt(p̂(1 - p̂)/n) < 1.96
-1.96 * sqrt(p̂(1 - p̂)/n) < p̂ - p < 1.96 * sqrt(p̂(1 - p̂)/n)
-p̂ - 1.96 * sqrt(p̂(1 - p̂)/n) < -p < -p̂ + 1.96 * sqrt(p̂(1 - p̂)/n)
p̂ + 1.96 * sqrt(p̂(1 - p̂)/n) > p > p̂ - 1.96 * sqrt(p̂(1 - p̂)/n)
p̂ - 1.96 * sqrt(p̂(1 - p̂)/n) < p < p̂ + 1.96 * sqrt(p̂(1 - p̂)/n)
a 95% confidence interval for the population proportion p̂
(p̂ - 1.96 * sqrt(p̂(1 - p̂)/n), p̂ + 1.96 * sqrt(p̂(1 - p̂)/n))
substituting
n = 40, p̂ = 0.3
95% confidence interval for p
(0.3 - 0.142, 0.3 + 0.142)
simplifies
(0.158,0.442)

Confidence intervals for proportions
Suppose we have a random sample size n from a sufficiently large population with sample proportion p̂ 
np̂ > 5
n(1 - p̂) > 5
then for a given value α between 0 and 1 and a [100(1 - α)]% confidence interval for the population proportion p is
(p̂ - z_α/2 * sqrt(p̂(1 - p̂)/n), p̂ + z_α/2 * sqrt(p̂(1 - p̂)/n))
the endpoints of our confidence interval are the confidence limits
p̂ +/- z_α/2 * sqrt(p̂(1 - p̂)/n)
p̂ - is the sample proportion
p - is the population proportion
n - is the sample size
z_α/2 - is the corresponding z-score
E = z_α/2 * sqrt(p̂(1 - p̂)/n is the margin of error
confidence interval can be written as follows
(p̂ - [margin of error], p̂ + [margin of error])
(p̂ - [z-score] * [standard error], p̂ + [z-score] * [standard error])
(p̂ - z_α/2 * sqrt(p̂(1 - p̂)/n), p̂ + z_α/2 * sqrt(p̂(1 - p̂)/n))

finding confidence intervals for population proportions
consider a sample of size n = 100 from a large population where some individuals have a particular characteristic, given that the proportion of those in the sample with the characterisitc is p̂ = 0.64 find a 90% confidence interval for the population proportion p of individuals having this characteristic
Hint: use the fact that P(Z > 1.645) = 0.05 where Z ~ N(0,1)
n = 100, and p̂ = 0.64
np̂ = 100 * 0.64 = 64 > 5
n(1 - p̂) = 100 * (1 - 0.64) = 36 > 5
α = 1 - 0.9 = 0.1 => α/2 = 0.05
we are given that P(Z > 1.645) = 0.05
z_α/2 = z_0.05 = 1.645
90% confidence interval for the population proportion p
0.64 +/- 1.645 * sqrt(0.64(1 - 0.64)/100)
0.64 +/- 0.079

Finding confidence intervals for population proportions in context
A survery of a random sample of 1500 US households reveals that 780 of them own at least one horse. Find a 95% confidence interval for the proportion of all U.S. households that own at least one horse.
p |0.100|0.050|0.025|0.010|0.005|
zp|1.282|1.645|1.960|2.326|2.576|
---------------------------------
interpreting the data
the population consists of all U.S. households
some of the households surveyed own at least one horse some dont
size of the random sample is n = 1500
the proportion of households in the sample that own at least one horse
p̂ = 780/1500 = 0.52
np̂ = 1500 * 0.52 = 780 > 5
n(1 - p̂) = 1500 * (1 - 0.52) = 720 > 5
95% confidence interval
α = 1 - 0.95 = 0.05 => α/2 = 0.025
from the percentage points table of the normal distribution we obtain
Z_0.025 = 1.960
0.52 +/- 1.96 * sqrt(0.52(1 - 0.52)/1500)
0.52 +/- 0.025

