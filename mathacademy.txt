Vecotr equation of straight line passing through P and parallel to v:
r = p + tv

example:
P(-2, 5, -3) v = <1, -1, 2>
AP = sqrt(24)

(<-2, 5, -3> + t<1, -1, 2>) - <-2, 5, -3>
= <-1, 4, -1> - <-2, 5, -3>
= t<1, -1, 2>
= <t, -t, 2t>
|<t, -t, 2t>| = sqrt(24)
sqrt(t^2 + -t^2 + 2t^2) = sqrt(24)
sqrt(6t^2) = sqrt(24)
+/-t sqrt(6) = 2sqrt(6)
t = +/- 2
OA1-> = <-2, 5, -3> + 2<1, -1, 2> = <0, 3, 1>
OA2-> = <-2, 5, -3> - 2<1, -1, 2> = <-4, 7, -7>

example:
P(3, 1, -1) v = <2, 1, 3>
AP = sqrt(14)

(<3, 1, -1> + t<2, 1, 3>) - <3, 1, -1>
= <5, 2, 2> - <3, 1, -1>
= t<2, 1, 3>
= <2t, t, 3t>
|<2t, t, 3t>| = sqrt(14)
sqrt(2t^2 + t^2 + 3t^2) = sqrt(14)
+/-tsqrt(14) = sqrt(14)
t = +/-1

OA1-> = <3, 1, -1> + 1<2, 1, 3> = <5, 2, 2>
OA2-> = <3, 1, -1> - 1<2, 1, 3> = <1, 0, -4>

Find the parametric equations of the straight line that passes through
P(1, 4, -2) and Q(5, 3, 0)

[5, 3, 0] - [1, 4, -2] = [4, -1, 2]
[1, 4, -2] + t[4, -1, 2]
= [x, y, z] = [1 + 4t, 4 - t, 2t - 2]

Cartesian (canonical) equation of the straight line that passes through the point P(x0, y0, z0) and is parallel to the vector v = <vx, vy, vz> is given by:
(x - x0)/vx = (y - y0)/vy = (z - z0)/vz = t

==================================================

Equation of the plane that contains the point P(sqrt(2), 3, 4) and is perpendicular to the vector n = 2sqrt(2)i + 7j - 6k
The equation of the plane that passes through the point P(x0, y0, z0) and it perpendicular to the vector n can be given as:
(r - p) ⋅ n = 0

example:
r ⋅ n - p ⋅ n = 0
r ⋅ n = p ⋅ n
r ⋅ (2sqrt(2)i + 7j - 6k) = (sqrt(2)i + 3j + 4k) ⋅ (2sqrt(2)i + 7j - 6k)
r ⋅ (2sqrt(2)i + 7j - 6k) = 1

example:
P(2, -5, 3) and n = <-1, 2, -3>
r ⋅ <-1, 2, -3> = <2, -5, 3> ⋅ <-1, 2, -3>
r ⋅ <-1, 2, -3> = -21

==================================================

Hyperbolic cosine (pronounced "cosh"):

cosh x = 1/2(e^x + e^-x)

example:
evaluate cosh(ln2)
cosh(ln2) = 1/2(e^(ln2) + e^(-ln2))
= 1/2(e^(ln2) + e^(ln2^-1))
= 1/2(2 + 2^-1)
= 1/2(2 + 1/2)
= 1/2((4 + 1)/2)
= 5/4

example:
cosh(lnsqrt(3))
= 1/2(e^(lnsqrt(3)) + e^(-lnsqrt(3)))
= 1/2(e^(lnsqrt(3)) + e^(ln(1/sqrt(3))))
= 1/2(sqrt(3) + 1/sqrt(3))
= 1/2((3 + 1)/sqrt(3))
= 4/2sqrt(3)
= 2/sqrt(3)

Hyperbolic sine (pronounced "shine"):

sinh x = 1/2(e^x - e^-x)  also can be: (e^x - e^-x)/2

example:
sinh 1
= 1/2(e^1 - e^-1)
= 1/2(e - 1/e)
= 1/2((e^2 - 1)/e)
= (e^2 - 1)/2e

example:
sinh(lnsqrt(2))
= 1/2(e^(lnsqrt(2)) - e^(ln(1/sqrt(2))))
= 1/2(sqrt(2) - 1/sqrt(2))
= 1/2((2 - 1)/sqrt(2))
= 1/2sqrt(2)

Hyperbolic tangent (pronounced "tanch"):

tanh x sinh/cosh = (e^x - e^-x)/(e^x + e^-x)

has horizontal asymptotes y = +/- 1

we can write down the same equation by multiplying
numerator and denomenator e^x or e^-x

(e^x - e^-x)/(e^x + e^-x) * e^x/e^x
= (e^(2x) - 1)/(e^(2x) + 1)

(e^x - e^-x)/(e^x + e^-x) * e^-x/e^-x
= (1 - e^(-2x))/(1 + e^(-2x))

example:
tanh 4 (using the second definition)
= (e^(2(4)) - 1)/(e^(2(4)) + 1)
= (e^8 - 1)/(e^8 + 1)

example:
tanh (2ln3)
= (e^(2(2ln3)) - 1)/(e^(2(2ln3)) + 1)
= (e^(4ln3) - 1)/(e^(4ln3) + 1)
= (e^(ln3^4) - 1)/(e^(ln3^4) + 1)
= (3^4 - 1)/(3^4 + 1)
= (81 - 1)/(81 + 1)
= 80/82
= 40/41

example:
tanh(-ln2) (using the third definition)
= (1 - e^(-2(-ln2))) / (1 + e^(-2(-ln2)))
= (1 - e^(2ln2)) / (1 + e^(2ln2))
= (1 - e^(ln2^2)) / (1 + e^(ln2^2))
= (1 - e^(ln4)) / (1 + e^(ln4))
= (1 - 4) / (1 + 4)
= -3/5

Relationship between trigonometric and hyperbolic cosine:
Euler's formula:
e^(iθ) = cosθ + isinθ

replace θ with -θ:
e^(-iθ) = cosθ - isinθ

adding the two equations:
e^(iθ) + e^(-iθ) = 2cosθ
cosθ = 1/2(e^(iθ) + e^(-iθ))
identity:
cosθ = cosh(iθ)

Same relationship between trigonometric and hyperbolic sine
Euler's formula:
e^(iθ) = cosθ + isinθ
e^(-iθ) = cosθ - isinθ

subtracting the two equations
e^(iθ) - e^(-iθ) = 2isinθ

sinθ = 1/2i(e^(iθ) - e^(-iθ))
= -i/2(e^(iθ) - e^(-iθ))
identity:
sinθ = -isinh(iθ)

==================================================

Calculating a Cofactor
for any nxn matrix A, the cofactor Cij of the entry aij is:
Cij = (-1)^(i+j)Mij

example:
d23 (second row, third column)
C23 = (-1)^(i+j)M23 = -M23

example:
cofactor can be an equation of the first row:
det(A) = a11C11 + a12C12 + ... + a1nC1n
(I will indicate | for the next row)

A = [
  -3  0 0  5
   0  0 3 -2
   4 -1 2 -3
  -1  6 0  0
]
-3*C11 + 5*C14

(-3)(-1)^1+1 [
				0  3 -2
			   -1  2 -3
			    6  0  0
			 ]
+ 5(-1)^1+4 [
				0  0 3
				 4 -1 2
				-1  6 0
			]

= -3 [
	   0  3 -2
      -1  2 -3
       6  0  0
	 ]
= -5 [
	   0  0 3
	   4 -1 2
	  -1  6 0
	 ]

= -3(0*[2 -3|0 0]-3*[-1 -3|6 0]-2*[-1 2|6 0])
= -5(0*[-1 2|6 0]-0*[4 2|-1 0]+3*[4 -1|-1 6])
= -3*(-3*(0+18) + (-2)*(0-12) -5*(3*(24-1)))
= 90 -345
= -255

example:
A = [
	  0 8 0 0
	  -1 0 0 0
	  3 1 6 2
	  1 0 -1 2
	]

8(-1)^1+2 [
	-1  0 0
	 3  6 2
	 1 -1 2
   ]

= -8(-1*[6 2|-1 2]-0[3 2|1 2]+0[3 6|1 2])
= 8(6 * 2 - (-1) * 2) - 0 + 0
= 8 * 14
= 112

==================================================

We don't always have to use the first row, we can use any row or column and this is known as a Laplace expansion. It's useful to use this along a row or column with the most 0's

2 [
	2  1 -1
	-4 -2 1
	1  2  0
]

2(2*[-2 1|2 0]-1*[-4 1|1 0]-1*[-4 -2|1 2])
= 2(-2) 1 -1
= -8


example:
A [
	1  2  1 -1
	0 -4 -2  1
	2  0  0  1
	-3 1  2  0
]
= 2*(-1)^3+1 [
				2   1 -1
				-4 -2  1
				1   2  0
			 ]
+
1*(-1)^3+4 [
				1  2  1
				0 -4 -2
				-3 1  2
		   ]

= 2 [
	2   1 -1
	-4 -2  1
	1   2  0
]
-
[
	1  2  1
	0 -4 -2
	-3 1  2
]

Now we can compute the first 3x3 determinant by applying laplace expansion:

2 [
	2   1 -1
	-4 -2  1
	1   2  0
] = 1*C31 + 2*C32 + 0*C33
= 1*(-1)^3+1 * [1 -1|-2 1] + 2*(-1)^3+2 * [2 -1|-4 1]
= [1 -1|-2 1]-2[2 -1|-4 1]
= (1 - 2) - 2(2 - 4)
= -1 + 4
= 3

Second 3x3 from above
- [
	1  2  1
	0 -4 -2
	-3 1  2
] = 0*C21 + (-4)*C22 + (-2)*C23
= (-4)*(-1)^2+2 * [1 1|-3 2] + (-2)*(-1)^2+3 * [1 2|-3 1]
= -4[1 1|-3 2] + 2[1 2|-3 1]
= -4(2+3) + 2(1+6)
= -20 + 14
= -6

THEREFORE:
[
	1  2  1 -1
	0 -4 -2  1
	2  0  0  1
	-3 1  2  0
] = 2 * 3 - (-6) = 12

==================================================

Three basic properties of determinants:
1) The determinant of an nxn identity matrix is equal to 1
(this means 1s on diagonal and 0s everywhere else)
det(I) = 1

2) The determinant of a triangular or diagonal matrix is equal to the product of the entries on the main diagonal.
(this means all 0s triangle above/below the diagonal)

3) The determinant of A^T, the transpose of A, is the same as the determinant of A:
det(A^T) = det(A)
 
example:
[
  -2 0 0 0
  -4 1 0 0
  1 10 sqrt(3) 0
  -3 0 6 -2
] = (-2) * 1 * sqrt(3) * (-2) = 4sqrt(3)

You can use the determinant to find the volume of a parallelepiped (absolute value):
V = |det(M)|

The determinant of the product of two square matrices is equal to the product of the determinants:
det(A * B) = det(A) * det(B)

Another useful property of determinants is that, for any invertible matrix A, we have:
det(A^-1) = 1/det(A)

Remember A * A^-1 = I for any invertible matrix A. So we have:
A * A^-1 = I
det(A * A^-1) = det(I)
det(A) * det(A^-1) = 1
det(A^-1) = 1/det(A)
We can only apply this formula if A is invertible meaning that det(A) != 0

Calculating a determinant using linearity of the determinate:
(you can view a screenshot of this +/- between rows/columns)
example:
[
  107 215 99
   6   8  11
  107 215 100
]
Notice the 1st row of our determinant is almost equal to the 3rd row. So we can rewrite the given determinant as follows:
[
  107 215 99
   6   8  11
  107 215 100
] = [
  107 215 99
   6   8  11
107+0 215+0 99+1	
]

=

[
  107 215 99
   6   8  11
  107 215 99
] + [
  107 215 99
   6   8  11
   0   0   1
]
The first determinant must be zero since it has two identical rows, while the second determinant can be expanded across the 3rd row:
= 0 + 1(-1)^3+3*[107 215|6 8]
= 107 * 8 - 215 * 6
= -434

We can also use factorization to find the determinant:
example:
we are given:
[
  a+3 -5
   b   6
] = -7

find:
[
  a+2 -5
  b+4  6
] = [
  (a+3)-1 -5
    b+4    6
]

=

[
  a+3 -5
   b   6
] + [
  -1 -5
   4  6
]
= -7 + (-6 + 20) = 7

==================================================

(This applies to columns as well)
remember three standard row operations:
1) swapping two rows
2) Multiplying a row by a non-zero number
3) Adding a multiple of one row to another row
only 3 preserves the determinant.
swapping any two rows changes the sign of the determinant
multiplying a row by a number scales the determinant by that number

if we multiply the same number across multiple rows say 2rows and we use 3 then this scales the determinant 3^2
= det(k * A) = k^n * det(A)

example:
A is a 4x4 matrix and det(A)=5 what is the value of det(2A)
k = 2 and n = 4
det(2A) = 2^4 * det(A)
= 16 * 5
= 80


if a matrix has an entire row/column as 0 its determinant is zero
if a square matrix has at least two identical rows/columns, its determinant equals 0 (because we can subtract one row/column from another making it 0)
if a square matrix has at least two proportional rows/columns, its determinant equals zero
if a row/column has a linear combination of other rows/columns determinant is 0

det(A) = 0 if and only if one of the rows/columns of A is a linear combination of other rows/columns of A

==================================================

The first non-zero entry on each row (from left to right) is called the leading entry of that row.

row echelon form:
1) all the zeros rows (rows with only zeros) if any, are placed at the bottom of the matrix
2) Each leading entry of a row is in a column to the right of the leading entry of the row above it.

==================================================

When an augmented matrix is in row echelon form, we can solve the system using a method called back substitution.
back substitution involves:

starting with the lowest equation (which is already solved for one variable)

substituting the result into the next-lowest equation to find the solution for another variable, and

continuing to substitute the result into the next-lowest equation until the values of all the variables have been found.

The procedure for reducing a matrix to row echelon form using elementary row operations is called Gaussian elimination

Step 1) We want to make an entry the pivot element and we will make this entry equal to 1 (a11)
example:
{
	2x + 6y = -2
	3x - y = 2
}

M = [
	2  6 | -2
	3 -1 |  2
]
R1 := 1/2R1
~ [
	1  3 | -1
	3 -1 | 2
]

Step 2) We want to make the entry below the pivot entry = 0 (a21)
R2 := R2 + (-3)R1
~ [
	1   3 | -1
	0 -10 |  5
]
(already in REF, makes it easier if all diagonal is 1s)

Step 3) Now we need a second pivot element specifically -10 (a22) = 1
R2 := 1/-10R2
~ [
	1  3 | -1
	0  1 | -1/2
]
The system is now:
{
	x + 3y = -1
	y = -1/2
}
applying back subsitution we get:
x + 3(-1/2) = -1
x = 1/2
Therefore the solution is x = 1/2 and y = -1/2
vector form: <1/2, -1/2>

example:
[
	2 7  | -5
	7 11 | -4
]

R1 := 1/2R1
~ [
	1 7/2 | -5/2
	7  11 | -4
]

R2 := R2 -7R1
~ [
	1   7/2 | -5/2
	0 -27/2 | 27/2
]

R2 := -2/27R2
~ [
	1 7/2 | -5/2
	0   1 | -1
]

if a system of linear equations turns out to be all 0s on the bottom then that variable becomes the "free" variable:
{
	x - 2y = -5
 -3x + 6y = 15
}
= [
	1 -2 | -5
 -3  6 | 15
]
R2 := R2 + 3R1
[
	1 -2 | -5
	0  0 |  0
] = {
	x - 2y = -5
  0x + 0y = 0
}
x is called basic variable
y is our free variable
{
	x = -5 + 2y
	y = y
}
vector form:
[
	x
	y
] = [
	-5 + 2y
	   y
] = [
	-5
	 0
] + y[
	2
	1
]
Given a 2x2 system of linear equations we have the solutions:

Consistent independent
The system has exactly one solution if and only if the repective coefficient matrix is non-singular (determinant is non zero)

Consistent dependent
system has infinitely many solutions if the second row in SEF contains only 0's

Inconsistent systems
no solution, the second row in SEF contains only 0's on the left and non-zero on the right.

A homogeneous system always has at least one solution, x = 0 and y = 0, or in the vector form <0, 0>

==================================================

The standard Gaussian elimination for a 3x3 system:
1) if a11 != 0 and a11 != 1 then use the row operation R1 := R1/a11
2) use the first row to make the column below a11 0, if a21 != 0 then R2 := R2 + (-a21)R1; if a31 != 0 then R3 := R3 + (-a31)R1
3) if a22 != 1 then R2 := R2/a22
4) use second row to make the entries below a22 = 0. If a32 != 0 then R3 := R3 + (-a32)R2
5) if a33 != 0 then R3 := R3 + R3/a33
6) In special cases, if element on diagonal = 0 we need to exchange rows then proceed as above.


example:
[
	1 2 6   | 5
	0 1 -10 | -11
	4 8 13  | 9
]

R3 := R3 + (-4)R1
[
	1 2 6   | 5
	0 1 -10 | -11
	0 0 -11 | -11
]

R3 := -R3/11
[
	1 2 6   | 5
	0 1 -10 | -11
	0 0 1   | 1
]


example:
[ 
	1 -1 2 | 8
 -2 2 -3 | -11
  1 0  1 | 9
]

R2 := R2 + 2R1
[ 
	1 -1 2  | 8
  0 0  1  | 5
  1 0  1  | 9
]

R3 := R1 - R3
[ 
	1 -1 2  | 8
  0 0  1  | 5
  0 -1 1  | -1
]

(0 is on diagonal we need to swap)
R2 <-> R3
[ 
	1 -1 2  | 8
	0 -1 1  | -1
  0 0  1  | 5
]
z = 5
-y + 5 = -1
-y = -6
y = 6
x - 6 + 10 = 8
x = 4

example:
[
	1 2 3 | 1
	1 2 5 | 3
	2 1 4 | 9
]

R2 := R1 - R2
[
	1 2 3  | 1
	0 0 -2 | -2
	2 1 4  | 9
]

R3 := R3 + (-2)R1
[
	1 2 3  | 1
	0 0 -2 | -2
	0 -3 -2  | 7
]

R3 <-> R2
[
	1 2 3  | 1
	0 -3 -2  | 7
	0 0 -2 | -2
]

R3 := -1/2R3
[
	1 2 3  | 1
	0 -3 -2  | 7
	0 0 1 | 1
]

R2 := -1/3R2
[
	1 2 3   | 1
	0 1 2/3 | -7/3
	0 0 1   | 1
]

==================================================

Pivots are the first non-zero entries of a matrix
To find the pivots and pivot columns of a general matrix, need to convert row into REF

The pivots of any matrix are the pivots of its row equivalent REF matrix

The pivot columns of a matrix are the pivot columns of row equivalent REF matrix.

example:
[
	1  0 0  0
	0  3 0 -2
	0 -6 1  4
]
R3 := R3 + 2R2
~ [
	1 0 0 0
	0 3 0 -2
	0 0 1 0
]
(3 pivots a11, a12, a13)

example:
[
	1  4  0  2
	0 -2 -4  2
	0  4  9 -6
	0  0  2 -4
]

R3 := R3 + 2R2
[
	1  4  0  2
	0 -2 -4  2
	0  0  1 -2
	0  0  2 -4
]

R4 := R4 + -2R3
[
	1  4  0  2
	0 -2 -4  2
	0  0  1 -2
	0  0  0  0
]
(columns 1, 2, 3 are pivots)

Gaussian elimination to reduce M to REF into a linear system:
[
	1 -2  -6 | 12
	2  4  12 | -16
	1 -4 -12 | 21
]

R2 := R2 + (-2)R1
[
	1 -2  -6 | 12
	0  8  24 | -40
	1 -4 -12 | 21
]

R3 := R1 - R3
[
	1 -2  -6 | 12
	0  8  24 | -40
	0  2  6 | -9
]


R3 := R1 - R3
[
	1 -2  -6 | 12
	0  8  24 | -40
	0  0  0 | 21
]
OR: 
1) R2 := R2 + (-2)R1
2) R3 := R3 - R1
3) R2 := 1/8R2
4) R3 := R3 + 2R2

NO SOLUTION, last equation is 0x + 0y + 0z = 21 which is false

example:
{
	2x + 6y + 8z = 12
	y - z = -1
	4x + 4y + 24z = 7
}

[
	2 6  8 | 12
	0 1 -1 | -1
	4 4 24 | 7
]

R1 := 1/2R1
[
	1 3  4 | 6
	0 1 -1 | -1
	4 4 24 | 7
]

R3 := R3 - 4R1
[
	1 3  4 | 6
	0 1 -1 | -1
	0 -8 8 | -17
]

R3 := R3 + 8R2
[
	1 3  4 | 6
	0 1 -1 | -1
	0 0  0 | -25
]

==================================================

Reduced Row Echelon Form (RREF)
(Gauss-Jordan)
similiar to REF except all pivots = 1 and all entries below and above a pivot (in a column) = 0

Unlike the row echelon form, the RREF of a matrix is unique

example:
[
	1 2 1 | 14
	0 1 1 | 8
	0 0 1 | 4
]

R2 := R2 + (-1)R3
[
	1 2 1 | 14
	0 1 0 | 4
	0 0 1 | 4
]

R1 := R1 + (-1)R3
[
	1 2 0 | 10
	0 1 0 | 4
	0 0 1 | 4
]

R1 := R1 + (-2)R2
[
	1 0 0 | 2
	0 1 0 | 4
	0 0 1 | 4
]

example:
[
	1 -1 1 | 1
	2 -1 1 | 3
	-1 1 0 | -3
]

R2 := R2 - 2R1
[
	1 -1 1 | 1
	0  1 -1 | 1
	-1 1 0 | -3
]

R3 := R3 + R1
[
	1 -1 1 | 1
	0  1 -1 | 1
	0 0 1 | -2
]

R2 := R2 + R3
[
	1 -1 1 | 1
	0  1 0 | -1
	0 0 1 | -2
]

R1 := R1 - R3
[
	1 -1 0 | 3
	0 1 0 | -1
	0 0 1 | -2
]

R1 := R1 + R2
[
	1 0 0 | 2
	0 1 0 | -1
	0 0 1 | -2
]


example:
[
	1 1 1 | 2
	1 2 1 | 0
	1 1 2 | 3
]

R2 := R2 - R1
[
	1 1 1 | 2
	0 1 0 | -2
	1 1 2 | 3
]

R3 := R3 - R1
[
	1 1 1 | 2
	0 1 0 | -2
	0 0 1 | 1
]

R1 := R1 - R3
[
	1 1 0 | 1
	0 1 0 | -2
	0 0 1 | 1
]

R1 := R1 - R2
[
	1 0 0 | 3
	0 1 0 | -2
	0 0 1 | 1
]

x = 3
y = -2
z = 1

example:
[
	-1 -1 -3 |  1
	 2  2  6 | -2
	-2 -2 -6 |  2
]

R1 := -R1
[
	 1  1  3 | -1
	 2  2  6 | -2
	-2 -2 -6 |  2
]

R2 := R2 - 2R1
[
	 1  1  3 | -1
	 0  0  0 |  0
	-2 -2 -6 |  2
]

R3 := R3 + 2R1
[
	 1 1 3 | -1
	 0 0 0 | 0
	 0 0 0 | 0
]

example:
[
	1 1 2 | 19
	3 1 2 | 31
]

R2 := R2 + (-3)R1
[
	1 1 2 | 19
	0 -2 -4 | -26
]

R2 := -1/2R2
[
	1 1 2 | 19
	0 1 2 | 13
]

R1 := R1 + (-1)R2
[
	1 0 0 | 6
	0 1 2 | 13
]

example:
{
	x + 3z = -2
	x + y = 0
}

[
	1 0 3 | -2
	1 1 0 | 0
]

R2 := R2 + (-1)R1
[
	1 0 3 | -2
	0 1 -3 | 2
]

x = -2 - 3z
y = 2 + 3z

For a consistent system:
consistent idependent: if the solution is unique
consistent dependent: if there are infinitely many solutions

example:
{
	-x + 2y = 6
	2x - 3y = 13
	5x - y = 45
}

[
	-1 2 | 6
	2 -3 | 13
	5 -1 | 45
]

R2 := R2 + 2R1
[
	-1 2 | 6
	0 1  | 25
	5 -1 | 45
]

R3 := R3 + 5R2
[
	-1 2 | 6
	0 1 | 25
	0 9 | 75
]

R3 := R3 + (-9)R2
[
	1 2 | 18
	0 1 | 25
	0 0  | -150
]
0x + 0y = -150 has no solution, the system is inconsistent

example:
{
	x - 3y + z = 0
	-4x + 6y = 2
}

[
	1 -3 1 | 0
	-4 6 0 | 2
]

R2 := R2 + 4R1
[
	1 -3 1 | 0
	0 -6 4 | 2
]
system is consistent dependent, has many solutions

example:
{
	3x + 4y = 12
	x + ky = 4
}

[
	3 4 | 12
	1 k | 4
]

R1 <-> R2
[
	1 k | 4
	3 4 | 12
]

R2 := R2 + (-3)R1
[
	1 k | 4
	0 4 - 3k | 0
]

= {
	x + ky = 4
	(4 - 3k)y = 0	
}
if k = 4/3 second equation is 0 = 0 for any value y we can remove this equation from the system so it becomes:
{
	x + ky = 4
}
dependent when k = 4/3

example:
{
	2x + 3y = 1
	6x + (k + 3)y = -5
}

[
	2 3 | 1
	6 (k + 3) | -5
]

R2 := R2 + (-3)R1
[
	2 3 | 1
	0 (k - 6) | -8
]

= {
	2x + 3y = 1
	(k - 6)y = -8
}
the system is inconsistent if no solutions (one equation must be false)
when k = 6 the second equation is 0 = -8, which is false (no solution)
inconsistent when k = 6

==================================================

To find inverse of matrix:
1) write down A and the I2 side-by-side
[A|I2]
= [
	1 2 | 1 0
	3 7 | 0 1
]
2) apply Gauss-Jordan method to transform matrix A into the identity matrix (same operation on both matrices)
[A|I2]
= [
	1 2 | 1 0
	3 7 | 0 1
]

R2 := R2 + (-3)R1
~ [
	1 2 | 1 0
	0 1 | -3 1
]

R1 := R1 + (-2)R2
~ [
	1 0 | 7 -2
	0 1 | -3 1
]

= [I|A^-1]

A^-1 = [
				 7 -2
				 -3 1
			 ]

We can prove AA^-1 =
[
	1 2
	3 7
] [
	7 -2
	-3 1
]
= [
	1 0
	0 1
]

example:
we are given R1 := R1 + (-1)R2 and R2 := R2 + (-2)R1

A = [5 1|4 1]
B = [-2 1|-1 1]
C = [3 1|2 1]

R1 := R1 + (-1)R2
C = [1 0|2 1]

R2 := R2 + (-2)R1
C = [1 0|0 1]

example:
[ 
	2 0 | 1 0
	4 1 | 0 1
]

R1 := 1/2R1
[ 
	1 0 | 1/2 0
	4 1 | 0   1
]

R2 := R2 + (-4)R1
[ 
	1 0 | 1/2 0
	0 1 | -2  1
]

example:
[
	1 0 | 1 0
	2 5 | 0 1
]

R2 := R2 + (-2)R1
[
	1 0 |  1 0
	0 5 | -2 1
]

R2 := 1/5R2
[
	1 0 |    1   0
	0 1 | -2/5 1/5
]

example:
[
	1 1 | 1 0
	2 3 | 0 1
]

R2 := R2 + (-2)R1
[
	1 1 | 1 0
	0 1 | -2 1
]

R1 := R1 + (-1)R2
[
	1 0 | 3 -1
	0 1 | -2 1
]

example:
[
	1 -2 | 1 0
	0  2 | 0 1
]

R2 := 1/2R2
[
	1 -2 | 1 0
	0  1 | 0 1/2
]

R1 := R1 + 2R2
[
	1  0 | 1 1
	0  1 | 0 1/2
]

example:
[
	1 0 4  | 1 0 0
	0 1 0  | 0 1 0
	0 0 -1 | 0 0 1
]

R3 := (-1)R3
[
	1 0 4 | 1 0 0
	0 1 0 | 0 1 0
	0 0 1 | 0 0 -1
]

R1 := R1 + (-4)R3
[
	1 0 0 | 1 0 4
	0 1 0 | 0 1 0
	0 0 1 | 0 0 -1
]
= [I|A^-1]

example:
[
	1 0 0 | 1 0 0
	0 0 1 | 0 1 0
	0 1 0 | 0 0 1
]

R2 <-> R3
[
	1 0 0 | 1 0 0
	0 1 0 | 0 0 1
	0 0 1 | 0 1 0
]

example:
[
	1 1 0
	4 1 1
	1 0 0
]

R1 := R1 + (-1)R2
[
	1 0 0
	2 1 0
	0 0 1
]

R2 := R2 + (-2)R1
[
	1 0 0 
	0 1 0
	0 0 1
]

example:
[
	1 0 0   | 1 0 0
	0 1 0   | 0 1 0
	0 -10 5 | 0 0 1
]

R3 := R3 + 10R2
[
	1 0 0 | 1 0 0
	0 1 0 | 0 1 0
	0 0 5 | 0 10 1
]

R3 := 1/5R3
[
	1 0 0 | 1 0 0
	0 1 0 | 0 1 0
	0 0 1 | 0 2 1/5
]

example:
[
	1 -3  3 | 1 0 0
	0  1  2 | 0 1 0
	0  0 -1 | 0 0 1
]

R1 := R1 + 3R2
[
	1  0  9 | 1 3 0
	0  1  2 | 0 1 0
	0  0 -1 | 0 0 1
]

R3 := (-1)R3
[
	1  0  9 | 1 3 0
	0  1  2 | 0 1 0
	0  0  1 | 0 0 -1
]

R1 := R1 + (-9)R3
[
	1  0  0 | 1 3 9
	0  1  2 | 0 1 0
	0  0  1 | 0 0 -1
]

R2 := R2 + (-2)R3
[
	1  0  0 | 1 3 9
	0  1  0 | 0 1 2
	0  0  1 | 0 0 -1
]

==================================================

A diagonal matrix is invertible if it has non-zero entries on its main diagonal:

[
	a11 0 ... 0
	 0 a22 ... 0
	 .  . .    .
	 .  .  .   .
	 .  .   .  .
	 0  0 ... anm
]^-1
=
[
	1/a11 0 ... 0
	 0 1/a22 ... 0
	 .  . .    .
	 .  .  .   .
	 .  .   .  .
	 0  0 ... 1/anm
]

If P is a permutation matrix, then its inverse is given by:
P^-1 = P^T
A permutation is an identity matrix with columns out of order
example:
[
	0 1 0 0
	0 0 1 0
	1 0 0 0
	0 0 0 1
]
A^-1 = [
	0 1 0 0
	0 0 1 0
	1 0 0 0
	0 0 0 1
]
A^T = [
	0 0 1 0
	1 0 0 0
	0 1 0 0
	0 0 0 1
]

==================================================

Atomic triangular matrix
(or Frobenius matrix):
* all entries on the main diagonal are 1s
* The matrix has only one column below main diagonal do not = 0
* all other entries outside the main diagonal = 0
[
	1 0 0 0
	3 1 0 0
	5 0 1 0
	7 0 0 1
]
If F os a Frobenius matrix its inverse is also a Frobenius matrix, the nonzero entries outside the main diagonal have opposite signs:
[
	1 0 0 0
	-3 1 0 0
	-5 0 1 0
	-7 0 0 1
]

Review:
A = [
	a11 a12
	a21 a22
]
invertible matrix theorem:
* A is invertible
* Ax = b has a exactly one solution for any 2x1 column vector b
* Ax = 0 has the unique zero solution
* The lines a11x+a12y = b and a21x+a22y = b2 intersect at 1 point
* det(A) != 0

==================================================

Affine transformation T: R^2 -> R^2 is a function that form represented by:
x = Au + b
x, u and b are column vectors in R^2 and A is 2x2 matrix
u = [u|v] input
x = [x|y] output
(a geometric transformation that preserves collinearity points, allows operations like shifting, skewing, and resizing object while maintaining its basic shape).

example:
T: [u|v] -> [
	u  - v + 1
  2u + v - 3
]
=
[
	u - v
	2u + v
] + [1|-3]
=
A = [
	1 -1
	2  1
] ⋅ u = [u|v] + b = [1|-3]

A linear transformation x = Au is a special case of an affine transformation with b = 0
For an affine transformation T given by x = Au + b, A is the matrix representation of the linear transformation associated with T

To find the image of a point under an affine transformation, substitute the position vector into the formula for the affine transformation

example:
x = 3u + v - 2
y = u - 2v + 1
P(3, 2)
[
	3u + v - 2
	u - 2v + 1
]
=
[
	3u + v
	u - 2v
] + [-2|1]
=
[
	3  1
	1  -2
] ⋅ [u|v] + [-2|1]

U = [3|2]
B = [-2|1]

AU + B = [
	3  1
	1  -2
] [3|2] + [-2|1]
= 
[
	3   1
	1  -2
] [
 3
 2
] + [-2|1]
= [
	9
	0
]

= P'(9, 0)

example:
x = v - 2u - 3
y = u + 2v - 1
what the line segment of P'Q'
P(-1, 1)
Q(2, -1)

= [
	v - 2u - 3
	u + 2v - 1
] = [
-2u + v
	u + 2v
] + [
	-3
	-1
]
=
[
 -2  1
	1  2
][
	-1  2
	 1 -1
]
(-2)(-1)+(1)(1) (-2)(2)+(1)(-1)
(1)(-1)+(2)(1) (1)(2)+(2)(-1)
= [
	 3 -5
	 1 0 
] + [
	-3 -3
	-1 -1
]
=
[
	0 -8
	0 -1
]
= P'(0,0)
= Q'(-8,-1)

An invertible affine transformation is orientation-preserving if it preserves the orientation of any polygon in the plane

We can identify whether an affine transformation is orientation-perserving or not by matrix A of the associated linear map:
T: R^2 -> R^2 is defined as
x = Au + b
where x, u and b are column vectors in R^2 and A is a 2x2 matrix then T preserves orientation if:
det(A) > 0
does not preserve:
det(A) < 0 (orientation-reversing)

example:
(triangle shape)
[
	1 -2
	1 1
] [
	0 1 0
	0 0 1 
]
(1)(0)+(-2)(0) (1)(1)+(-2)(0) (1)(0)+(-2)(1)
(1)(0)+(1)(0) (1)(1)+(1)(0) (1)(0)+(1)(1)
[
	0 1 -2
	0 1 1
] + [
	0  0  0
 -1 -1 -1
]
=
[
	0 1 -2
 -1 0  0
]

example:
(square shape)
x = u + v + 1
y = u - v

[
	1  1
	1 -1
] [
	0 1 1 0
	0 0 1 1
]
(1)(0)+(1)(0) (1)(1)+(1)(0) (1)(1)+(1)(1) (1)(0)+(1)(1)
(1)(0)+(-1)(0) (1)(1)+(-1)(0) (1)(1)+(-1)(1) (1)(0)+(-1)(1)
[
	0 1 2  1
	0 1 0 -1
] + [
	1 1 1 1 
	0 0 0 0
]
=
[
	1 2 3  2
	0 1 0 -1
]

The area scale factor of T is given by the determinant of A
We can identify whether an affine transformation increases or decreases the area of a polygon (P) by the area scale factor:
* if |det(A)| > 1 the image of P under the action T will have a larger area than P
* if |det(A)| = 1 the image of P under the action of T will have same area as P
* if 0 < |det(A)| < 1 the image of P under the action of T will have a smaller area than P

If det(A) = 0 the image of P is not a polygon

T: R^2 -> R^2 is an affine transformation. Inverse of T is T^-1 the transformation reverses T:

T^-1(T(u)) = T(T^-1(u)) = u

method to compute the inverse of an affine transformation:
Au + b = x
Au = x - b
A^-1 ⋅ Au = A^-1 ⋅ (x - b)
I2 ⋅ u = A^-1(x - b)
u = A^-1(x - b)

An affine transformation T is invertible iff A represents the linear transformation associated with T is invertible: det(A) != 0

example:
[
	2 1
	5 2
] + [
	2
	1
]
A^-1
= 1/(2)*2 - (5)*1
= 1/-1 [
	2 -1
	-5 2
] = [
	-2 1
	5 -2
] - [
	2
	1
]
(-2)(2)+(1)(1)
(5)(2)+(-2)(1)
(reverse signs since -)
= [
	3
	-8
]

example:
[
	7 -5
	-4 3
] + [
	4
	-3
]
A^-1
= 1/(7)*3 - (-5)-4
= 1/1 [
	3 5
	4 7
] - [
	 4
	-3
]
(3)(4)+(5)(-3)
(4)(4)+(7)(-3)
- [
	-3
  -5
]
since we need to add this to final results we must switch the signs:
+ [
	3
  5
]

example:
affine transformation T:
x = u + v, y = u + 2v + 1
given the inverse transformation T^-1 of T:
u = ax - y + 1, v = by - x + c
find a, b, c, and add a+b+c
A =
[
	1 1
	1 2
] + [
	0
	1
]
A^-1 =
1/1(2) - (1)(1)
1/1 [
	2 -1
	-1 1
][
 x - 0
 y - 1
]
= [
	2x + (-1) * (y - 1)
	-1x + 1 * (y - 1)
]
= [
	2x - y + 1
	y - x - 1
]
u = 2x - y + 1
v = 1y - x + (-1)
therefore: a+b+c = 2 + 1 + (-1) = 2

example:
x = 5v - 7u + 3
y = 7v - 10u + 5
[
	-7 5
	-10 7
]
A^-1 =
1/-7(7) - (-10)5
1/1 [
	7 -5
	10 -7
][
	x - 3
	y - 5	
]
= [
	7x * (x - 3) + (-5) * (y - 5)
	10x * (x - 3) + (-7) * (y - 5)
]
= [
	7x - 5y + 4
	10x - 7y + 5
]
u = 7x - 5y + 4
v = 10x + (-7)y + 5
a+b+c = 7+10+(-7) = 10

A is a 2x2 matrix, u and b are a 2x1 column vectors

* det(A) != 0 image of two dimensional object is a two dimensional object. Image of a polygon with n vertices

* det(A) = 0 then:
	* if A has at least one nonzero entry, it is a one dimensional line segment
	* if A is zero matrix, then the two dimensional space becomes a point.

==================================================

We can only compute sum, difference or dot product of two vectors have the same number of components:
[
	1
	2
	3
] + [
	-1
	5
] = undefined

Review:
(dot product)
u = [
	-1
	4
	3
	-5
]
v = [
	-2
	3
	-4
	6
]
u⋅v = (-1)(-2)+(4)(3)+(3)(-4)+(-5)(6)
= 2 + 12 - 12 - 30
= -28

finding an unknown quantity with the dot product:
a = [
	10
	x
	0
	5
]
b = [
	x
	x
	8
	5
]
a ⋅ b = 0 find value of x
stating from:
a ⋅ b = 0
10 * x + x * x + 0 * 8 + 5 * 5 = 0
10x + x^2 + 25 = 0
x^2 + 10x + 25 = 0
(x + 5)^2 = 0
x = -5

example:
u ⋅ v = 11 and x < 0
u=[
	4/x^2
	4
	x
	7
]
v=[
	x^4
	0
	8
	-7
]
4/x^2 * x^4 + 4 * 0 + x * 8 + 7 * -7 = 11
4x^2 + 8x - 49 = 11
4x^2 + 8x - 60 = 0
x^2 + 2x - 15 = 0
(x - 3)(x + 5) = 0
x = -5

example:
a ⋅ b = 8 
a = [
	5
	0
	p
	1
]
b = [
	p
	-3
	7
	-4
]
5*p + 0*-3 + 7*p + 1*-4
12p - 4 = 8
12p = 12
p = 1

Solve for one coefficient in a linear combination:
find s, if 3a1 + sa2 = b
3[
	-1
	2
	1
] + s[
	4
	0
	-2
] = [
	13
	6
	-5	
]
(switch the 3a1 to other side to solve for s)
s[
	4
	0
	-2
] = [
	13
	6
	-5	
] - 3[
	-1
	2
	1
]
s[
	4
	0
	-2
] = [
	16
	0
	-8
]
s = 4 (multiple of 4)

example:
(find scalar l)
l[
	0
	5
	-2
	8
] = [
	45
	-20
	4
	19
] - 5[
	9
	-2
	0
	7
]
l[
  0
	5
	-2
	8
] = [
	0
	-10
	4
	-16
]
s = -2 (multiple of -2)

example:
find x1 + x2 given 2a - 6x = b
a = [
 -2
	5
	1
	3
]
x = [
	x1
	x2
	x3
	x4
]
b = [
	8
	4
	-22
	-6
]
2a - 6x = b
x = -1/6(b - 2a)
([
	8
	4
	-22
	-6
] - 2 [
	-2
	5
	1
	3
])
x = -1/6[
	12
	-6
	-24
	0
]
=
[
	-2
	1
	4
	0
]

solving for two coefficients in a linear combination:
c1 = [
	4
	-1
	3
]
c2 = [
	1
	0
	1
]
d = [
	5
	-5
	0
]
if x1c1+x2c2 = d what is x1+x2
x1 [
	4
	-1
	3
] + [
  1
	0
	1
] = [
	5
	-5
	0
]
[
	4x1 + x2
	   -x1
	3x1 + x2
] = [
	5
	-5
	0
]
{
	4x1 + x2 = 5
	-x1 = -5
	3x1 + x2 = 0
}
x1 = 5 lets substitute:
4(5) + x2 = 5
x2 = -15
x1 = 5, x2 = -15 lets substitute:
3(5) + (-15) = 0
0 = 0
final solution:
x1 + x2 = 5 - 15 = -10

Solving for three coefficients:
x1[
 0
 1
 0
] + x2[
	1
	0
	-1
] + x3[
	1
	2
	3
] = [
	1
	1
	7
]
{
	x2 + x3 = 1
	x1 + 2x3 = 1
	-x2 + 3x3 = 7
}
solve using Gaussian elimination:
[
	0  1 1 | 1
	1  0 2 | 1
	0 -1 3 | 7
]
row reducing:
R1 <-> R2
[
	1  0 2 | 1
	0  1 1 | 1
	0 -1 3 | 7
]
R3 := R3 + R2
[
	1 0 2 | 1
	0 1 1 | 1
	0 0 4 | 8
]
R3 := 1/4R3
[
	1 0 2 | 1
	0 1 1 | 1
	0 0 1 | 2
]
system becomes:
{
	x1 + 2x3 = 1
	x2 + x3 = 1
	x3 = 2
}
substitute:
x2 + (2) = 1
x2 = -1
substitute:
x1 + 2(2) = 1
x1 = -3
x1+x2+x3 = -3 - 1 + 2 = -2

example:
x1[
	1
	2
	3
] + x2[
	2
	5
	6
] + x3[
	3
	2
	9
] = [
	-2
	-6
	7
]
{
	x1 + 2x2 + 3x3 = -2
	2x1 + 5x2  + 2x3 = -6
	3x1 + 6x2 + 9x3 = 7
}
[
	1 2 3 | -2
	2 5 2 | -6
	3 6 9 | 7
]
R2 := R2 + (-2)R1
[
	1 2 3  | -2
	0 1 -4 | -2
	3 6 9  | 7
]
R2 := R2 + (-2)R1
[
	1 2 3  | -2
	0 1 -4 | -2
	3 6 9  | 7
]
R3 := R3 + (-3)R1
[
	1 2 3  | -2
	0 1 -4 | -2
	0 0 0  | 13
]
{
	x1 + 2x2 + 3x3 = -2
	x2 - 4x3 = -2
	0 = 13
}
= no solution

example:
(supressing the vectors to save space)
{
	x1 - x2 + 2x3 = 2
  x2 = 3
  x1 + x2 + 5x3 = -1
}
[
	1 -1 2 | 2
	0  1 0 | 3
	1  1 5 | -1
]
R3 := R3 + (-1)R1
[
	1 -1 2 | 2
	0  1 0 | 3
	0  2 3 | -3
]
R3 := R3 - 2R2
[
	1 -1 2 | 2
	0  1 0 | 3
	0  0 3 | -9
]
R3 := 1/3R3
[
	1 -1 2 | 2
	0  1 0 | 3
	0  0 1 | -3
]
{
	x1 - x2 + 2x3 = 2
	x2 = 3
	x3 = -3
}
substitute:
x1 - 3 + 2(-3) = 2
x1 = 11
x1+x2+x3 = 11+3-3=11

example:
[
	 1  2 | -1
	-4 -3 | -6
	-7 -5 | -11
]
R2 := R2 + 4(R1)
[
	 1  2 | -1
	 0  5 | -10
	-7 -5 | -11
]
R3 := R3 + 7R1
[
	 1  2 | -1
	 0  5 | -10
	 0  9 | -18
]
R2 := 1/5R2
[
	 1  2 | -1
	 0  1 | -2
	 0  9 | -18
]
R3 := R3 - 9R2
[
	 1  2 | -1
	 0  1 | -2
	 0  0 | 0
]
{
	x1 + 2x2 = -1
	x2 = -2
	0 = 0
}
x1 + 2(-2) = -1
x1 = 3
x2 = -2
3 * (-2) = -6

example:
[
	-3 1 | -5
	-3 1 | 7
]

R2 := R2 - R1
[
	-3 1 | -5
	 0 0 | 12
] = b != Span{a1, a2}


example:
[
	2 1 | -1
	-1 1 | -7
	4 1 | k
]

R1 := R1 + R2
[
	1 2 | -8
	-1 1 | -7
	4 1 | k
]

R2 := R2 + R1
[
	1 2 | -8
	0 3 | -15
	4 1 | k
]

R3 := R3 + (-4)R1
[
	1 2 | -8
	0 3 | -15
	0 -7 | k + 32
]

R2 := 1/3R2
[
	1 2 | -8
	0 1 | -5
	0 -7 | k + 32
]

R3 := R3 + (7)R2
[
	1 2 | -8
	0 1 | -5
	0 0 | k - 3
]
k = 3

example:
[
	-3  9 | -12
	-2  7 | -10
	-6 18 | k
]
R1 := -1/3R1
[
	1  -3 | 4
	-2  7 | -10
	-6 18 | k
]
R2 := R2 + (2)R1
[
	1  -3 | 4
	0  1  | -30
	-6 18 | k
]
R3 := R3 + (6)R1
[
	1  -3 | 4
	0  1  | -30
	0  0  | k + 24
]
k = -24

example:
[
	-1  1 | 1
	 3 -5 | -8
	 5 -7 | -10
]
R2 := R2 + (3)R1
[
	-1  1 | 1
	 0 -2 | -5
	 5 -7 | -10
]

R3 := R3 + (5)R1
[
	-1  1 | 1
	 0 -2 | -5
	 0 -2 | -5
]
R3 := R3 - R2
[
	-1  1 | 1
	 0 -2 | -5
	 0 0 | 0
]
{
	-s + t = 1
	-2t = -5
}
-2t = -5
t = 5/2
-s = 2/2 - 5/2 = -3/2
s = 3/2
s*t = 15/4

[
	1 -1 | -3
	5 -1 | 5
	8 -3 | -7
]
R2 := R2 + (-5)R1
[
	1 -1 | -3
	0  4 | 20
	8 -3 | -7
]
R3 := R3 + (-8)R1
[
	1 -1 | -3
	0  4 | 20
	0  5 | 17
]
R3 := R3 + (5)R1
[
	1 -1 | -3
	0  4 | 20
	0  0 | 2
]

==================================================

v1 and v2 is linearly independent:
x1v1 + x2v2 = 0 otherwise any other solution is linearly dependent

lineraly independent (if we set x1 and x2 = 0):
x1 [
	1
	0
] + x2 [
	0
	1
] = 0

linearly dependent (we can set x1 = x2 = 0 but we can also set x1 = 2 and x1 = 1)
x1 [
	1
	1
] + x2 [
	-2
	-2
] = 0

A set of two vectors that are parllel (vectors that are multiples of each other) are lineraly dependent

A set of two vectors that are not parllel are lineraly independent

The zero vector is parllel to every other vector because it is a multiple of any other vector:
0 = 0 * v => 0 || v (lineraly dependent)

example:
[
	1 -2 2 | 0
	2 3  1 | 0
	0 7 -3 | 0
]
R2 := R2 + (-2)R1
[
	1 -2 2 | 0
	0 7 -3 | 0
	0 7 -3 | 0
]
R3 := R3 - R2
[
	1 -2 2 | 0
	0 7 -3 | 0
	0 0  0 | 0
]
x3 is the free variable
x1a1+x2a2+x3a3 = 0 has infinite number of nonzero solutions which means that the vectors are linearly dependent

==================================================

H ⊆ R^n is a subspace of R^n if it satisfies:

* Closure under vector addition:
	if u and v are in H, their sum u+v is also in H
* Closure under scalar multiplication:
	if u is in H, c*u is also in H for any scalar number c

if a set does not contain the zero vector then the set is not closed under scalar multiplication

example:
let L be the line with equation x = 2y in R^2
[
	2y
	y
]
L contains the zero vector:
(0) = 2(0)
0 = 0
L is closed under vector addition:
a = [
	2a
	a
]
b = [
	2b
	b
] = [
	2(a + b)
	 a + b
]
which satisfies x = 2y, a+b in L
L is closed under scalar multiplication:
k*a
a = [
	2a
	a
] * k
= [
	2ka
	ka
]
L is a subspace of R^2

three dimentional space:
L be the line in R^3 passes through the points (1, 2, 2) and (2, 1, 1)

the direction vector of the L is:
d = [
	2
	1
	1
] - [
	1
	2
	2
] = [
	1
	-1
	-1
]
This means the vector equation of the line is
r = [
	1
	2
	2
] + t[
	1
 -1
 -1
]
The Cartesian equation is
x - 1 = (y - 2)/-1 = (z - 2)/-1
but this line does not pass through origin:

(0) - 1 != ((0) - 2)/-1 = ((0) - 2)/-1
L does not contain the zero-vector

L is not closed under vector addition:
lets consider the vectors:
[
	1
	2
	2
]
and
[
	2
	1
	1
]
=
[
	3
	3
	3
]
the point (3,3,3) does not belong to L since:
(3) - 1 != ((3) - 2)/-1 = ((3) - 2)/-1

L is not closed under scalar multiplication
since 0 in not in L
L is not a subspace of R^3
direction:
d = [
	1
 -1
	1
] - [
	0
	0
	0
] = [
	1
	-1
	1
]
vector equation:
r = [
	0
	0
	0
] + t[
	1
	-1
	1
] = [
	t
	-t
	t
]
cartesian equation:
x = -y = z
zero-vector, closed under vector addition and scalar multiplication

A plane is a subspace of three-dimensional space?
example:
x + 4y - 3z = 2 in R^3:
[
	2 - 4y + 3z
	    y
	    z
]
does not pass through origin (zero-vector):
(0) + 4(0) - 3(0) = 2
0 != 2

is not closed under vector addition:
a = [
	2
	0
	0
]
b = [
	1
	1
	1
] = [
	3
	1
	1
]
(3) + 4(1) - 3(1) = 2
4 != 2

is not closed under scalar multiplication 0 is not in the set
[
	x
	y
 x-y
]

==================================================

The only non-trivial subspaces in R^2 are straight lines that pass through the origin.

every subspace must contain the origin

The only non-trivial subspaces in R^3 are straight lines or planes that pass through the origin

R which belongs to the family of vector spaces R^n (when n = 1). This vector space has only two subspaces:
The zero subspace {0}. which contains only the number 0
The whole space R, contains all real numbers

==================================================

Is b in Col(B). What are the values of x1 and x2 where x1 and x2 are real numbers sub that b = x1b1 + x2b2 and b1, b2 are the respective columns of B
B = [
	5  -2
	15 -6
	0   1
]
b = [
	7
	21
	0
]
in order to determine whether b lies in Col(B) we need to check if the equation Bx = b is consistent:
[
	5  -2 | 7
	15 -6 | 21
	0   1 | 0
]
R2 := R2 - 3R1
[
	5  -2 | 7
	0   0 | 0
	0   1 | 0
]
R2 <-> R3
[
	5  -2 | 7
	0   1 | 0
	0   0 | 0
]
{
	5x1 - 2x2 = 7
	x2 = 0
	0 = 0
} = {
	5x1 - 2x2 = 7
	x2 = 0
}
x1 = 7/5
one way to write b as a linear combination of b1 and b2
[
	7
	21
	0
] = 7/5[
	5
	15
	0
] + 0[
	-2
	-6
	1
]

determine if the value of an unknown given a vector thats in the column space:
A = [
	1 2
	3 -2
	5 -1
]
b = [
	10
	-2
 2 + k
] (belongs to Col(A))
Ax = b must be consistant
[
	1  2 | 10
	3 -2 | -2
	5 -1 | 2 + k
]
R2 := R2 - 3R1
[
	1  2 | 10
	0 -8 | -32
	5 -1 | 2 + k
]
R3 := R2 - 5R1
[
	1  2 | 10
	0 -8 | -32
	0 -11 | k - 48
]
R2 := 1/8R2
[
	1  2 | 10
	0  1 | 4
	0 -11 | k - 48
]
R3 := R3 + 11R2
[
	1  2 | 10
	0  1 | 4
	0  0 | k - 4
]
= {
	x1 + 2x2 = 10
	x2 = 4
	0 = k - 4
}
k = 4

example:
[
	3 8 | 14
	-2 -11 | -15
	1 6 | k + 5
]
R1 <-> R3
[
	1 6 | k + 5
	-2 -11 | -15
	3 8 | 14
]
R2 := R2 + (2)R1
[
	1 6 | k + 5
	0 1 | 2k - 5
	3 8 | 14
]
R3 := R3 - (3)R1
[
	1 6 | k + 5
	0 1 | 2k - 5
	0 -10 | -3k - 1
]
R3 := R3 + (10)R2
[
	1 6 | k + 5
	0 1 | 2k - 5
	0 0 | 17k - 51
]
= {
	x1 + 6x2 = k+5
	x2 = 2k - 5
	0 = 17k - 51
}
k = 3

example:
[
	1 -2 | 1
	2 -2 | 3
	5 -8 | k
]
R2 := R2 + (-2)R1
[
	1 -2 | 1
	0  2 | 1
	5 -8 | k
]
R3 := R3 + (-5)R1
[
	1 -2 | 1
	0  2 | 1
	0  2 | k - 5
]
R3 := R3 - R2
[
	1 -2 | 1
	0  2 | 1
	0  0 | k - 6
]
k = 6

larger matrices is b in Col(E):
E = [
	1 -4  7  1 | 2
	4 -16 28 4 | 7
	1 -3  0 -1 | 0
]
R2 := R2 + (-4)R1
[
	1 -4  7  1 | 2
	0  0  0  0 | -1
	1 -3  0 -1 | 0
] = system is inconsisten b is not in Col(E)

example:
[
	1 -1 3 | 2
	2  0 4 | -1
	1 -3 0 | 7
]
R2 := R2 + (-2)R1
[
	1 -1 3 | 2
	0  2 -2 | -5
	1 -3 0 | 7
]
R3 := R3 - R1
[
	1 -1 3 | 2
	0  2 -2 | -5
	0 -2 -3 | 5
]
R3 := R3 + R2
[
	1 -1 3 | 2
	0 2 -2 | -5
	0 0 -5 | 0
]
= {
	x1 - x2 + 3x3 = 2
	2x2 - 2x3 = -5
	-5x3 = 0
}
x3 = 0
2x2 - 2(0) = -5
x2 = -5/2
2 + (-5/2) - 3(0)
x1 = -1/2

==================================================

null space of a matrix A is the equation Ax = 0 and the proper syntax: Null(A)

example:
[
	3  -6
	-5 10
	-8 16
][
	6
	3
]
(3)(6)+(-6)(3)
(-5)(6)+(10)(3)
(-8)(6)+(16)(3)
= [
	0
	0
	0
]
example:
[
	2 4
	4 8
	1 2
][
	-8
	4
]
(2)(-8)+(4)(4)
(4)(-8)+(8)(4)
(1)(-8)+(2)(4)
[
	2 4
	4 8
	1 2
][
	4
	-2
]
(2)(4)+(4)(-2)
(4)(4)+(8)(-2)
(1)(4)+(2)(-2)
[
	2 4
	4 8
	1 2
][
	-4
	3
]
(first two NULL(A))

example:
[
	2 -4
	1  5
][
	2
 -3
]
(2)(2)+(-4)(-3)
[
	2 -4
	1  5
][
	5
 -1
]
(2)(5)+(-4)(-1)
[
	2 -4
	1  5
][
 -3
  1
]
(2)(-3)+(-4)(1)
None are NULL just by examining first entry

find a variable in a NULL space:
[
	3 2 -4
	-3 3 -1
	6 -6 2
][
	2
	k
	3
] = [
	0
	0
	0
]
[
	6 + 2k - 12
	-6 + 3k - 3
	12 - 6k + 6
] = [
	0
	0
	0
] 
= {
	2k - 6 = 0
	3k - 9 = 0
	-6k + 18 = 0
}
k = 3

example:
[
	3  -1
	-12 4
	9  -3
][
	k
 -6
]
= {
	3k + 6 = 0
	-12k - 24 = 0
	9k + 18 = 0
}
k = -2

example:
[
	0 3 -15
	-1 1 -3
][
	2
	k
	1
]
= {
	3k - 15 = 0
	k - 5 = 0
}
k = 5

using set builder notation:
A = [
	-1 3 -2
	5 -15 10
	2 -6 4
]

R1 := R1 + R3
[
	1 -3 2
	5 -15 10
	2 -6 4
]
R2 := R2 + (-5)R1
[
	1 -3 2
	0 0 0
	2 -6 4
]
R3 := R3 + (-2)R1
[
	1 -3 2
	0 0 0
	0 0 0
]
= {
	x1 - 3x2 + 2x3 = 0
}
x1 = 3x2 - 2x3
= {[
	3x2 - 2x3
	    x2
	    x3
] : x2,x3 in R}


[
	3 6
	6 12
]
R1 := 1/3R1 
[
	1 2
	6 12
]
R2 := R2 + (-6)R1
[
	1 2
	0 0
]
= {
	x1 + 2x2 = 0
}
x1 = -2x2
= {[
	-2x2
	 x2
]: x2 in R}

==================================================

finding a basis of a space spanned by a set of vectors:
a1 = [2|3]
a2 = [3|4]
a3 = [1|1]
S = Span{a1, a2, a3}

the basis of S is a set of lineraly independent vectors that spans S
a2 is a linear combination of vectors a1 and a3
a2 = 1*a1 + 1*a3

Vector a2 can be removed from Span{a1,a2,a3} without chaing the span therefor basis of S is {a1,a3}
B = {
	[2|3],
	[1|1]
}

example:
a1 = [3|1]
a2 = [2|2]
a3 = [1|-1]
a1 is a linear combination
a1 = 1*a2 + 1*a3
S = Span{a1,a2,a3} is {a2,a3}
B = {[2|2], [1|-1]}

example:
a1 = [2|0]
a2 = [1|3]
a3 = [3|3]
a3 is a linear combination
a3 = 1*a1 + 1*a2
S = Span{a1,a2,a3} is {a1,a2}
B = {[2|0], [1|3]}

You can also find a subset of linearly independent vectors and compute RREF

The pivot columns are linearly independent vectors and the non-pivots correspond to linear dependent (or redundant) vectors that can be removed.

Pick the columns from origin matrix not from the reduced one.
example:
a1 = [5|2]
a2 = [10|4]
a3 = [15|5]
[
	5 10 15
	2 4 5
]
R1 := 1/5R1
[
	1 2 3
	2 4 5
]
R2 := R2 + (-2)R1
[
	1 2 3
	0 0 -1
]
(1st and 3rd column pivot, 2nd non-pivot)
therefore:
B = {[5|2], [15|5]}

Determining whether a given set is a basis of a span:
a1 = [
	1
	-1
	-3
]
a2 = [
	0
	1
	0
]
a3 = [
	1
	-1
	-2
]
a4 = [
	2
	-2
	1
]
= {
	x1 + x3 = 2
	-x1 + x2 - x3 = -2
	-3x1 -2x3 = 1
}
We must use RREF (1's for pivots and 0's below and above pivot points), not just REF
[
	 1 0  1 | 2
	-1 1 -1 | -2
	-3 0 -2 | 1
]
R2 := R2 + R1
[
	 1 0  1 | 2
	 0 1  0 | 0
	-3 0 -2 | 1
]
R3 := R3 + 3R1
[
	 1 0  1 | 2
	 0 1  0 | 0
	 0 0  1 | 7
]
R1 := R1 + (-1)R3
[
	 1 0  0 | -5
	 0 1  0 | 0
	 0 0  1 | 7
]
B is indeed a basis of Span{a1,a2,a3,a4}, x1 = 5, x2 = 0 and x3 = 7
= -5[
	1
	-1
	-3
] + 0[
	0
	1
	0
] + 7[
	1
	-1
	-2
] = [
	2
	-2
	1
]
x1+x2+x3 = -5+0+7 = 2

example:
[
	1 -1 1  | -1
	-2 3 -2 | 2
	5 -5 6  | 2
]
R2 := R2 + (2)R1
[
	1 -1 1  | -1
	0 1  0  | 0
	5 -5 6  | 2
]
R3 := R3 + (-5)R1
[
	1 -1 1  | -1
	0  1 0  | 0
	0  0 1  | 7
]
R1 := R1 - R2 | OR (R1 + (-1)R3)
[
	1  0 1  | -1
	0  1 0  | 0
	0  0 1  | 7
]
R1 := R1 - R3 | OR (R1 + R2 from previous)
[
	1  0 0  | -8
	0  1 0  | 0
	0  0 1  | 7
]
x1+x2+x3 = -8 + 0 + 7 = -1

[
	1 -1 | 2
	-2 4 | -2
]
R2 := R2 + (2)R1
[
	1 -1 | 2
	0 2 | 2
]
R2 := 1/2R2
[
	1 -1 | 2
	0 1 | 1
]
R1 := R1 + R2
[
	1 0 | 3
	0 1 | 1
]
= 3[
	1
	-2
] + 1[
	-1
	4
] = [
	2
	-2
]
x1*x2 = 3

example:
[
	2 -6 0
	1 -1 1
	3 1 5
]
R1 <-> R2
[
	1 -1 1
	2 -6 0
	3 1 5
]
R2 := R2 + (-2)R1
[
	1 -1 1
	0 -4 -2
	3 1 5
]
R3 := R3 + (-3)R1
[
	1 -1 1
	0 -4 -2
	0 4 2
]
R3 := R3 + R2
[
	1 -1 1
	0 -4 -2
	0 0 0
]
OR (REF)
R2 := R2 + (-1/2)R1
[
	2 -6 0
	0 2 1
	3 1 5
]
R3 := R3 + (-3/2)R1
[
	2 -6 0
	0 2 1
	0 10 5
]
R3 := R3 + (-5)R2
[
	2 -6 0
	0 2 1
	0 0 0
]
columns 1,2 pivots therefore:
B = {
	[
		2
		1
		3
	],
	[
		-6
		-1
		1
	]
}

example:
[
	0 0 0
	0 0 3
	1 0 2
]
R1 <-> R3
[
	1 0 2
	0 0 0
	0 0 3
]
B = {
	[
		0
		0
		1
	],
	[
		0
		3
		2
	]
}

find linear combination:
[
	1 3 4
	-2 -6 5
]
R2 := R2 + (2)R1
[
	1 3 4
	0 0 13
]
R2 := 1/13R2
[
	1 3 4
	0 0 1
]
R1 := R1 + (-4)R2
[
	1 3 0
	0 0 1
]
basis of Col(A) is {a1,a2}
B = {
	[
		1
		-2
	],
	[
		4
		5
	]
}
Since 2nd is non pivot this tells us that a2 is a linear combination of all other columns in original matrix:
[
	3
	-6
] = 3[
	1
	-2
] + 0[
	4
	5
]
x1*x3 = 3 * 0 = 3

example:
[
	1 0 -1
	0 -2 -6
]
R2 := -1/2R2
[
	1 0 -1
	0 1 3
]
column 3 is non-pivot

[
	1 0 2 1
	0 5 10 5
	1 0 2 2
]

R3 := R3 - R1
[
	1 0 2 1
	0 5 10 5
	0 0 0 1
]
R2 := 1/5R2
[
	1 0 2 1
	0 1 2 1
	0 0 0 1
]
Col(A) is {a1,a2,a4}
B = {a1,a2} is not a basis of Col(A)

[
	1 2 -1 0
	0 4 -4 4
	3 5 -2 -1
]
R3 := R3 + (-3)R1
[
	1 2 -1 0
	0 4 -4 4
	0 -1 1 -1
]
R2 := 1/4R2
[
	1 2 -1 0
	0 1 -1 1
	0 -1 1 -1
]
R1 := R1 + (-2)R2
[
	1 0  1 -2
	0 1 -1 1
	0 -1 1 -1
]
R3 := R3 + R2
[
	1 0  1 -2
	0 1 -1 1
	0 0 0  0
]
OR we can reverse the last two steps above.
Col(A) is {a1,a2}
B = {
	[
		1
		0
		3
	],
	[
		2
		4
		5
	]
}
therefore we can use the 4th column as a linear combination of all other columns:
[
	0
	4
	-1
] = -2[
	1
	0
	3
] + 1[
	2
	4
	5
]

example of finding a basis of Null(A)
[
	1 0 1 0
	0 1 0 1
	0 0 0 0
]
{
	x1 + x3 = 0
	x2 + x4 = 0
}
x1 = -x3, x2 = -x4
[
	x1
	x2
	x3
	x4
] = [
	-x3
	-x4
	x3
	x4
]
resulting in:
= x3[
 -1
	0
	1
	0
] + x4[
	0
	-1
	0
	1
]

example (finding basis of Null(A))
[
	1 0 1
	0 1 0
	0 0 0
]
= {
	x1 = -x3
	x2 = 0
}
x3[
	-1
	0
	1
]
x3 is the only free variable

give the matrix A find a basis of Null(A) (RREF)
A = [
	1 -2 -1
	0  0  5
	5 -10 7
]
R3 := R3 + (-5)R1
[
	1 -2 -1
	0  0  5
	0  0 12
]
R3 := R3 + (-12)R2
[
	1 -2 -1
	0  0  1
	0  0  0
]
R1 := R1 + R2
[
	1 -2  0
	0  0  1
	0  0  0
]
{
	x1 - 2x2 = 0
	x3 = 0
}
x1 = 2x2, x3 = 0
x2 is the free variable
x2 [
	2
	1
	0
]

example:
A = [
	1 -2 8
	0 -4 10
	-2 0 -6
]
R3 := R3 + (2)R1
[
	1 -2 8
	0 -4 10
	0 -4 10
]
R3 := R3 + (-1)R2
[
	1 -2 8
	0 -4 10
	0 0 0
]
R2 := -1/4R2
[
	1 -2 8
	0 1 -5/2
	0 0 0
]
R1 := R1 + 2R2
[
	1 0 8
	0 1 -5/2
	0 0 0
]
= {
	x1 + 3x3 = 0
	x2 - 5/2x3 = 0
}
x1 = -3x2, x2 = 5/2x3
x3 is a free variable
[
	-3x3
	5/2x3
	x3
] = x3[
	-3
	5/2
	1
]

finding coordinates of vector x relative to basis B = {b1,b2}
[
	1 -3  | 10
	4 -10 | 8
	-2 6  | -20
]
R2 := R2 + (-4)R1
[
	1 -3 | 10
	0  2 | -32
	-2 6 | -20
]

R3 := R3 + (2)R1
[
	1 -3 | 10
	0  2 | -32
	0  0 | 0
]
{
	x1 + 48 = 10
	2x2 = -32
}
x2 = -16
x1 = -38
[x]_B = [-38|-16]

example:
[
	1 2 | 2
	-2 1 | 6
]
R2 := R2 + (2)R1
[
	1 2 | 2
	0 5 | 10
]
R2 := 1/5R2
[
	1 2 | 2
	0 1 | 2
]
= {
	x1 + 4 = 2
	x2 = 2
}
x1 = -2
x2 = 2
[x]_B = [-2|2]

solving with more than two vectors:
[
	1  2  0 | 2
	-1 0  0 | 2
	2  0 -1 | -5
	0  4  0 | 4
]
R2 := R2 + R1
[
	1  2  0 | 2
	0  2  0 | 4
	2  0 -1 | -5
	0  4  0 | 4
]
R3 := R3 + (-2)R1
[
	1  2  0 | 2
	0  2  0 | 4
	0  -4 -1 | -9
	0  4  0 | 4
]
R3 := R3 + 2R2
[
	1  2  0 | 2
	0  2  0 | 4
	0  0 -1 | -1
	0  4  0 | 4
]
R4 := R4 + (-2)R2
[
	1  2  0 | 2
	0  2  0 | 4
	0  0 -1 | -1
	0  0  0 | -4
]
= {
	x1 + 2x2 = 2
	2x2 = 4
	-x3 = -1
	0 = 4
}
column 4 is always false, no solutions

[
	1 2 0  | 5
	-2 1 0 | 10
	4 -2 3 | -17
]
R2 := R2 + (2)R1
[
	1 2 0  | 5
	0 5 0 | 20
	4 -2 3 | -17
]
R3 := R3 + (-4)R1
[
	1 2 0  | 5
	0 5 0 | 20
	0 -10 3 | -37
]
R2 := 1/5R2
[
	1 2 0  | 5
	0 1 0 | 4
	0 -10 3 | -37
]
R3 := R3 + (10)R2
[
	1 2 0 | 5
	0 1 0 | 4
	0 0 3 | 3
]
= {
	x1 + 8 = 5
	x2 = 4
	3x3 = 3
}
x3 = 1
x2 = 4
x1 = -3
[x]_B = [
	-3
	4
	1
]

R^2 and R^3 have special notations for the vectors of standard basis:
R^2 : {
	[
		1
		0
	],
	[
		0
		1
	]
}
R^3 : {
	[
		1
		0
		0
	],
	[
		0
		1
		0
	],
	[
		0
		0
		1
	]
}

In general the standard basis of R^n is:
{
	[
		1
		0
		0
		.
		.
		.
		0
	],
	[
		0
		1
		0
		.
		.
		.
		0
	],
	...
	[
		0
		0
		0
		.
		.
		.
		1
	],
}

==================================================

Writting a two-dimensional vector in a different basis:
Let B = {b1,b2} be a basis of R^2 and [x]_B = [5|-2] the coordinates of x relative to the basis C = {c1,c2} where c1 = -b2 and c2 = 3b1:

x = 5b1 - 2b2
= -2b2 + 5b1
= 2(-b2) - 5/3(-3b1)
= 2c1 - 5/3c2
therefore: [x]_c = [2|-5/3]

example:
[x]_b = [3|-7] basis C = {c1,c2} c1 = 5b2 and c2 = 4b1 

x = 3b1 - 7b2
= -7/5(5b2) + 3/4(4b1)
= -7/5c1 + 3/4c2
therefore: [x]_c = [-7/5|3/4]
* Remember when substituting make sure they equal to the original values

example:
[x]_c = [1|-2] basis B = {b1,b2} b1 = -c2 and b2 = 3c1
(swapped c and b from last example, doesn't matter)

x = c1 - 2c2
= -2c2 + c1
= 2(-c2) + 1/3(3c1)
= 2b1 + 1/3b2
[x]_B = [2|1/3]

example:
(three dimensions)
[x]_B = [-2|-3|5] basis C = {c1,c2,c3} c1 = -3b2, c2 = -b3, and c3 = -4b1

x = -2b1 - 3b2 + 5b3
= -3b2 + 5b3 - 2b1
= (-3b2) - 5(-b3) + 1/2(-4b1)
= c1 - 5c2 + 1/2c3
[x]_c = [
	1
	-5
	1/2
]

example:
[x]_B = [-3|4|-6] basis C = {c1,c2,c3} c1 = 3b2 c2 = -b3 c3 = 4b1

x = -3b1 + 4b2 - 6b3
= 4b2 - 6b3 - 3b1
= 4/3(3b2) + 6(-b3) - 3/4(4b1)
= 4/3c1 + 6c2 - 3/4c3
[x]_c = [
	4/3
	6
	-3/4
]

example:
[x]_B = [4|-5|2] basis C = {c1,c2,c3} c1 = -2b2 c2 = b3 c3 = -3b1

x = 4b1 - 5b2 + 2b3
= -5b2 + 2b3 + 4b1
= 5/2(-2b2) + 2(b3) - 4/3(-3b1)
[x]_c = [
	5/2
	2
	-4/3
]

writting a vector in a different basis given a linear relationship between two bases:
[x]_B = [5|-2] basis C = {c1,c2} b1 = 2c1 - c2 b2 = c1 + c2

x = 5b1 - 2b2
= 5(2c1 - c2) - 2(c1 + c2)
= 10c1 - 5c2 - 2c1 - 2c2
= 8c1 - 7c2
[x]_c = [8|-7]


example:
[x]_B = [1|-3] basis C = {c1,c2} c1 = b2 - b1 c2 = 2b1 - 3b2

{
	c1 = b2 - b1
	c2 = 2b1 - 3b2
}

b's in terms of c's multiply first equation by 2 and add equations:

2c1 + c2 = -b2   =>   b2 = -2c1 - c2

substituting into first equation:
c1 = (-2c1 - c2) - b1   =>   b1 = -3c1 - c2

x = b1 - 3b2
= (-3c1 - c2) - 3(-2c1 - c2)
= -3c1 - c2 + 6c1 + 3c2
= 3c1 + 2c2
[x]_c = [3|2]

example:
[x]_B = [2|-3] basis C = {c1,c2} c1 = b1 - 2b2, c2 = b1 + b2

{
	c1 = b1 - 2b2
	c2 = b1 + b2
}

multiply second equation by 2 add the equations:

c1 + 2c2 = 3b1   =>   b1 = 1/3c1 + 2/3c2

substitute into first equation:

c1 = (1/3c1 + 2/3c2) - 2b2   =>   b2 = -1/3c1 + 1/3c2

x = 2(1/3c1 + 4/3c2) - 3(-1/3c1 + 1/3c2)
= 2/3c1 + 4/3c2 + c1 - c2
= 5/3c1 + 1/3c2
[x]_c = [5/3|1/3]

example:
[x]_B = [-3|4] basis C = {c1,c2} c1 = b1 + b2, c2 = -b1

{
	c1 = b1 + b2
	c2 = -b1
}

b1 = -c2 (from second equation)
c1 = (-c2) + b2   =>   b2 = c1 + c2 (substitution)

x = -3b1 + 4b2
= -3(-c2) + 4(c1 + c2)
= 3c2 + 4c1 + 4c2
= 4c1 + 7c2
[x]_c = [4|7]

==================================================

The change-of-coordinates matrix allows us to express the vector [x]_B in the basis C via transformation:
[x]_c = P_B->c * [x]_B

B = {b1,b2} and C = {c1,c2} bases of R^2 c1 = b2 - 4b1 c2 = 5b1 + 7b2
[c1]_B = [-4|1], [c2]_B = [5|7]
P_c->B = [
	-4 5
	 1 7
]

example:
B={b1,b2,b3},C={c1,c2,c3} what are a, b, c?
b1 = c1 + 2c2 - c3
b2 = 5c3 + 2c2
b3 = c2 - c1

change-of-coordinates B -> C
P_B->C = [
	1 0 -1
	a b 1
	-1 c 0
]
[b1]_c = [
	1
	2
	-1
]
[b2]_c = [
	0
	2
	5
]
[b3]_c = [
	-1
	1
	0
]
The change-of-coordinates matrix from B to C is a matrix columns are the coordinates of the vectors of B relative to the basis C:
P_B->c = [
	1 0 -1
	2 2 1
	-1 5 0
]
a = 2, b = 2, c = 5

Change-of-coordinates matrix are linearly independent the matrix must be invertible
P_B->c^-1 = P_c->B   Inverting a matrix
[
	-4 -6
	 3  5
]^-1
= 1/(-4)*5 - (-6)*3 [
	 5  6
	-3 -4
]
= (-1/2)[
	 5  6
	-3 -4
]
= [
	-5/2 -3
	 3/2  2
]

example:
[
	 3 -5
	-6  9
]^-1
= (-1/3)[
	9 5
	6 3
]
= [
	-3 -5/3
	-2 -1
]

1/3
[
	-6 3
	-3 1
]

example:
B = {[1|3],[-3|-6]} basis of R^2 let S be standard basis of R^2, find change-of-coordinates matrix S to B:
Using REF
[
	1 -3 | 1 0
	3 -6 | 0 1
]
R2 := R2 + (-3)R1
[
	1 -3 |  1 0
	0  3 | -3 1
]
R2 := 1/3R2
[
	1 -3 |  1 0
	0  1 | -1 1/2
]
R1 := R1 + 3R2
[
	1  0 | -2 1
	0  1 | -1 1/2
]
right side we obtain change-of-coordinates from S to B

[
	1 -2 | 2 -3
	-4 6 | -7 2
]
R2 := R2 + (4)R1
[
	1 -2 | 2 -3
	0 -2 | 1 -10
]
R1 := R1 + (-1)R2
[
	1  0 | 1 7
	0 -2 | 1 -10
]
R2 := -1/2R2
[
	1 0 | 1 7
	0 1 | -1/2 5
]
P_B->c = [
	1 7
	-1/2 5
]

example:
[x]_c: x = 5b1 - b2

P_B-c = [
	3 -5 1
	-6 9 0
	1 -1 1
][
	5
 -1
	0
] = [
	20
 -39
	6
]

Coordinates of a vector in a new basis given the inverse change-of-coordinates matrix:
from B to C. Find [x]_B x = 2c1 - 6c2, [x]_c = [2|-6]
P_B->c = [
	-4 3
	6 -4
]
[x]_B = P_c->B ⋅ [x]_c
first find change-of-coordinates matrix P_c->B we compute the inverse of P_B->c:
P_c->B = P^-1_B->c 
= [
	-4 3
	6 -4
]^-1
= (-1/2)[
	-4 -3
	-6 -4
]
= [
	2 3/2
	3 2
][
	2
	-6
] = [
	-5
	-6
]

Remember in order to find [x]_B we need P_c->B and [x]_c we are given P_B->c so we need to reverse to find P_c->B

[x]_B = [6|-9]
B = {
	[
		0
		-2
	], [
		1
		0
	]
}
C = {
	[
		1
		3
	], [
		1
		4
	]
}
[ 
	1 1 | 0 1
	3 4 | -2 0
]
R2 := R2 + (-3)R1
[ 
	1 1 | 0 1
	0 1 | -2 -3
]
R1 := R1 + (-1)R2
[ 
	1 0 | 2 4
	0 1 | -2 -3
]
= [
	2 4
	-2 -3
][
	6
	-9
]
[
 -24
  15
]
==================================================

If the vector space V has a basis with n vectors, then any basis of V has exactly n vectors.
The number n vectors in any basis of V is called the dimension of the space V dim(V)

If a vector space has a basis with a finite number of vectors then it is called finite-dimensional

If there is no finite basis, the vector space is called infinite-dimensional.

finding span with RREF:
[
	2 -2 2
	-2 1 -2
	1 -1 3
]
R2 := R2 + R1
[
	2 -2 2
	0 -1 0
	1 -1 3
]
R3 := R3 + (-1/2)R1
[
	2 -2 2
	0 -1 0
	0  0 2
]

example:
V = [
	3 5
	-6 -10
]
R2 := R2 + (2)R1
[
	3 5
	0 0
]
dim(Span(V)) = 1

The dimension of column space of matrix A is called the rank of A: rank(A)
rank(A) = dim(Col(A))

A is a 4x7 with 3 non-pivot find rank(A)
7 - 3 = 4: rank(A) = 4

rank(A) is the number of non-zero rows (pivot columns) in the corresponding REF matrix of A

example:
A = [
	-2 1 3 -2
	6 -2 -7 5
	0 2 4 -3
	0 -3 -6 3
]
R2 := R2 + (3)R1
[
	-2 1 3 -2
	0 1 2 -1
	0 2 4 -3
	0 -3 -6 3
]
R3 := R3 + (-2)R2
[
	-2 1 3 -2
	0 1 2 -1
	0 0 0 -1
	0 -3 -6 3
]
R4 := (-1/3)R4
[
	-2 1 3 -2
	0 1 2 -1
	0 0 0 -1
	0 1 2 -1
]
R4 := R4 - R2
[
	-2 1 3 -2
	0 1 2 -1
	0 0 0 -1
	0 0 0 0
]
(the answer was 3 operations but same output):
R2 := R2 + (3)R1
R3 := R3 + (-2)R2
R4 := R4 + 3R2

example:
[
	-4 6
	0 -1
	2 -3
]
R3 := R3 + (1/2)R1
[
	-4 6
	0 -1
	0 0
]
= rank(2)

dim(Null(A)) is equal to the number of non-pivot columns (free variables) in the corresponding REF of A

If A is a 9x11 matrix that has 9 pivot columns whats dim(Null(A))
11 - 9 = 2
dim(Null(A)) = 2

the dimension of the null space of a matrix A is often called the nullity of A:
nullity(A) = dim(Null(A))

using REF:
D = [
	2 1 2 3 1
	0 4 -2 1 -2
	8 0 10 9 7
	0 8 -4 2 -4
]
R3 := R3 + (-4)R1
[
	2 1 2 3 1
	0 4 -2 1 -2
	0 -4 2 -3 3
	0 8 -4 2 -4
]
R2 := R2 + R3
[
	2 1 2 3 1
	0 0 0 -2 1
	0 -4 2 -3 3
	0 8 -4 2 -4
]
R4 := R4 + (2)R3
[
	2 1 2 3 1
	0 0 0 -2 1
	0 -4 2 -3 3
	0 0 0 -4 2
]
(answer did this differenty)
R3 := R3 + (-4)R1
R3 := R3 + R2
R4 := R4 + (-2)R2
dim(Null(D)) = 2

D = [
	1 -2 0
	5 -7 9
	-3 6 -1
]
R3 := R3 + (3)R1
[
	1 -2 0
	5 -7 9
	0 0 -1
]
R2 := R2 + (-5)R1
[
	1 -2 0
	0 3 9
	0 0 -1
]
nullity(D) = dim(Null(D)) = 0

A is invertible:
Col(A) = R^n
dim(Col(A)) = n = rank(A)
Null(A) = {0}
dim(Null(A)) = 0 = nullity(A)

if A is a nxn matrix and Null(A) = {0} then rank(A) = n
if A is a nxn matrix and Null(A) = {0} then A has n pivot columns

if A is a nxn matrix and det(A) != 0 
- Null(A) has no basis
- A has n pivot columns

if A is a 7x7 matrix and A is invertiable Col(A) = R^7

The rank-nullity theorem relates the rank of a matrix to the dimension of its null space
dim(Col(A)) + dim(Null(A)) = dim(R^n)
or rank(A) + nullity(A) = n

8x6 matrix A, if rank(A) = 5 then what is nullity(A)?
rank(A) + nullity(A) = n
5 + nullity(A) = 6
nullity(A) = 6 - 5
= 1

Let A be a 3x6 matrix. if B = {b1,b2,b3} is a basis of Col(A) find dim(Null(A)).
n = 6, B is formed by 3 vectors: rank(A) = 3
dim(Null(A)) = 3

==================================================

An eigenvector of A is a non-zero vector:
Av = λv
eigenvalue is the scalar λ corresponding to the eigenvector for example:
(using | to denote next row to save space)

Av = [
	2  2
	2 -1
] ⋅ [1|-2] = [-2|4]
= (-2) ⋅ [1|-2]
= -2v

v = [1|-2] is the eigenvector
λ = -2 is the eigenvalue (the multiple of the final results)

example:
Av = [
	1 3
	3 1
] ⋅ [1|1] = [4|4]
= 4v
v eigenvector, eigenvalue λ = 4

example:
Av = [
	-1 8
	-1 -7
]⋅[-4|1] = [12|-3]
= (-3)⋅[-4|1]
= -3v
v eigenvector, eigenvalue λ = -3

example:
Av = [
	-1 -6
	-3  2
]⋅[-1|1] = [-5|5]
= (5)⋅[-1|1]
= 5v
v eigenvector, eigenvalue λ = 5

unknown value given an eigenvector and eigenvalue:
A = [
	2 1
	1 2
][1|2c]
λ = 6c is [1|2c]
= [
	2 + 2c
	1 + 4c
] = [6c|12c^2]
= {
	2 + 2c = 6c
	1 + 4c = 12c^2
}
solving c in first equation:
c = 1/2
substitution into second:
1 + 4(1/2) = 12(1/2)^2
3 = 3

example:
λ = 2k + 1
A = [
	1 5
	4 0
]
v = [
		5
	3k - 2
]

Av = λv
[
	1 5
	4 0
][
		5
	3k - 2
]
=
(2k + 1)[
		5
	3k - 2
]

Next step:
[
	5 + 5(3k - 2)
			20
] = [
			5(2k + 1)
	(2k + 1)(3k - 2)
]

Next step:
[
	-5 + 15k
		20
] = [
	10k + 5
	6k^2 - k - 2
]
= {
	-5 + 15k = 10k + 5
	20 = 6k^2 - k - 2
}
-5 + 15k = 10k + 5
5k = 10
k = 2

substitute:
20 = 6(2)^2 - (2) - 2
20 = 20
final solution to the system is k = 2

example:
[
	-2 -1
	 4  3
][
	4
 -2c
]
=
(2)[
	4
 -2c
]

=
[
	-8 + 2c
	16 - 6c
] = [
	8
	-4c
]
= {
	-8 + 2c = 8
	16 - 6c = -4c
}
2c = 16
c = 8
16 - 6(8) = -4(8)
-32 = -32
final answer: c = 8

Any non-zero multiple of an eigenvector is again an eigenvector, and the corresponding eigenvalue is the same

there should be at least one non-zero vector v that lies in Null(A - λI), the null space of the matrix: A - λI
Av = λv
Av - λv = 0
Av - λIv = 0
(A - λI)v = 0

The invertible matrix theorem tells us that the matrix A - λI must be singular meaning det(A - λI) = 0

This is called the characteristic equatiion:
First matrix A - λI:
A - λI = [
	2  5
 -1 -4
] - λ[
	1 0
	0 1
]
= [
	2-λ   5
  -1  -4-λ
]
then solve the characteristic equation det(A - λI) = 0
|2-λ  5 |
|-1 -4-λ| = 0
(2 - λ)(-4 - λ) - 5 ⋅ (-1) = 0
-8 - 2λ + 4λ + λ^2 + 5 = 0
λ^2 + 2λ - 3 = 0
(λ + 3)(λ - 1) = 0
eigenvalues are: λ = -3, λ = 1

Characteristic equations:
example:
[
	5-λ   3
	 0   5-λ
]
(5-λ)(5-λ) - 3 * 0 = 0
25 - 5λ - 5λ + λ^2 = 0
λ^2 - 10λ + 25 = 0

example:
[
	2-λ   2
	 -8   -6-λ
]
(2-λ)(-6-λ) - 2 * (-8) = 0
-12 - 2λ + 6λ + λ^2 + 16 = 0
λ^2 + 4λ + 4 = 0

The characteristic equation of any 2x2 matrix A is always a quadratic equation, which implies that A has at most 2 eigenvalues. Possible cases:
* Two distinct real eigenvalues
* One repeated real eigenvalue (or two eigenvalues that are the same)
* No real eigenvalues (or two complex eigenvalues)

computing eigenvalues of matrix with two distinct eigenvalues:
A - λI = [
	10-λ  3
	  6  7-λ
]
det(A - λI) = 0
|10-λ 3|
|6  7-λ| = 0
(10-λ)(7-λ) - 3 * 6 = 0
70 - 7λ - 10λ + λ^2 - 18 = 0
λ^2 - 17λ + 52 = 0

using the quadratic formula to find the eigenvalues:

λ = (17 +/- sqrt((-17)^2 - 4 * 1 * 52))/2 * 1
= (17 +/- sqrt(81))/2
= (17 +/- 9)/2
= 13, 4
eigenvalues are λ = 13, and λ = 4

example:
(excluding matrix to save space)
(-4-λ)(7-λ) - 2 * 6 = 0
-28 + 4λ - 7λ + λ^2 - 12 = 0
λ^2 - 3λ - 40 = 0

λ = (3 +/- sqrt((-3)^2 - 4 * 1 * 40))/2 * 1
= (3 +/- sqrt(169))/2
= (3 +/- 13)/2
= 8, -5
eigenvalues are λ = 8, and λ = -5

example:
(-6-λ)(2-λ) - 3 * 3 = 0
-12 + 6λ - 2λ + λ^2 - 9 = 0
λ^2 + 4λ - 21 = 0

λ = (-4 +/- sqrt((4)^2 - 4 * 1 * (-21)))/2 * 1
= (-4 +/- sqrt(100))/2
= (-4 +/- 10)/2
λ = 3, λ = -7

example:
(-6-λ)(-10-λ) - (-3) * 2 = 0
60 + 6λ + 10λ + λ^2 + 6 = 0
λ^2 + 16λ + 66 = 0

λ = (-16 +/- sqrt((16)^2 - 4 * 1 * (66)))/2 * 1
((16)^2 - 4 * 1 * (66)) isolating
= 256 - 254
= -8 its < 0 therefore no real eigenvalues

example:
(3-λ)(1-λ) - 1 * (-1) = 0
3 - 3λ - λ + λ^2 + 1 = 0
λ^2 - 4λ + 4 = 0
(λ - 2)(λ - 2)
(λ - 2)^2
one eigenvalue (double root) λ = 2


eigenvalues of a tiangular/diagonal matrix
A - λI = [
	3-λ 		0
	 9  -2sqrt(3)-λ
]
(3 - λ)(-2sqrt(3) - λ) - 9 * 0 = 0
(λ - 3)(λ + 2sqrt(3)) = 0
λ = 3 and λ = -2sqrt(3)
the eigenvalues are the entries on the main diagonal. The eigenvalues of a triangular or diagonal matrix are always given by the entries on the main diagonal

For a general matrix (which is neither triangular nor diagonal), probably isn't the case

example:
[
	sqrt(3) 0
	  4     2
]
(sqrt(3) - λ)(2 - λ) - 0 * 4 = 0
(sqrt(3) - λ)(2 - λ) = 0
λ = sqrt(3) and λ = 2

example:
[
	sqrt(2)  0
   	0  -sqrt(3)  
]
(sqrt(2) - λ)(-sqrt(3) - λ) - 0 * 0 = 0
(λ - sqrt(2))(λ + sqrt(3))
λ = sqrt(2) and λ = -sqrt(3)

==================================================

calculating eigenvector from an eigenvalue if v = [a|b] is an eigenvector of A = [2 5|-1 -4] that has the eigenvalue λ = 1 what is b/a
we need to find non-zero solutions of the matrix equation:
(A - λI)x = 0
in this example λ = 1
A - λI = [
	 2  5
	-1 -4 
] - [
	1 0
	0 1
] = [
	 1  5
	-1 -5
]
= {
	x1 + 5x2 = 0
 	-x1 - 5x2 = 0
}
[
	 1  5 | 0
	-1 -5 | 0
]
R2 := R2 + R1
[
	1 5 | 0
	0 0 | 0
]
(first column pivot, x2 free)
x1 + 5x2 = 0  =>  x1 = -5x2
= [
	-5x2
	 x2
]
for instance x2 = -1 we get the eigenvector:
v = [a|b] = [5|-1]
b/a = -1/5

example:
λ = 3
what is the value of b/a
A - 3I = [
	1 -2
	-2 1
] - 3[
	1 0
	0 1
] = [
	-2 -2
	-2 -2
]
= {
	-2x1 - 2x2 = 0
	-2x1 - 2x2 = 0
}
[
	-2 -2 | 0
	-2 -2 | 0
]
R2 := R2 + (-1)R1
[
	-2 -2 | 0
	 0  0 | 0
]
-2x1 - 2x2 = 0  =>  x1 = -x2
[
	-x2
	x1
]
setting x2 = 1 we get the eigenvector
[
	-1
	 1
]
1/-1 = -1

example:
what is the eigenvector of A if v = [a|b]
λ = 5 what is the value of a/b
A - 5I = [
	 7  5
	-4 -5
] - 5[
	1 0
	0 1
] = [
	 2   5
	-4 -10
]
= {
	2x1 + 5x2 = 0
	-4x1 - 10x2 = 0
}
= [
	 2   5 | 0
	-4 -10 | 0
]
R2 := R2 + (2)R1
[
	 2   5 | 0
	 0   0 | 0
]
2x1 + -5x2 = 0  =>  x1 = -5/2x2
[
	-5/2x2
	  x2
]
setting x2 = 2 we get the following eigenvector:
v = [a|b] = [-5|2]
a/b = -5/2

finding the eigenvector of A
λ = 0
A = [
	-6 4
	-3 2
] - 0[
	1 0
	0 1
] = [
	-6 4
	-3 2
]
= {
	-6x1 + 4x2 = 0
	-3x1 + 2x2 = 0
}
= [
	-6 4 | 0
	-3 2 | 0
]
R2 := R2 + (-1/2)R1
[
	-6 4 | 0
	 0 0 | 0
]
-6x1 + 4x2 = 0
-6x1 = -4x2
x1 = 4/6x2
x1 = 2/3x2
[
	2/3x2
	 x2
]
setting x2 = 3 we get the eigenvector:
[
	2
	3
]

example:
λ = -3
A = [
	7 -10
	2 -5
] - (-3)[
	1 0
	0 1
] = [
	10 -10
	2 -2
]
[
	10 -10 | 0
	2  -2  | 0
]
R2 := R2 + (-1/5)R1
[
	10 -10 | 0
	0   0  | 0
]
10x1 = 10x2
x1 = x2
[
	x2
	x2
]
setting x2 = 1 we get the eigenvector:
[
	1
	1
]

given a matrix A with an eigenvalue λ, the eigenspace V_λ can be defined as the set of all possible eigenvetors corresponding to λ plus the vector 0:

V_λ = {the eigenvetors corresponding to λ} U {0}

The eigenspace consists of all (not only non-zero) solutions of the equation (A - λI)x = 0, the eigenspace can also be viewed as the null space of the matrix A - λI:

V_λ = Null(A - λI)

Eigenvectors that correspond to different eigenvalues are always linearly independent

finding two linearly independent eigenvectors:
λ = 1 and λ = -4 

for λ = 1
A - λI = [
	1 -1
	0 -4
] - 1[
	1 0
	0 1
] = [
	0 -1
	0 -5
]
[
	0 -1 | 0
	0 -5 | 0
]
R2 := R2 + (-5)R1
[
	0 -1 | 0
	0  0 | 0
]
(second column is the pivot so x1 is free)
x2 = 0
[
	x1
	0
]
setting x1 = 1 we get eigenvector v1 = [1|0]
for λ = -4
A - λI = [
	1 -1
	0 -4
] - (-4)[
	1 0
	0 1
] = [
	5 -1
	0 0
]
[
	5 -1 | 0
	0  0 | 0
]
(x2 is free)
x1 = 1/5x2
[
	1/5x2
	 x2
]
setting x2 = 5 we get eigenvector v2 = [1|5]

example:
λ = -3 and λ = 4 

λ = -3
A = [
	-10 -7
	 14 11
] - (-3)[
	1 0
	0 1
] = [
	-7 -7
	14 14
]
[
	-7 -7 | 0
	14 14 | 0
]
R2 := R2 + (2)R1
[
  -7 -7 | 0
	0   0 | 0
]
(x2 free)
x1 = -x2
[
	-x2
	 x2
]
setting to x2 = 1 we get eigenvector v1 = [-1|1]
λ = 4
A = [
	-10 -7
	 14 11
] - 4[
	1 0
	0 1
] = [
	-14 -7
	 14  7
]
[
	-14 -7 | 0
	 14  7 | 0
]
R2 := R2 + R1
[
	-14 -7 | 0
	 0   0 | 0
]
(x2 free)
x1 = -1/2x2
[
	-1/2x2
	  x2
]
setting x2 = 2 we get eigenvector v2 = [-1|2]
two linearly independent eigenvectors of matrix A:
[-1|1] and [-1|2]

example:
λ = 1 and λ = 5

for λ = 1
A = [
	3 2
	2 3
] - [
	1 0
	0 1
] = [
	2 2
	2 2
]
[
	2 2 | 0
	2 2 | 0
]
R2 := R2 - R1
[
	2 2 | 0
	0 0 | 0
]
(x2 free)
x1 = -x2
[
	-x2
	 x2
]
we can set x2 = 1 eigenvector: [-1|1]

for λ = 5
A = [
	3 2
	2 3
] - 5[
	1 0
	0 1
] = [
	-2  2
	 2 -2
]
[
	-2  2 | 0
	 2 -2 | 0
]
R2 := R2 + R1
[
	-2  2 | 0
	 0  0 | 0
]
(x2 free)
[
	x2
	x2
]
setting x2 = 1, we get eigenvector v2 = [1|1]
two linearly independent eigenvectors of matrix A:
[-1|1], [1|1]

The determinant of a triangular or diagonal matrix is given by the product of the elements on the main diagonal, calculating eigenvlaues of a 3x3 matrix:
determine all real eigenvalues λ of A

A = [
	-9 4  8
	 0 9 -7
]
A - λI = [
	-9-λ 4   8
	 0  9-λ -7
	 0   0  6-λ
]
the characteristic equation is det(A - λI) = 0
The determinant or diagonal matrix is given by the product of entries on the main diagonal:
(-9 - λ)(9 - λ)(6 - λ) = 0
(λ + 9)(λ - 9)(λ - 6) = 0
eigenvalues are λ1 = -9, λ2 = 9, λ3 = 6

example:
find the characteristic equation
[
	-3 2 -1
	 5 2  3
	 0 0  1
]
A - λI = [
	-3-λ  2  -1
	 5   2-λ  3
	 0    0  1-λ
]
expanding the determinant across the 3rd row:
(1 - λ)| -3-λ  2 |
       |   5  2-λ| = 0

(1 - λ)((-3 - λ)(2 - λ) - 2*5) = 0
(1 - λ)(λ^2 + λ - 16) = 0

example:
find all real eigenvalues of λ
A = [
	 3  0 0
	 1 -2 0
	-2  3 4
]
A - λI = [
	3-λ  0   0
	1  -2-λ  0
	-2   3  4-λ
]
(3 - λ)(-2 - λ)(4 - λ) = 0
(λ - 3)(λ + 2)(λ - 4) = 0
λ1 = -2, λ2 = 3, λ3 = 4

The algebraic multiplicity of an eigenvalue λ is the number of times it is a solution of the characteristic equation. 6x6 matrix A with the characteristic equation:
(λ - 4)(λ - 4)(λ - 1)(λ + 8)^3 = 0
eigenvalue λ = 4 is a double root, it has algebraic multiplicity = 2
λ = 1 has algebraic multiplicity 1
λ = -8 has a algebraic multiplicity of 3

Eigenvalues of 4x4 matrix containing a block of zeros
P = [
	3  0 -8 -2
	0 -1  3  5
	0  0  4  0
	0  7 -3  1
]
P - λI = [
	3-λ  0  -8  -2
	0  -1-λ  3   5
	0    0  4-λ  0
	0    7  -3  1-λ
]

we can expand 4x4 determinant across the 1st column:
[
	3-λ  0  -8  -2
	0  -1-λ  3   5
	0    0  4-λ  0
	0    7  -3  1-λ
]
       |-1-λ  3   5 |
(3 - λ)|  0  4-λ  0 | = 0
       |  7  -3  1-λ|

now we can expand 3x3 determinant across 2nd row:

(3 - λ)(4 - λ)|-1-λ  5 |
              |  7  1-λ| = 0

(3 - λ)(4 - λ)((-1 - λ)(1 - λ) - 35) = 0
(3 - λ)(4 - λ)(λ^2 - 36) = 0
(λ - 3)(λ - 4)(λ - 6)(λ + 6) = 0

eigenvalues of P are λ = 3, λ = 4, λ = 6, λ = -6
all with algebraic multiplicity 1

example:
P = [
	 -1  -9 -18 -3
	  0 -10   0  0
	  0   0 -10  0
	-18  18 -36 -4
]
P - λI = [
	-1-λ  -9  -18 -3
	  0 -10-λ   0  0
	  0   0  -10-λ 0
	-18 18   -36 -4-λ
]
we can expand 4x4 determinant across the 2nd row:
			 |-1-λ  -18  -3 |
(-10-λ)| 0  -10-λ   0 | = 0
			 |-18  -36  -4-λ|

expanding the 3x3 detereminant across the 2nd row:

(-10-λ)(-10-λ) |-1-λ -3 |
							 |-18 -4-λ| = 0

(-10 - λ)^2((-1 - λ)(-4 - λ) - 54) = 0
(10 + λ)^2(λ^2 + 5λ - 50) = 0
(10 + λ)^2(λ + 10)(λ - 5) = 0
(10 + λ)^3(λ - 5) = 0
eigenvalues are λ = -10 with AM 3 (alegraic multiplicity) and λ = 5

eigenvalues of a general 3x3 matrix:
A = [
	1 -1 -2
	-1 1 -2
	-2 -2 -7
]
A - λI = [
	1-λ  -1   -2
	 -1 1-λ   -2
	 -2  -2 -7-λ
]
expanding the determinant across the 1st row:

(1-λ)|1-λ -2 |-(-1)|-1   -2|+(-2)|-1 1-λ|
	   |-2 -7-λ|     |-2 -7-λ|     |-2  -2| = 0

(-λ^2 - 5λ^2 + 17λ - 11)+(3 + λ)-2(4 - 2λ) = 0
-λ^3 - 5λ^2 + 22λ - 16 = 0
λ^3 + 5λ^2 - 22λ + 16 = 0

now we need to solve this equation, we find the first root by testing values. According to the rational zeros theorem, a list of good first guesses consists of all divisors of 16:
+/-1, +/-2, +/-4, +/-8, +/-16

picking x = 1:
(1)^3 + 5(1)^2 - 22(1) + 16 = 0

λ = 1 is a root of the equation. We can factor (λ - 1) out of λ^3 + 5λ^2 - 22λ + 16 using synthetic division:

1 | 1 5 -22  16
  |   1   6 -16
  |____________
    1 6 -16  0

factorization:
(λ - 1)(λ^2 + 6λ - 16) = 0
(λ - 1)(λ - 2)(λ + 8) = 0
λ1 = 1, λ2 = 2, λ3 = -8

example:
(finding eigenvalues)
A = [
	 4  2  1
	-2 -1 -2
	 2  2  3
]
A - λI = [
	 4-λ  2  1
	 -2 -1-λ -2
	  2   2  3-λ
]
expanding the determinant across the 1st row:

(4-λ)|-1-λ -2|-2|-2 -2|+(1)|-2 -1-λ|
	   | 2  3-λ|  |2 3-λ|    |2     2| = 0

expanding first part:
(4 - λ)((-1 - λ)(3 - λ) - (-2)(2))
(4 - λ)(-3 + λ - 3λ + λ^2 + 4)
-12 + 4λ - 12λ + 4λ^2 + 16 + 3λ - λ^2 + 3λ^2 - λ^3 - 4λ
-λ^3 + 6λ^2 - 9λ + 4

expanding second part:
((-2)(3 - λ) - (-2)(2))
(-6 + 2λ + 4)
-2(-2 + 2λ)

expanding third part:
((-2)(2) - (-1-λ)(2))
+(-4 + 2 + 2λ)
+(-2 + 2λ)

altogether:
(-λ^3 + 6λ^2 - 9λ + 4) - 2(-2 + 2λ) + (-2 + 2λ) = 0

combining like terms (with multiplying the 2):
-λ^3 + 6λ^2 - 11λ + 6 = 0
λ^3 - 6λ^2 + 11λ - 6 = 0

test values that are divors of 6:
+/-1, +/-2, +/-3, +/-6

lets pick x = 1
(1)^3 - 6(1)^2 + 11(1) - 6 = 0

λ = 1 is a root, so factor out (λ - 1) from λ^3 - 6λ^2 + 11λ - 6
using synthetic division

1 | 1 -6 11 -6
  |    1 -5  6
  |____________
    1 -5  6  0

(λ - 1)(λ^2 - 5λ + 6) = 0
(λ - 1)(λ - 2)(λ - 3) = 0
λ1 = 1, λ2 = 2, λ3 = 3

example:
(finding characteristic)
A = [
	 0 -2 -3
	-2  3  6
	 2 -2 -5
]
A - λI = [
	 0-λ -2 -3
	 -2  3-λ  6
	  2  -2 -5-λ
]
(0-λ)|3-λ   6 |-(-2)|-2  6 |+(-3)|-2 3-λ|
	   | -2 -5-λ|     |2 -5-λ|     |2   -2| = 0

expanding first:
((3 - λ)(-5 - λ) - (6)(-2))
-15 - 3λ + 5λ + λ^2 + 12
(0 - λ)(λ^2 + 2λ - 3)
-λ^3 - 2λ^2 + 3λ

expanding second:
((-2)(-5 - λ) - (6)(2))
(10 + 2λ - 12)
2(-2 + 2λ)

(MADE A MISTAKE HERE and below took the wrong cross determinant A - λI)
(corrected now)
expanding third:
((-2)(-2) - (3 - λ)(2))
-2 + 2λ
-3(-2 + 2λ)

altogether:
(-λ^3 - 2λ^2 + 3λ) + 2(-2 + 2λ) - 3(-2 + 2λ) = 0
λ^3 + 2λ^2 - λ - 2 = 0

^ these are easy to mess up, they take a lot of time and careful persision.

calculating eigenvalues of a 3x3

example:
v = [a|b|c] whats b/c given λ = 7
A = [
	1  4 0
	0 -2 3
	0  0 7
] - 7[
	1 0 0
	0 1 0
	0 0 1
] = [
	-6  4 0
	 0 -9 3
	 0  0 0 
]
[
	-6  4 0 | 0
	 0 -9 3 | 0
	 0  0 0 | 0
]
R2 := (-1/3)R2
[
	-6  4  0 | 0
	 0  3 -1 | 0
	 0  0  0 | 0
]
R1 := (-1/2)R1
[
	 3  -2 0 | 0
	 0  3 -1 | 0
	 0  0  0 | 0
]
(didn't need to do any row operations, the resulting matrix from step 1 is already in row echelon form)
x2 = 1/3x3

x1 = 2/3x2
x1 = 2/3(1/3x3)
x1 = 2/9x3

[
	2/9x1
	1/3x3
	  x3
]
setting x3 to 9 we get eigenvector:
[
	2
	3
	9
]
b/c = 3/9 = 1/3

example:
v = [a|b|c] whats a/b given λ = 1
A = [
	2 1  0
	2 3 -2
	1 1  1
] - [
	1 0 0
	0 1 0
	0 0 1
] = [
	1 1 0
	2 2 -2
	1 1 0
]
[
	1 1  0 | 0
	2 2 -2 | 0
	1 1  0 | 0
]
R2 := R2 + (-2)R1
[
	1 1  0 | 0
	0 0 -2 | 0
	1 1  0 | 0
]
R3 := R3 + (-1)R1
[
	1 1  0 | 0
	0 0 -2 | 0
	0 0  0 | 0
]
x1 = -x2

x3 = 0

[
	-x2
	x2
	0
]
setting x2 = 1 we get eigenvector: v = [-1|1|0]
a/b = -1/1 = -1

example:
λ = 3
A = [
	-9   9 -7
	-14 13 -8
	-2   1  2
] - 3[
	1 0 0
	0 1 0
	0 0 1
] = [
	-12  9 -7
	-14 10 -8
	-2   1 -1
]
[
	-12  9 -7 | 0
	-14 10 -8 | 0
	 -2  1 -1 | 0
]
R1 <-> R3
[
	-2  1  -1 | 0
	-14 10 -8 | 0
	-12  9 -7 | 0
]
R2 := R2 + (-7)R1
[
	 -2 1 -1 | 0
	  0 3 -1 | 0
	-12 9 -7 | 0
]
R3 := R3 + (-6)R1
[
	 -2 1 -1 | 0
	  0 3 -1 | 0
	  0 3 -1 | 0
]
R3 := R3 + (-1)R2
[
	 -2 1 -1 | 0
	  0 3 -1 | 0
	  0 0  0 | 0
]
(x3 free)
x2 = 1/3x3

x1 = -1/2(-x2 + x3)
x1 = -1/2(-(1/3x3) + x3)
x1 = -1/3x3

[
	-1/3x3
	 1/3x3
	  x3
]
setting x3 = 3 eigenvector v = [-1|1|3]

example:
λ = -1
A = [
	1  2  4
	0 -1 -4
	0  0  2
] + [
	1 0 0
	0 1 0
	0 0 1
] = [
	2 2  4
	0 0 -4
	0 0  3
]
[
	2 2  4 | 0
	0 0 -4 | 0
	0 0  3 | 0
]
R2 := R2 + R1
[
	2 2  4 | 0
	0 0  0 | 0
	0 0  3 | 0
]
R1 := (1/2)R1
[
	1 1  2 | 0
	0 0  0 | 0
	0 0  3 | 0
]
Answer just did one operation:
R3 := R3 + 3/4R2
(but our answer still holds!)

x3 = 0

x1 + x2 = 0
x2 = -x1

[
	-x2
	 x2
	 0
]
setting x2 = 1 eigenvector v: [-1|1|0]

The set of eigenvectors {v1,v2,...vk} of a matrix A, where each vector v_i corresponds to different eigenvalue, is linearly independent

* Eigenvectors that correspond to the same eigenvalue often is linearly dependent

find eigenvalues for:
we need to find the third eigenvalue, the first one is λ1 = -3 and second λ2 = 2
we also need to find the eigenvector related to the third eigenvalue

A = [
	-2  0 -2
	 1 -1 -1
	-2  0  1
]
A = [
	-2-λ  0  -2
	 1  -1-λ -1
	-2    0  1-λ
]
((-2 - λ)(1 - λ) - (2)(2))
(-1 - λ)(λ^2 + λ - 6)
(λ + 1)(λ + 3)(λ - 2) = 0
the one that is missing is λ3 = -1

A - λI = [
	-2  0 -2
	 1 -1 -1
	-2  0  1
] -(-1)[
	1 0 0
	0 1 0
	0 0 1
] = [
	 -1 0 -2
	  1 0 -1
	 -2 0  2
]
[
	-1 0 -2 | 0
	 1 0 -1 | 0
	-2 0  2 | 0
]
R2 := R2 + R1
[
	-1 0 -2 | 0
	 0 0 -3 | 0
	-2 0  2 | 0
]
R3 := R3 + (-2)R1
[
	-1 0 -2 | 0
	 0 0 -3 | 0
	 0 0  6 | 0
]
R3 := R3 + (2)R2
[
	-1 0 -2 | 0
	 0 0 -3 | 0
	 0 0  0 | 0
]
(x2 is free)

x3 = 0
x1 = 0
[
	0
	x2
	0
]
setting x2 = 1 eigenvector: [0|1|0]
a/b = 0/1 = 1

example:
using a diagonal matrix to use the eigenvalues to find the eigenvector (we already have λ1 = 1, λ2 = -4):
A = [
	1  7 2
	0 -4 2
	0  0 5
] - 5[
	1 0 0
	0 1 0
	0 0 1
] = [
	-4 7 2
	0 -9 2
	0 0 0
]
(already in row echelon form)

x2 + 2x3 = 9/2x3
x1 = 1/4(7x2 + 2x3)
x1 = 1/4(7(2/9x3) + 2x3)
x1 = 1/4 * 32/9x3
x1 = 8/9x3
[
	8/9x3
	2/9x3
	 x3
]
setting x3 = 0 eigenvector: [8|2|9]
a/b = 8/2 = 4

A basis of a one dimensional eigenspace:
A = [
	7 0 0
	2 7 0
	3 6 7
] - 7[
	1 0 0
	0 1 0
	0 0 1
] = [
	0 0 0
	2 0 0
	3 6 0
]
R1 <-> R3
[
	3 6 0
	2 0 0
	0 0 0
]
R2 := R2 + (-2/3)R1
[
	3 6  0
	0 -4 0
	0 0  0
]
(x3 is free)
x2 = 0
x1 = 0
[
	0
	0
	x3
] = x3[
	0
	0
	1
]
required basis is:
B = {[0 | 0 | 1]}

example:
A = [
	5 5 4 8
	0 5 2 1
	0 0 5 1
	0 0 0 5
] - 5[
	1 0 0 0
	0 1 0 0
	0 0 1 0
	0 0 0 1
] = [
	0 5 4 8
	0 0 2 1
	0 0 0 1
	0 0 0 0
]
(already in row echelon form)
x1 is free
x4 = 0
x3 = 0
x2 = 0
[
	x1
	0
	0
	0
] = x1[
	1
	0
	0
	0
]
required basis is:
B = {[1 | 0 | 0 | 0]}

example:
A = [
	1 2  4
	2 1 -4
	0 0  3
] - 3[
	1 0 0
	0 1 0
	0 0 1
] = [
	-2  2  4
	 2 -2 -4
	 0  0  0
]
[
	-2  2  4 | 0
	 2 -2 -4 | 0
	 0  0  0 | 0
]
R2 := R2 + R1
[
	-2  2  4 | 0
	 0  0  0 | 0
	 0  0  0 | 0
]
(1st column pivot x2 and x3 are free)
x1 = x2 + 2x3
[
	x2 + 2x3
		x2
		x3
] = x2[
	1
	1
	0
] + x3[
	2
	0
	1
]
required basis:
B = {[1 | 1 | 0], [2 | 0 | 1]}

example:
A = [
	2 0 0
	0 2 3
	0 0 2
] - 2[
	1 0 0
	0 1 0
	0 0 1
] = [
	0 0 0
	0 0 3
	0 0 0
]
(3rd column pivot, x1 and x2 are free)
x3 = 0
[
	x1
	x2
	0
] = x1[
	1
	0
	0
] + x2[
	0
	1
	0
]
required basis:
B = {[1 | 0 | 0], [0 | 1 | 0]}

example:
find parts of eigenvectors (a + b), we are given:
v1 = [a | 1 | 0] and v2 = [b | 0 | 1]
λ = 1
A = [
	 7 -6 6
	 6 -5 6
	-3  3 -2
] - [
	1 0 0
	0 1 0
	0 0 1
] = [
	 6 -6  6
	 6 -6  6
	-3  3 -3
]
R2 := R2 + (-1)R1
[
	 6 -6  6 | 0
	 0  0  0 | 0
	-3  3 -3 | 0
]
R3 := R3 + (1/2)R1
[
	 6 -6  6 | 0
	 0  0  0 | 0
	 0  0  0 | 0
]
(ANSWER did an addition row operation R1 := 1/6R1)
(not needed for the correct final answer)
x1 = -x3 + x2
[
	x2 - x3
	  x2
	  x3
]
since v1 = [a|1|0], x2 = 1 and x3 = 0, therefore a = 1 - 0 = 1
since v2 = [b|0|1], x2 = 0 and x3 = 1, therefore b = 0 - 1 = -1
a + b = 1 + (-1) = 0

example:
we are given:
v1 = [a | 1 | 0], v2 = [b | 0 | 1]
λ = 7, whats a + b
A = [
	 8  5  4
	-2 -3 -8
	 0  0  7
] - 7[
	1 0 0
	0 1 0
	0 0 1
] = [
	 1   5  4
	-2 -10 -8
	 0   0  0
]
R2 := R2 + (2)R1
[
	 1  5  4 | 0
	 0  0  0 | 0
	 0  0  0 | 0
]
x1 + 5x2 + 4x3 = 0
x1 = -5x2 - 4x3
[
	-5x2 - 4x3
			x2
			x3
]
since v1 = [a|1|0], x2 = 1 and x3 = 0:
a = -5(1) - 4(0) = -5
since v2 = [b|0|1], x2 = 0 and x3 = 1:
b = -5(0) - 4(1) = -4
a + b = -5 + (-4) = -9

if λ is a simple root of the characteristic equation then the eigenspace V_λ has dimension 1:
dim(V_λ) = 1

if λ is not a simple root of the characteristic equation (its a double, triple, etc) the dimension of the eigenspace V_λ equals number of free variables in the system of linear equations:
(A - λI)x = 0 (unless its a double root)

if an eigenvalue λ is a root of multiplicity k in the correspoding characteristic equation, then the eigenspace V_λ has dimension not greater than k:
dim(V_λ) <= k

Review:
the multiplicity of an eigenvalue as a root of the characterstic equation is called algebraic multiplicity. The dimension of the corresponding eigenspace is called the geometric multiplicity of the eigenvector

The geometric multiplicity of an eigenvalue is always less or equal to the algebraic multiplicity.

finding the dimensions linearly independent eigenvectors (pivots are dependent) given eigenvalues:
example:
λ = -6 and λ = 2

A = [
	-8 -2 4
	 0  2 0
	-5 -1 4
] -(-6)[
	1 0 0
	0 1 0
	0 0 1
] = [
	-2 -2  4
   0  8  0
  -5 -1 10
]
R1 := (-1/2)R1
[
	 1  1  2 | 0
   0  8  0 | 0
  -5 -1 10 | 0
]
R3 := R3 + (5)R1
[
	 1  1  2 | 0 
   0  8  0 | 0 
   0  4  0 | 0
]
2 pivots
3 - 2: dim(V_-6) = 1
(also -6 is a simple root)

A = [
	-8 -2 4
	 0  2 0
	-5 -1 4
] - 2[
	1 0 0
	0 1 0
	0 0 1
] = [
	-10 -2 4
	  0  0 0
	 -5 -1 2
]
R1 := -1/2R1
[
	  5  1 2 | 0
	  0  0 0 | 0
	 -5 -1 2 | 0
]
R3 := R3 + R1
[
	  5  1 2 | 0
	  0  0 0 | 0
	  0  0 0 | 0
]
1 pivot
3 - 1: dim(V_2) = 2

example:
find all dimensions for:
λ = 5, λ = -2, and λ = 1
dim(V_5) and dim(V_-2) = 1 (simple roots)

C = [
	1 1 0  0
	0 1 1  0
	0 0 5  0
	0 0 0 -2
] - [
	1 0 0 0
	0 1 0 0
	0 0 1 0
	0 0 0 1
] = [
	0 1 0  0
	0 0 1  0
	0 0 4  0
	0 0 0 -3
]
R3 := R3 - 4R2
[
	0 1 0  0
	0 0 1  0
	0 0 0  0
	0 0 0 -3
]
R3 <-> R4
[
	0 1 0  0
	0 0 1  0
	0 0 0 -3
	0 0 0  0
]
(3 pivots)
4 - 3 = 1 lineraly independent eigenvector
dim(V_1) = 1

==================================================
(using | sometimes in vectors to represent next row)

A square matrix A is called diagonalizable if there exists a diagonal matrix D and an invertible matrix P
A = PDP^-1

To diagonalize a matrix A we need to find a diagonal matrix D and an invertible matrix P that satisfy the equation above.

example (diagonalize 2x2):
A = [
	0 -6
	1  5
]

step 1: find the eigenvalues
solve the characteristic equation |A-λI| = 0, eigenvalues are λ1 = 2 and λ2 = 3

step 2: find a basis of R^2 consisting of eigenvectors
we get: v1 = [3|-1] v2 = [-2|1], {v1,v2} is a basis of R^2 since eigenvectors corresponding to distinct eigenvalues are linearly independent.

step 3: Construct the matrices D and P.

Matrix D has the eigenvalues as entries on the diagonal, in any order.
D = [
	2 0
	0 3
]
The columns P are the eigenvectors. Each eigenvector in the same column as its respective eigenvalue:
P = [
	3 -2
	-1 1
]
finally:
A = PDP^-1 = [
	3 -2
	-1 1
][
	2 0
	0 3
][
	3 -2
	-1 1
]^-1

= [
	6 -6
	-2 3
][
	1 2
	1 3
] = [
	0 -6
	1 5
]
= A

(6)(1)+(-6)(1)  (6)(2)+(-6)(3)
(-2)(1)+(3)(1)  (-2)(2)+(3)(3)

(We can double check our solution by computing the product on the right side)

example:
we are given:
λ1 = 4 and λ2 = 3
A = [
	 3 0
	-5 4
]
v1 = [0|1], v2 = [1|5]
find matrices P and D such that PDP^-1 = a where D is a diagonal matrix

D = [
	4 0
	0 3
]

P using the eigenvectors as columns:
1st column is eigenvector for λ1 = 4
2nd column is eigenvector for λ2 = 3

P = [
	0 1
	1 5
]

theorem:
If A is a 2x2 matrix, then it is diagonalizable if and only if there exists a basis of R^2 that consists of eigenvvectors of A

If A has two distinct eigenvalues, then it is diagonalizable. Two distinct eigenvalues will be two linearly independent eigenvectors (one for each eigenvalue)

Double roots λ of the characteristic equation, the matrix will be diagonalizable only if we can find exactly two linearly independent eigenvectors corresponding to λ, which may not be possible. The corresponding eigenspace V_λ must be dimension 2

identifying if a 2x2 matrix is diagonalizable:
A = [
	3 -5
	0 3
]
A is triangular, the eigenvalues are the entries on the main diagonal.
eigenvalues are λ1 = λ2 = 3, since there is one repeated eigenvalue the matrix may not be diagonalizable. To check row reduce:
A - 3I = [
	3 -5
	0 3
] - 3[
	1 0
	0 1
] = [
	0 -5
	0 0
]
1 pivot column, 2 - 1 = 1 linearly independent eigenvector corresponding to the current eigenvalue. A is not diagonalizable.

example:
A = [
	4-λ 1
	-1 2-λ
]
(4 - λ)(2 - λ) - (1)(-1)
9 - 6λ + λ^2 
λ^2 - 6λ + 9
(λ - 3)(λ - 3)
(λ - 3)^2

A - 3I = [
	 4 1
  -1 2
] - 3[
	1 0
	0 1
] = [
	1 1
 -1 -1
]
R2 := R2 + R1
[
	1 1
	0 0
]
1 pivot column, implies we will only have 2-1=1 linearly independent eigenvector corresponding to the eigenvalue. A is not diagonalizable.

example:
A = [
	10-λ -4
	 24 -10-λ
]
(10 - λ)(-10 - λ) - (-4)(24)
-100 - 10λ + 10λ + λ^2 + 96
λ^2 - 4
(λ - 2)(λ + 2)
λ1 = 2 and λ2 = -2 we have 2 distinct eigenvalues therefore A is diagonalizable.
D = [
	2 0
	0 -2
]

Connection between matrix and diagonal form:
* Review: 
A is our matrix
P is eigenvectors
D is our eigenentries on diagonal

A = PDP^-1

if we want D the subject:
A = PDP^-1
P^1 * A = P^-1 * PDP^-1
P^1A = I_2DP^-1
P^1A = DP^-1

P^-1A * P = DP^-1 * P
P^-1AP = DI_2
P^-1AP = D

A = PDP^1 <=> D = P^-1AP

example:
find value of a/b
A = [
	1 4
	2 3
]
D = [
	5 0
	0 -1
]
P = [
	1 a
	1 b
]
eigenvalues of A are λ1 = 5 and λ2 = -1
(second column of P λ2 = -1)

Now we need to find an eigenvector that corresponds to the second columne of λ2 = -1

A-(-1)I = [
	1 4
	2 3
] + [
	1 0
	0 1
] = [
	2 4
	2 4
]
R2 = R2 + (-1)R1
[
	2 4 | 0
	0 0 | 0
]
(x2 is free)
first equation we get x1 = -2x2
[
	-2x2
	 x2
]
setting x2 = 1 we get: v2 = [a|b] = [-2|1]
a/b = -2/1 = -2

example:
find the second column of P
A = [
	-5 -2
	12 5
]
D = [
	1 0
	0 -1
]
P = [
	 1 *
	-3 *
]
λ1 = 1 <- must correspond to P column 1
lets find eigenvector for λ2 = -1
A-(-1)I = [
	-5 -2
	12  5
] + [
	1 0
	0 1
] = [
	-4 -2
	12 6
]
R2 := R2 + (3)R1
[
	-4 -2 | 0
	 0  0 | 0
]
(x2 is free!)
-4x1 - 2x2 = 0
-4x1 = 2x2
x1 = 2x2/-4
x1 = -1/2x2
[
	-1/2x2
		x2
]
setting x2 = 2 we get:
v2 = [-1|2]
P = [
	1 -1
	-3 2
]

example:
find b/a
A = [
	-1 2
	-6 6
]
D = [
	2 0
	0 3
]
P = [
	2 a
	3 b
]
λ1 = 2 <- must correspond to P column 1
lets find eigenvector for λ2 = 3
A-(3)I = [
	-1 2
	-6 6
] - 3[
	1 0
	0 1
] = [
	-4 2
	-6 3
]
R1 := 1/2R1
[
	-2 1 | 0
	-6 3 | 0
]
R2 := R2 + (-3)R1
[
	-2 1 | 0
	 0 0 | 0
]
(ANSWER DID THIS IN ONE STEP: R2 := R2 + (-3/2)R1)
(x2 is free)
x1 = 1/2x2
[
	1/2x2
	  x2
]
setting x2 = 2 eigenvector:
[
	1
	2
]
b/a = 2/1 = 2

Diagonalizing a 2x2 matrix:
example:
A = [
	3 -8
	0 -2
]
find diagonal matrix D and an invertible matrix P such that D = P^-1AP

Step 1: find eigenvalues, λ1 = 3 λ2 = -2
(since we have a triangular matrix)

Step 2: find eigenvector for λ1 = 3
A - 3I = [
	3 -8
	0 -2
] - 3[
	1 0
	0 1
] = [
	0 -8
	0 -5
]
R2 := R2 + (-5/8)R1
[
	0 -8 | 0
	0  0 | 0
]
(x1 free)
x2 = 0
[
	x1
	0
]
setting x1 = 1: eigenvector v1 = [1|0]

for λ2 = -2
A -(-2)I = [
	3 -8
	0 -2
] + 2[
	1 0
	0 1
] = [
	5 -8
	0  0
]
(already in row echelon form)
(x2 is free)
solve first equation: x1 = 8/5x2
[
	8/5x2
	 x2
]
setting x2 = 5: v2 = [8|5]
D = [
	3 0
	0 -2
]
P = [
	1 8
	0 5
]

example:
B = [
	 9-λ  8
	-6 -7-λ
]
(9 - λ)(-7 - λ) - (8)(-6)
-63 + 7λ - 9λ + λ^2 + 48
λ^2 - 2λ - 15
(λ - 5)(λ + 3)
D = [
	 5  0
	 0 -3
]
B - 5I = [
	9 8
	-6 -7
] - 5[
	1 0
	0 1
] = [
	4 8
 -6 -12
]
R2 := R2 + (3/2)R1
[
	4 8 | 0
	0 0 | 0
]
(x2 is free)
4x1 + 8x2 = 0
x1 = -8/4x2
x1 = -2x2
setting x1 = 1 eigenvector: v1 = [-2|1]
now lets find -3
B -(-3)I = [
	9 8
	-6 -7
] + 3[
	1 0
	0 1
] = [
	12 8
	-6 -4
]
R1 := 1/2R1
R2 := R2 + R1
[
 6 4 | 0
 0 0 | 0
]
(x2 is free)
x1 = -4/6x2
x1 = -2/3x2
[
	-2/3x2
	  x2
]
setting x2 = 3: eigenvector v2 = [-2|3]
P = [
	-2 -2
	 1  3
]
(P and D found!)

example:
find D and P: D = P^-1AP
A = [
	-1 -6
	 0  3
]
A is triangular so we can simply plugin the eigenvalues into D
D = [
	-1 0
	 0 3
]
A -(-1)I = [
	-1 -6
	 0  3
] + [
	1 0
	0 1
] = [
	0 -6
	0 4
]
R1 := 1/3R1
R2 := R2 + 2R1
(ANSWER did this: R2 := R2 + 2/3R1)
[
	0 -2 | 0
	0  0 | 0
]
(x1 is free)
[
	x1
	0
]
setting x2 = 1: eigenvector v1 = [1|0]
for λ = 3
A -(3)I = [
	-1 -6
	 0  3
] - 3[
	1 0
	0 1
] = [
	-4 -6
	0 0
]
(already row echelon form)
-4x1 = 6x2
x1 = -3/2x2
setting x2 = 2: eigenvector v2 = [-3|2]
P = [
	1 -3
	0  2
]

Remember doesn't matter what order we put the eigenvalues in D diagonaly as long as the corresponding eigenvectors are lined up in P (if we swap D we must swap P)

==================================================

An nxn matrix A is said to be diagonalizable if there exists a diagonal matrix D and an invertible matrix P:
A = PDP^-1

theorem:
An nxn matrix A is diagonalizable if and only if there exists a basis of R^n that consists of eigenvectors of A

theorem:
if an nxn matrix A has n distinct eigenvalues (n simple roots of the characteristic equation), then there exists a basis of eigenvectors. The matrix is diagonalizable

3x3 matrix examples:
find a possible diagonal matrix D
A = [
	-1-λ 0  -4
	-1  2-λ  1
	-1   0 -1-λ
]
(2-λ)|-1-λ -4|
     |-1 -1-λ|
((-1-λ)(-1-λ) - (-4)(-1))
1 + λ + λ + λ^2 - 4
λ^2 + 2λ - 3
(2 - λ)(λ + 3)(λ - 1)
λ1 = 2, λ2 = 1, λ3 = -3, 
since all of the eigenvalues are simple roots of the characteristic polynomial, A is diagonalizable 
D = [
	2 0  0
	0 1  0
	0 0 -3
]
(order doesn't matter)

example:
find diagonal matrix D
A = [
	1-λ  0  -5
	11  8-λ  1
	 4   0  -7-λ
]
(8-λ)|1-λ -5|
		 |4 -7-λ|
((1-λ)(-7-λ) - (4)(-5))
-7 - λ + 7λ + λ^2 + 20
λ^2 + 6λ + 13
no real roots, A is not diagonalizable

example:
find the missing values then the vaue of a/b:
given the following matrices
A = [
	-2 -1  5
	 1 -4 -4
	 3 -3  0
] 
D = [
	-6  0 0
	 0 -3 0
	 0  0 3
]
P = [
	-1 a 1
	 1 b 0
	 1 0 1
]

λ = -3 (since we need the middle P column)
A = [
	-2 -1  5
	 1 -4 -1
	 3 -3  0
] -(-3)[
	1 0 0
	0 1 0
	0 0 1
] = [
	1 -1  5
	1 -1 -1
	3 -3  3
]
R2 := R2 + (-1)R1
[
	1 -1  5 | 0
	0  0 -6 | 0
	3 -3  3 | 0
]
R3 := R3 + (-3)R1
[
	1 -1  5  | 0
	0  0 -6  | 0
	0  0 -12 | 0
]
R3 := R3 + (-2)R2
[
	1 -1  5 | 0
	0  0 -6 | 0
	0  0  0 | 0
]
(x2 is free)
x3 = 0
x1 = x2
[
	x2
	x2
	0
]
setting x2 = 1 eigenvector: [1|1|0]
a/b = 1/1 = 1

example:
find the first column of matrix P
A = [
	5 -4 -2
	0 -1 0
	4 -4 -1
]
D = [
	-1 0 0
	0 1 0
	0 0 3
]
P = [
	* 1 1
	* 0 0
	* 2 1
]

finding λ = -1
A = [
	5 -4 -2
	0 -1  0
	4 -4 -1
] + [
	1 0 0
	0 1 0
	0 0 1
] = [
	6 -4 -2
	0  0  0
	4 -4  0
]
R1 := 1/2R1
R3 := 1/4R3
[
	3 -2 -1 | 0
	0  0  0 | 0
	1 -1  0 | 0
]
R2 <-> R3
[
	3 -2 -1 | 0
	1 -1  0 | 0
	0  0  0 | 0
]
R2 + (-1/3)R1
[
	3   -2  -1 | 0
	0 -1/3 1/3 | 0
	0    0   0 | 0
]
(x3 is free)
second equation: x2 = x3
substitute into first: x1 = x3
[
	x3
	x3
	x3
]
setting x3 = 1 eigenvector: [1|1|1]

example:
find D and P given:
λ1 = -4, λ2 = -2, λ3 = 2
A = [
	-6  4 0
	 1  0 3
	 8 -4 2
]
D = [
	-4  0 0
	 0 -2 0
	 0  0 2
]
trying λ3 = 2 first (set of unique column for an answer)
[
	-6  4 0
	 1  0 3
	 8 -4 2
] - 2[
	1 0 0
	0 1 0
	0 0 1
] = [
	-8 4 0
	1 -2 3
	8 -4 0
]
R3 := R3 + R1
[
	-8 4 0 | 0
	1 -2 3 | 0
	0  0 0 | 0
]
R1 <-> R2
[
	1 -2 3 | 0
	-8 4 0 | 0
	0  0 0 | 0
]
R2 := R2 + (8)R1
[
	1  -2  3 | 0
	0 -12 24 | 0
	0   0  0 | 0
]
(x3 free)
x2 = 2x3
x1 = 2(2x3) - 3x3  
x1 = 4x3 - 3x3  
x1 = x3
[
	  x3
		2x3
		x3
]
eigenvector v3"
[
	1
	2
	1
]

example:
find D and P given:
λ1 = -2, λ2 = -1, λ3 = 1
A = [
	 -5 2  2
	-12 4  6
	  0 1 -1
]
D = [
	-2 0 0
	 0 -1 0
	 0 0 0
]

A = [
	 -5 2  2
	-12 4  6
	  0 1 -1
] -(-2)[
	1 0 0
	0 1 0
	0 0 1
] = [
	-3  2 2
	-12 6 6
	 0 1  1
]
R2 := R2 + (-4)R1
[
	-3  2  2 | 0
	 0 -2 -2 | 0
	 0  1  1 | 0
]
R2 := 1/2R2
[
	-3  2  2 | 0
	 0 -1 -1 | 0
	 0  1  1 | 0
]
R3 := R2 + R3
[
	-3  2  2 | 0
	 0 -1 -1 | 0
	 0  0  0 | 0
]
R1 := R1 + 2R2
[
	-3  0  0 | 0
	 0 -1 -1 | 0
	 0  0  0 | 0
]
R1 := -1/3R1
[
	 1  0  0 | 0
	 0 -1 -1 | 0
	 0  0  0 | 0
]
R2 := (-1/1)R2
[
	 1 0 0 | 0
	 0 1 1 | 0
	 0 0 0 | 0
]
(x3 free)
x2 = -x3
x1 = 0
[
	0
 -1
	1
]

matrix A can be diagonal if the sum of the dimensions of an eigenspace equals the number of row/columns of matrix A, some double roots may have only one vector.

to check whether diagonalization is possible:
theorem:
An nxn matrix is diagonalizable iff the sum of the dimensions of the eigenspaces equals n

example:
find corresponding diagonal matrix D
A = [
	 1-λ  0   0
	 5  -3-λ -1
	-5    4  2-λ
]
(1-λ)|-3-λ -1|
     |4   2-λ|
(-3 - λ)(2 - λ)
-6 + 3λ - 2λ + λ^2 + 4
λ^2 + λ - 2
(λ - 1)^2(λ + 2)
λ = -2
lets check the double root:
A - 1I = [
	 1  0  0
	 5 -3 -1
	-5  4  2
] - [
	1 0 0
	0 1 0
	0 0 1
] = [
	 0  0  0
	 5 -4 -1
	-5  4  1
]
R3 := R3 + R2
[
	 0  0  0
	 5 -4 -1
	 0  0  0
]
R1 <-> R2
[
	 5 -4 -1
	 0  0  0
	 0  0  0
]
(one pivot) 3 - 1 = 2 linearly independent eigenvectors corresponding to λ2 = 1 so
dim(V_1) = 2

A is diagonalizable since:
dim(V_-2) + dim(V_1) = 1 + 2 = 3
D = [
	1 0  0
	0 1  0
	0 0 -2
]

example:
if matrix A is diagonalizable find a corresponding diagonal matrix D
A = [
	-6-λ  0  0
	-9  12-λ 0
	-3   6  -6-λ
]
(-6-λ)|(-6-λ)  0|
			|-9 (12-λ)|
(-6 - λ)(12 - λ) - (0)(-9)
-72 + 6λ - 12λ + λ^2
λ^2 - 6λ - 72
(λ + 6)(λ + 6)(λ - 12)
(λ + 6)^2(λ - 12)
double check double root:
A -(-6)I = [
	-6  0  0
	-9 12  0
	-3  6 -6
] -(-6)[
	1 0 0
	0 1 0
	0 0 1
] = [
	 0  0 0
	-9 18 0
	-3  6 0
]
R1 <-> R3
[
	-3  6 0 | 0
	-9 18 0 | 0
	 0  0 0 | 0
]
R2 := R2 + (-3)R1
[
	-3  6 0 | 0
	 0  0 0 | 0
	 0  0 0 | 0
]
(one pivot) this implies that we will have 3-1=2 linearly independent eigenvectors corresponding to λ2 = -6
A is diagonalizable:
dim(V_12) + dim(V_-6) = 1 + 2 = 3
D = [
	-6  0  0 
	 0 -6  0
	 0  0 12
]

example:
find missing values (a,b) then a/b
D = [
	1 0 0
	0 2 0
	0 0 2
]
P = [
	1 -5 a
	2  0 b
	1  8 0
]
A = [
	10  -7  5
	16 -12 10
	 8  -7  7
] - 2[
	1 0 0
	0 1 0
	0 0 1
] = [
	 8  -7  5
	16 -14 10
	 8  -7  5
]
R3 := R3 + (-1)R1
R2 := R2 + (-2)R1
[
	 8  -7  5 | 0
	 0   0  0 | 0
	 0   0  0 | 0
]
(x2, x3 are free)
x1 = 1/8(-5x3 + 7x2)
since we know x3 = 0 from P above
[
 1/8(7x2)
	x2
	0
]
[
	7
	8
	0
]
a/b = 7/8

example:
find missing a,b values then the value of a/b
A = [
	 -8  8 -6
	-15 14 -9
	 -5  4 -1
]
D = [
	1 0 0
	0 2 0
	0 0 2
]
P = [
	2 a 4
	3 0 5
	1 b 0
]
A = [
	 -8  8 -6
	-15 14 -9
	 -5  4 -1
] - 2[
	1 0 0
	0 1 0
	0 0 1
] = [
	-10  8 -6
	-15 12 -9
	 -5  4 -3
]
R2 := R2 + (-3)R3
[
	-10  8 -6
	  0  0  0
	 -5  4 -3
]
R3 := R3 + (-1/2)R1
[
	-10  8 -6
	  0  0  0
	  0  0  0
]
R1 := (1/2)R1
[
	 -5  4 -3
	  0  0  0
	  0  0  0
]
(x2 and x3 free)
x1 = -1/5(3x3 - 4x2)
x2 = 0 from the P above, and setting x3 = 5
[
	-3
	 0
	 5
]

example:
find D and P from A
D = [
	1 0  0
	0 1  0
	0 0 -1
]
A = [
	1  0 0
	2 -1 0
	3 -3 1
] - [
	1 0 0
	0 1 0
	0 0 1
] = [
	0  0 0
	2 -2 0
	3 -3 0
]
R1 <-> R2
[
	2 -2 0
	0  0 0
	3 -3 0
]
R3 := R3 + (-3/2)R1
[
	2 -2 0
	0  0 0
	0  0 0
]
(x3, x2 is free)
x1 = x2
[
	x2
	x2
	x3
] = x2[
	1
	1
	0
] + x3[
	0
	0
	1
]
v3 = [0|2|3]
P = [
	1 0 0
	1 0 2
	0 1 3
]

example:
find P (eigenvectors)
D = [
	1 0  0
	0 1  0
	0 0 -4
]
(lets try λ = -4 first)
A = [
	1   1  1
	0   6  5
	0 -10 -9
] -(-4)[
	1 0 0
	0 1 0
	0 0 1
] = [
	5   1  1
	0  10  5
	0 -10 -5
]
R3 := R3 + R2
[
	5   1  1 | 0
	0  10  5 | 0
	0   0  0 | 0
]
R2 := 1/5R2
[
	5   1  1 | 0
	0   2  1 | 0
	0   0  0 | 0
]
5x1 + x2 + x3 = 0
2x2 + x3 = 0
x3 = -2x2
5x1 + x2 - 2x2 =0
5x1 - x2 = 0
x2 = 5x1
x3 = -10x1
v3 = [
	-1
	-5
	10
]
P = [
	1  0 -1
	0 -1 -5
	0  1 10
]

==================================================

A square matrix A is symmetric if it is equal to its transpose:
A^T = A

An nxn matrix is symmetric if a_ij = a_ji for all 1 <= i,j <= n

this really means that it is symmetric across its main diagonal

examples:
P is symmetric P = P^T
P = [
	 1 -6
	-6  1
]
Q is symmetric Q = Q^T
Q = [
	0 3
	3 0
]
P is symmetric P = P^T
P = [
	2  0  1
	0 -3 -2
	1 -2  1
]
R is symmetric R = R^T
R = [
	5  8
	8 -5
]

if A is a symmetric matrix:
-A is symmetric
A^m is symmetric for any positive integer m
A^-1 is symmetric for nonsingular A

if A and B are nxn symmetric matrices:
A + B is symmetric
A ⋅ B is not always symmetric, example:
A = [
	0 1
	1 0
] ⋅ B = [
	1 1
	1 0
] = [
	1 0
	1 1
]
NOT symmetric ^

to construct symmetric matrices:
A + A^T is symmetric for any square matrix A
A^TA and AA^T are symmetric for any matrix A

For any matrix A:
(A + A)^T = A^T + (A^T)^T
= A^T + A
= A + A^T

(AA^T)^T = (A^T)^TA^T
= AA^T

(A + B)^T = A^T + B^T
= A + B

(A^-1)^T = (A^T)^-1
= A^-1

A square matrix A is orthogonally diagonalizable if there exists an orthogonal matrix P such that:
A = PDP^T
D = P^TAP (equivalent)

theorem:
A matrix A with real entries is orthogonally diagonalizable iff it is symmetric

every symmetric matrix is orthogonally diagonalizable

example:
A = [
	3  3
	3 -5
]
orthogonally diagonalization:
(P = [
	3/sqrt(10)  1/sqrt(10)
	1/sqrt(10) -3/sqrt(10)
]
D = [
	4  0
	0 -6
]
P^T = [
	3/sqrt(10)  1/sqrt(10)
	1/sqrt(10) -3/sqrt(10)
]) = A
P is orthogonal and D is diagonal. D are the eigenvalues, and columns of P are orthonormal eigenvectors corresponding to the eigenvalues of A

orthogonal diagonalization is almost the same as the diagonalization of a matrix:
Step 1: find eigenvalues of A
Step 2: find a basis of R^2 consisting of unit orthogonal eigenvectors of A
Step 3: construct the matrices D and P

we must ensure that we normalize the eigenvectors

example:
what is the first column of P?
P = [
	* -sqrt(10)/10
	* -3sqrt(10)/10
]
=
[
	3sqrt(10)/10
	-sqrt(10)/10
]

example:
what is the second column of P?
P = [
	sqrt(2)/2 *
	sqrt(2)/2 *
]
the second column must be orthogonal to the first column
the norm of the second column must be equal to 1
the only vector with these properties:
[
	sqrt(2)/2
	-sqrt(2)/2
]

example:
P = [
	* 3/5
	* -4/5
]
= vector:
[
	4/5
	3/5
]

example:
given that D = P^TAP where P is an orthogonal matrix, which of the following could be the second column of the matrix P?
D = [
	3  0
	0 -2
]
finding second column of P, use λ = -2
A = [
	-1 2
	 2 2
] -(-2)[
	1 0
  0 1
] = [
	1 2
	2 4
]
R2 := R2 + (-2)R1
[
	1 2 | 0
	0 0 | 0
]
x1 = -2x2
[
	-2x2
	x2
] = [
	-2
	 1
]
||v2|| = sqrt(5) dividing by its norm.
v2/||v2|| = 1/sqrt(5)[-2 | 1] = [
	-2sqrt(5)/5
	sqrt(5)/5
]

example:
what is the first column of P?
D = [
	4  0
	0 -2
]
A = [
	 1 -3
	-3  1
] - 4[
	1 0
	0 1
] = [
	-3 -3
	-3 -3
]
R2 := R2 + (-1)R1
[
	-3 -3 | 0
 	 0  0 | 0
]
x1 = -x2
[
	-1
	1
]
||v1|| = sqrt(2) dividing by norm:
v1/||v1|| = 1/sqrt(2)[-1 | 1] = [
	-sqrt(2)/2
	sqrt(2)/2
]

example:
given: λ1 = 5, λ2 = 10
find diagonal D and orthogonal P
D = P^TAP
D = [
	5  0
	0 10
]
A = [
	9 2
	2 6
] - 5[
	1 0
	0 1
] = [
	4 2
	2 1
]
x2 = -2x1
4x1 = -2(-2x1)
x1 = 1
[
	1
	-2
]
(Answer didn't reduce nor came up with above):
[
	-1
	 2
]
v1/||v1|| = 1/sqrt(5)[-1 | 2] = [
	-1
]
A = [
	9 2
	2 6
] - 10[
	1 0
	0 1
] = [
	-1  2
	 2 -4
]
R2 := 1/2R2
R2 := R2 + R1
[
	-1  2 | 0
	 0  0 | 0
]
x1 = 2x2
[
	2
	1
]
v2/||v2 = 1/sqrt(5)[2 | 1] = [
	2/sqrt(5)
	1/sqrt(5)
]
P = [
	-1/sqrt(5) 2/sqrt(5)
	2/sqrt(5) 1/sqrt(5)
]

example:
given: λ1 = 4, λ2 = -2
D = [
	4  0
	0 -2
]
A = [
	1 3
	3 1
] - 4[
	1 0
	0 1
] = [
	-3  3
	 3 -3
]
x2 = 1
x1 = 1
v1 = [1 | 1]
v1/||v1|| = 1/sqrt(2)[1 | 1] = [
	sqrt(2)/2
	sqrt(2)/2
]
A = [
	1 3
	3 1
] -(-2)[
	1 0
	0 1
] = [
	3 3
	3 3
]
x2 = -x1
x1 = -(-x1)
x1 = 1
I got [1 | -1]
Answer is (not sure whos wrong):
v2 = [-1 | 1]
||v2|| = sqrt(2)
v2/||v2|| = 1/sqrt(2)[-1 | 1] = [
	-sqrt(2)/2
	sqrt(2)/2
]
P = [
	sqrt(2)/2 -sqrt(2)/2
	sqrt(2)/2 sqrt(2)/2
]



























